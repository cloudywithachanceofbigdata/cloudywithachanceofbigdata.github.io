<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">4 posts tagged with &quot;etl&quot; | Full Stack Chronicles</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" name="twitter:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" property="og:url" content="https://fullstackchronicles.io/tags/etl"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="twitter:site" content="@fschronicles1"><meta data-rh="true" name="twitter:creator" content="@fschronicles1"><meta data-rh="true" name="og:type" content="website"><meta data-rh="true" name="og:locale" content="en_US"><meta data-rh="true" name="og:site_name" content="Full Stack Chronicles"><meta data-rh="true" name="msapplication-TileColor" content="#2d89ef"><meta data-rh="true" name="theme-color" content="#ffffff"><meta data-rh="true" property="og:title" content="4 posts tagged with &quot;etl&quot; | Full Stack Chronicles"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/favicon.ico"><link data-rh="true" rel="canonical" href="https://fullstackchronicles.io/tags/etl"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/etl" hreflang="en"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/etl" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MZCGVO503N-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Full Stack Chronicles Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Full Stack Chronicles Blog Feed Atom Feed">
<link rel="alternate" type="application/json" href="/feed.json" title="Full Stack Chronicles Blog Feed JSON Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FVDC1E8G6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0FVDC1E8G6",{})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Full Stack Chronicles" href="/opensearch.xml">


<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0f4c81"><link rel="stylesheet" href="/assets/css/styles.5ea58133.css">
<link rel="preload" href="/assets/js/runtime~main.fa9202be.js" as="script">
<link rel="preload" href="/assets/js/main.a1cf5441.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#A9BCD0;color:#1A4E82" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><b>If you find our content useful, follow us on <a target="_blank" rel="noopener noreferrer" href="https://github.com/stackql">GitHub</a>, if you have some content to share, reach out</b></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ navbar--primary"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Full Stack Chronicles</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/tags">Topics</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/snowflake">Snowflake</a></li><li><a class="dropdown__link" href="/tags/okta">Okta</a></li><li><a class="dropdown__link" href="/tags/openapi">OpenAPI</a></li><li><a class="dropdown__link" href="/tags/spark">Spark</a></li><li><a class="dropdown__link" href="/tags/kafka">Kafka</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/json-ld-structured-data-for-docusaurus">Yoast (like) JSON-LD Structured Data for Docusaurus</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/gitver-an-alternative-versioning-scheme-to-semver-or-calver">Introducing GitVer - an alternative versioning scheme</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/use-deno-deploy-to-serve-non-traditional-artifacts">Use Deno Deploy to Serve Non-Traditional Artifacts</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/apache-beam-in-five-minutes">Apache Beam in Five Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/aws-iam-vs-google-iam">AWS IAM vs Google IAM</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/create-and-use-custom-magic-commands-in-jupyter">Create and use Custom Magic Commands in Jupyter</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/deno-in-five-minutes">Deno in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dbt-in-five-minutes">DBT in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/loading-parquet-files-into-snowflake">Loading Parquet Files into Snowflake</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/analyze-developer-activity-with-stackql-jupyter-bigquery">Analyze Developer Activity with StackQL, Jupyter and BigQuery</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/converting-google-discovery-docs-to-openapi3-specs">Converting Google Discovery Docs to OpenAPI3 Specs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/recurse-javascript-object-to-get-values-for-a-given-key-the-easy-way">Recurse JavaScript Object to Get Values for a Given Key the Easy Way</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dataops-with-container-images-and-multi-stage-builds">DataOps with Container Images and Multi-Stage Builds</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/using-the-snowflake-sql-api-with-typescript">Using the Snowflake SQL API with TypeScript</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/split-a-large-swagger-openapi-specification-into-smaller-documents">Split a large Open API or Swagger Specification into smaller documents</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>4 posts tagged with &quot;etl&quot;</h1><a href="/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/blog/apache-beam-in-five-minutes.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/apache-beam-in-five-minutes">Apache Beam in Five Minutes</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-12-12T00:00:00.000Z" itemprop="datePublished">December 12, 2022</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Apache Beam is an open-source project which provides a unified programming model for Batch and Streaming data pipelines.  </p><p><strong>B</strong>(<em>atch</em>) <strong>+</strong> <em>str</em>(<strong>EAM</strong>) <strong>=&gt;</strong> <strong>BEAM</strong>  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="beam-sdk-and-execution-framework">Beam SDK and Execution Framework<a class="hash-link" href="#beam-sdk-and-execution-framework" title="Direct link to heading">​</a></h2><p>Beam SDKs allow you to define <strong>Pipelines</strong> (in languages such as Java or Python).  A pipeline is essentially a graph (a DAG - Directed Acyclic Graph) of nodes that represent transformation steps.  </p><p><a target="_blank" href="/assets/files/apache_beam_pipeline-57da72b3b0021f899068fb96d45ac459.png"><img loading="lazy" alt="Apache Beam Pipeline" src="/assets/images/apache_beam_pipeline-57da72b3b0021f899068fb96d45ac459.png" width="735" height="216" class="img_ev3q"></a></p><p>Pipelines can then be executed on a backend service (such as your local machine, Apache Spark, or Google Cloud Dataflow) using <strong>Runners</strong>.  For instance, to run a pipeline locally, you would use the DirectRunner; to run a pipeline on Google Cloud Dataflow you would use the DataflowRunner runner.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="beam-programming-model">Beam Programming Model<a class="hash-link" href="#beam-programming-model" title="Direct link to heading">​</a></h2><p>The <strong>PCollection</strong> is the most atomic data unit in the Beam programming model, akin to the RDD in the Apache Spark core API; it is a representation of an immutable collection of items that is physically broken down into <strong>bundles</strong> (subsets of elements for parallelization).  </p><p>PCollections can be <em>bounded</em> (which is a batch processing pattern) or <em>unbounded</em> (which is a stream processing pattern).  </p><p>A <strong>PTransform</strong> is an operator that takes a PCollection as an input and outputs a new PCollection with transforms applied.  This is the same coarse-grained transformation pattern employed by Spark.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="beam-dsl">Beam DSL<a class="hash-link" href="#beam-dsl" title="Direct link to heading">​</a></h2><p>The Beam DSL is a set of higher-order functions that can be used to construct pipelines.  These functions are used to construct the graph of nodes that represent the pipeline.  </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="map-flatmap-and-filter">Map, FlatMap and Filter<a class="hash-link" href="#map-flatmap-and-filter" title="Direct link to heading">​</a></h3><p>The basic <strong>Map</strong>, <strong>FlatMap</strong> and <strong>Filter</strong> functions in the Beam API work similarly to their namesakes in the Spark Core API.  The Map and FlatMap functions are higher-order functions (that is, functions that have arguments of other functions) that operate on each element in a collection, emitting an output element for each input element.  The Filter function can be used to only emit elements from an input PCollection that satisfy a given expression.  </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pardo-and-dofn">ParDo and DoFn<a class="hash-link" href="#pardo-and-dofn" title="Direct link to heading">​</a></h3><p><strong>ParDo</strong> is a wrapper function for parallel execution of a user-defined function called a <strong>DoFn</strong> (&quot;do function&quot;), ParDo&#x27;s and DoFn&#x27;s are used when the basic Map and FlatMap operators are not enough.  DoFns are executed in parallel on a PCollection and can be used for computational transformations or transformations other than 1:1 between inputs and outputs.  </p><p>Think of these as user-defined functions to operate on a PCollection in parallel.  </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="groupbykey-combinebykey">GroupByKey, CombineByKey<a class="hash-link" href="#groupbykey-combinebykey" title="Direct link to heading">​</a></h3><p><strong>GroupByKey</strong> and <strong>CombineByKey</strong> are operators that group data (key-value pairs) by the key for each element.  This is typically a precursor to some aggregate operation (such as a count or sum operation).  </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cogroupbykey-and-flatten">CoGroupByKey and Flatten<a class="hash-link" href="#cogroupbykey-and-flatten" title="Direct link to heading">​</a></h3><p><strong>CoGroupByKey</strong> is akin to a <code>JOIN</code> operation in SQL (by the key for each element in two PCollections).  <strong>Flatten</strong> is akin to a <code>UNION</code> in SQL.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="side-inputs">Side Inputs<a class="hash-link" href="#side-inputs" title="Direct link to heading">​</a></h2><p><strong>Side Inputs</strong> can be used with ParDo and DoFn to provide additional data, which can be used to enrich your output PCollection, or utilized within the logic of your DoFn.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sources-sinks-and-connectors">Sources, Sinks and Connectors<a class="hash-link" href="#sources-sinks-and-connectors" title="Direct link to heading">​</a></h2><p><strong>Sources</strong> represent where data is read into an Apache Beam pipeline; <strong>sinks</strong> represent destinations where data is written out from pipelines.  A Beam pipeline will contain one or more sources and sinks.  </p><p>Sources can be bounded (for batch processing) or unbounded for stream processing.  </p><p><strong>Connectors</strong> can be source connectors or sink connectors to read from or write to the various sources and targets used in a Beam pipeline.  Examples include FileIO and TextIO for working with files or text data, BigQueryIO for reading or writing into BigQuery, PubSubIO for reading and writing messages into Google PubSub, and much more.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="streaming-and-unbounded-pcollections">Streaming and Unbounded PCollections<a class="hash-link" href="#streaming-and-unbounded-pcollections" title="Direct link to heading">​</a></h2><p>Streaming data sources are represented by Unbounded PCollections.  Unbounded PCollections support windowing operations using <strong>Fixed Windows</strong>, <strong>Sliding Windows</strong>, or <strong>Session</strong> Windows.  <strong>Watermarks</strong> are used to allow for late-arriving data to be processed within its associated time window, and <strong>Triggers</strong> can be used to control the processing of windowed batches of data.   </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="templates">Templates<a class="hash-link" href="#templates" title="Direct link to heading">​</a></h2><p>Beam templates enable the reusability of pipelines, converting compile-time pipeline parameters to run-time arguments.  Jobs (invocations of pipelines) can be launched from templates.  </p><p><strong>Templates</strong> include classic templates, where the graph for the pipeline is built (compile-time) with the template, flex templates where the pipeline graph is created when the template is launched (runtime).  </p><p>In addition, Google provides several templates with Cloud Dataflow (Google-provided templates), allowing you to launch routine jobs without writing any code.  </p><p>Google-provided templates are available for batch, streaming, and utility pipelines, for example:  </p><ul><li>Kafka to BigQuery</li><li>Pub/Sub Topic to BigQuery</li><li>Text Files on Cloud Storage to BigQuery</li><li>Text Files on Cloud Storage to Cloud Spanner</li><li>Bulk Compress or Decompress Files on Cloud Storage</li><li>and more</li></ul><p>5 minutes is up!  I hope you enjoyed this quick introduction to Apache Beam.  If you want to learn more, check out the <a href="https://beam.apache.org/documentation/" target="_blank" rel="noopener noreferrer">Apache Beam documentation</a>.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/google">google</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/gcp">gcp</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/beam">beam</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/apache-beam">apache beam</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/dataflow">dataflow</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/google-cloud-dataflow">google cloud dataflow</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/etl">etl</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/stream-processing">stream processing</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/blog/dbt-in-five-minutes.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/dbt-in-five-minutes">DBT in 5 Minutes</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-08-05T00:00:00.000Z" itemprop="datePublished">August 5, 2022</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://docs.getdbt.com/" target="_blank" rel="noopener noreferrer"><strong>DBT (or Data Build Tool)</strong></a> is a modern data transformation tool born in the cloud/DevOps era. It&#x27;s a great project which much has been written about; I will try to give as brief an overview as possible.  </p><details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>ETL vs ELT Refresher</summary><div><div class="collapsibleContent_i85q"><p>A quick refresher on ELT vs ETL before we discuss DBT. I have created an infographic for this...</p><a target="_blank" href="/img/blog/dbt-in-five-minutes/etl-vs-elt.png"><img loading="lazy" alt="ETL vs ELT" src="/img/blog/dbt-in-five-minutes/etl-vs-elt.png" width="595" height="410" class="img_node_modules-@docusaurus-theme-classic-lib-theme-MDXComponents-Img-styles-module" class="img_ev3q"></a></div></div></details><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="summary">Summary<a class="hash-link" href="#summary" title="Direct link to heading">​</a></h2><p>DBT is an open-source command line tool written in Python from DBT Labs (formerly Fishtown Analytics).  </p><p>DBT is designed to manage data transformations while applying software engineering best practices (including version control, automated testing, reviews, approvals, etc).  Its modern software engineering and cloud-first design goals separate it from its old-school ETL/ELT predecessors.  </p><p>DBT is an <strong>ELT</strong> tool focusing on the <strong>T</strong>(ransform) only, the E(xtract) and L(oad) are up to you (there are plenty of tools that specialize in this).  </p><p>At its core DBT is a templating engine using Jinja (Python templating engine); it generates templates that represent SQL commands to create, replace or update objects in your database (the <strong>“T”</strong> in ELT), then oversees the execution of the templated commands.  The work is &quot;pushed down&quot; to the underlying database containing the source and target objects and data.   </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="models">Models<a class="hash-link" href="#models" title="Direct link to heading">​</a></h2><p>The concept most integral to DBT is the <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models" target="_blank" rel="noopener noreferrer"><strong>Model</strong></a>.  A Model is simply a representation of a transform (or set of transforms) to a dataset, resulting in a target object (which could be a table or tables in a datamart).  A model is expressed as a <code>SELECT</code> statement stored in a <code>.sql</code> file in your <code>dbt</code> project (well get to that in a minute).  </p><p>Suppose we want to create a denormalized fact table for commits to store in a datamart in BigQuery.  This is what a model file might look like (using the BigQuery SQL dialect and referencing objects that should exist and be accessible at runtime when we execute the model).  </p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">{{ config</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">materialized</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;table&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> }}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> commits </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    SUBSTR</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">commit</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">13</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> commit_short_sha</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    committer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">name </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> commiter_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    committer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">date</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> commit_date</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    message</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repo_name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:#393A34">`</span><span class="token identifier">bigquery-public-data.github_repos.sample_commits</span><span class="token identifier punctuation" style="color:#393A34">`</span><span class="token plain"> c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">select</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> commits</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Models are created as views by default, but you can materialize these as tables where needed.  </p><p>You configure connectivity to the target database using <a href="https://docs.getdbt.com/docs/available-adapters" target="_blank" rel="noopener noreferrer"><strong>adapters</strong></a> (software libraries provided by dbt in the case of most mainstream databases) and <a href="https://docs.getdbt.com/dbt-cli/configure-your-profile" target="_blank" rel="noopener noreferrer"><strong>profiles</strong></a> (which contain details around authentication, databases/datasets, schemas etc).  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dbt-project">DBT Project<a class="hash-link" href="#dbt-project" title="Direct link to heading">​</a></h2><p>A DBT project is simply a folder containing your models and some other configuration data.  You can initialize this by running <a href="https://docs.getdbt.com/reference/commands/init" target="_blank" rel="noopener noreferrer"><strong><code>dbt init</code></strong></a> from your desired project directory.  In its most basic form, the structure looks like this:  </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">models/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ your_model.sql</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─ schema.yml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dbt_project.yml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Your models can be created under subfolders for organization.  <a href="https://docs.getdbt.com/reference/resource-configs/schema" target="_blank" rel="noopener noreferrer"><strong><code>schema.yml</code></strong></a> is an optional file that  contains tests for columns, can also include descriptions for documentation.  The <a href="https://docs.getdbt.com/reference/dbt_project.yml" target="_blank" rel="noopener noreferrer"><strong><code>dbt_project.yml</code></strong></a> file is the main entry point for the <code>dbt</code> program, it contains the configuration for the project, including which <code>profile</code> to use.  Profiles (stored in a file called <a href="https://docs.getdbt.com/reference/profiles.yml" target="_blank" rel="noopener noreferrer"><strong><code>profiles.yml</code></strong></a> store all of the necessary connectivity information for your target database platform.  By default <code>dbt init</code> creates this file a <code>.dbt</code> folder under your home directory.  </p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>You could store this with your project (be careful not to commit secrets like database credentials to source control).  If you store it in any other directory than the default, you will need to tell <code>dbt</code> where it can find this file using the <code>--profiles-dir</code> argument of any <code>dbt</code> command, see <a href="https://docs.getdbt.com/dbt-cli/configure-your-profile#advanced-customizing-a-profile-directory" target="_blank" rel="noopener noreferrer"><strong>here</strong></a> for more information.</p></div></div><p>To confirm your project is ship shape, run <a href="https://docs.getdbt.com/reference/commands/parse" target="_blank" rel="noopener noreferrer"><strong><code>dbt parse</code></strong></a>; if there are no errors, you are good to proceed running and testing your models.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="running-dbt-models">Running DBT Models<a class="hash-link" href="#running-dbt-models" title="Direct link to heading">​</a></h2><p>To run your models, simply run the following command from the directory containing your <code>dbt_project.yml</code> file (typically the root of your project folder):  </p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Command</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Output</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><pre tabindex="0" class="codeBlockStandalone_MEMb thin-scrollbar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><b><a href="https://docs.getdbt.com/reference/commands/run" target="_blank" rel="noopener noreferrer">dbt run</a></b></code></pre></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><pre tabindex="0" class="codeBlockStandalone_MEMb thin-scrollbar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><code class="codeBlockLines_e6Vv">06:56:36  Running with dbt=1.2.0<br>06:56:36  Found 1 model, 2 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics<br>06:56:36<br>06:56:37  Concurrency: 1 threads (target=&#x27;dev&#x27;)<br>06:56:37<br>06:56:37  1 of 1 START table model dbt_dataset.fct_commits ............................... [RUN]<br>06:56:50  1 of 1 OK created table model dbt_dataset.fct_commits .......................... [CREATE TABLE (672.3k rows, 396.7 MB processed) in 13.28s]<br>06:56:50<br>06:56:50  Finished running 1 table model in 0 hours 0 minutes and 14.01 seconds (14.01s).<br>06:56:50<br>06:56:50  Completed successfully<br>06:56:50<br>06:56:50  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1</code></pre></div></div></div><p>Model deployed!  Let&#x27;s test it:   </p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Command</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Output</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><pre tabindex="0" class="codeBlockStandalone_MEMb thin-scrollbar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><b><a href="https://docs.getdbt.com/reference/commands/test" target="_blank" rel="noopener noreferrer">dbt test</a></b></code></pre></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><pre tabindex="0" class="codeBlockStandalone_MEMb thin-scrollbar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><code class="codeBlockLines_e6Vv">06:57:19  Running with dbt=1.2.0<br>06:57:19  Found 1 model, 2 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics<br>06:57:19<br>06:57:19  Concurrency: 1 threads (target=&#x27;dev&#x27;)<br>06:57:19<br>06:57:19  1 of 2 START test not_null_fct_commits_commit_short_sha ........................ [RUN]<br>06:57:21  1 of 2 PASS not_null_fct_commits_commit_short_sha .............................. [PASS in 1.88s]<br>06:57:21  2 of 2 START test unique_fct_commits_commit_short_sha .......................... [RUN]<br>06:57:24  2 of 2 PASS unique_fct_commits_commit_short_sha ................................ [PASS in 3.14s]<br>06:57:24<br>06:57:24  Finished running 2 tests in 0 hours 0 minutes and 5.41 seconds (5.41s).<br>06:57:24<br>06:57:24  Completed successfully<br>06:57:24<br>06:57:24  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2</code></pre></div></div></div><p>This will run all of the tests associated with your model(s) - in this case, <code>not null</code> and <code>unique</code> tests defined in the <code>schema.yml</code> file.  That&#x27;s it, deployed and tested.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="other-stuff">Other Stuff<a class="hash-link" href="#other-stuff" title="Direct link to heading">​</a></h2><p>There is some other stuff in DBT you should be aware of, like <code>seeds</code>, <code>snapshots</code>, <code>analyses</code>, <code>macros</code>, and more but our five minutes is up 😃.  We can discuss these next time; you are up and running with the basics of DBT now, get transforming!</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/dbt">dbt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/elt">elt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/etl">etl</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/sql">sql</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/snowflake">snowflake</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/bigquery">bigquery</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/blog/scaling-up-prefect-with-gitstorage-featured-image.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/scaling-up-prefect-with-gitstorage">Scaling up Prefect with GitStorage</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-02-28T00:00:00.000Z" itemprop="datePublished">February 28, 2022</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/datwiz" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="http://0.gravatar.com/avatar/f9af9c3fae755ac170c5798c53c5267d?s=80" alt="Chris Ottinger"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/datwiz" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Chris Ottinger</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Technologist</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://prefect.io" target="_blank" rel="noopener noreferrer">Prefect.io</a> is a python based Data Engineering toolbox for building and
operating Data Pipelines.  Out of the box, Prefect provides an initial workflow for managing data
pipelines that results in a container image per data pipeline job.</p><p>The one-to-one relationship between data pipeline jobs and container images enables data engineers to
craft pipelines that are loosely coupled and don&#x27;t require a shared runtime environment configuration.
However, as the number of data pipeline jobs grow the default container per job approach starts to
introduce workflow bottlenecks and lifecycle management overheads.  For example, in order
to update software components used by flows, such as upgrading the version of Prefect, all the data
pipeline job images have to be rebuilt and redeployed.  Additionally the container image per job workflow
introduces a wait time for data engineers to re-build data pipeline container images and test flows
centrally on Prefect Server or Prefect Cloud environment.</p><p>Fortunately, Prefect comes to its own rescue with the ability to open up the box, exposing the flexibility
in the underlying framework.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="out-of-the-box---prefect-dockerstorage">Out of the box - Prefect DockerStorage<a class="hash-link" href="#out-of-the-box---prefect-dockerstorage" title="Direct link to heading">​</a></h2><p>Out of the box, Prefect provides a simple workflow for defining and deploying data pipelines as container images.
After getting a first data pipeline running in a local environment, the attention turns to scaling up development
and deploying flows into a managed environment, using either the Prefect Cloud service or a Prefect Server.</p><p>Combining Prefect Cloud or Prefect Server with Kubernetes provides a flexible and scalable platform
solution for moving data pipelines into production.  There are a number of options for packaging
data pipeline flow code for execution on kubernetes clusters.  The Docker Storage option provides
the workflow for bundling the data pipeline job code into container images, enabling a common
controlled execution environment and well understood distribution mechanism.  The data pipeline runs as
a pod using the flow container image.</p><p>Prefect Docker Storage workflow steps for building and deploying data pipeline flows include:</p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Steps</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">PlantUML</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><a target="_blank" href="/assets/files/image1-3eb8a74efcfb6b3a329f69dd9b89ca34.png"><img loading="lazy" alt="Workflow Steps" src="/assets/images/image1-3eb8a74efcfb6b3a329f69dd9b89ca34.png" width="253" height="435" class="img_ev3q"></a> </p></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@startuml &quot;docker-storage-workflow&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(*) --&gt; &quot;package flow code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">into a container image&quot; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; &quot;register Prefect flow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using image reference&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; &quot;push image to container registry&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; &quot;run flow in Prefect Server or Cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(new image pulled from registry)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; (*)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@enduml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div><ul><li>packaging a flow (python code) as a serialised/pickled object into a container image</li><li>registering the flow using the container image name</li><li>pushing the container image to a container repository accessible from the kubernetes cluster</li><li>running the flow by running an instance of the named container image as a kubernetes pod</li></ul><p>This is relatively simple immutable workflow.  Each data pipeline flow version is effectively a unique and
self contained &#x27;point-in-time&#x27; container image.  This initial workflow can also be extended to package
multiple related flows into a single container image, reducing the number of resulting container images.
But, as the number of data pipeline jobs grow, there issues of container image explosion and data engineering
productivity remain.</p><p>Using Prefect GitStorage for flows addresses both container image proliferation as well as development
bottlenecks.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="prefect-git-storage">Prefect Git Storage<a class="hash-link" href="#prefect-git-storage" title="Direct link to heading">​</a></h2><p>Prefect <a href="https://docs.prefect.io/orchestration/flow_config/storage.html#git" target="_blank" rel="noopener noreferrer">Git Storage</a> provides a workflow for developing and deploying data pipelines directly from git repositories,
such as Gitlab or Github.  The data pipeline code (python) is pulled from the git repository on each invocation
with the ability to reference git branches and git tags.  This approach enables:</p><ul><li>reducing the number of container images to the number of different runtime configurations to be supported.</li><li>improving the data engineering development cycle time by removing the need to build and push container images
on each code change.</li><li>when combined with kubernetes Prefect Run Configs and Job templates, enables selection of specific runtime environment images</li></ul><p>Note that the GitStorage option does required access from the runtime kubernetes cluster to the central git storage
service, e.g. gitlab, github, etc.</p><p>Prefect Git Storage workflow steps for &#x27;building&#x27; and deploying data pipeline flows include:</p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Steps</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">PlantUML</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><a target="_blank" href="/assets/files/image2-d57463bea4147ef77047e87d3b7a49a7.png"><img loading="lazy" alt="Workflow Steps" src="/assets/images/image2-d57463bea4147ef77047e87d3b7a49a7.png" width="253" height="361" class="img_ev3q"></a> </p></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@startuml &quot;git-storage-workflow&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(*) --&gt; &quot;push commited flow code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">changes to git service&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; &quot;register PrefectFlow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using branch or tag reference&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; &quot;run flow in Prefect Server or Cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(code pulled from git service)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt; (*)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@enduml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div><ul><li>pushing the committed code to the central git service</li><li>registering the flow using the git repository url and branch or tag reference</li><li>running the flow by pulling the reference code from the git service in a kubernetes pod</li></ul><p>The container image build and push steps are removed from the developer feedback cycle time.
Depending on network bandwidth and image build times, this can save remove 5 to 10 minutes from each deployment iteration.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pushing-the-flow-code">Pushing the flow code<a class="hash-link" href="#pushing-the-flow-code" title="Direct link to heading">​</a></h3><p>Once a set of changes to the data pipeline code has been committed, push to the central git service.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> commit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> push</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="registering-the-flow">Registering the flow<a class="hash-link" href="#registering-the-flow" title="Direct link to heading">​</a></h3><p>The flow can be registered with Prefect using either a branch (HEAD or latest) or tag reference.  Assuming
a workflow with feature branches:</p><ul><li>feature branches: register the flow code using the feature branch.  This enables the latest version (HEAD)
of the pushed flow code to be used for execution.  It also enables skipping re-registration of the flow on new
changes as the HEAD of the branch is pulled on each flow run</li><li>main line branches: register pinned versions of the flow using git tags.  This enables the use of a
specific version of the flow code to be pulled on each flow run, regardless of future changes.</li></ul><p>Determining the which reference to use:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># using gitpython module to work with repo info</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> git </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Repo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># presidence for identifing where to find the flow code</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># BUILD_TAG =&gt; GIT_BRANCH =&gt; active_branch</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">build_tag </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> branch_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">build_tag </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">getenv</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;BUILD_TAG&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> build_tag </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  branch_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">getenv</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;GIT_BRANCH&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> branch_name </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    branch_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Repo</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">getcwd</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">active_branch</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Configuring Prefect Git storage:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> prefect</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">storage </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> my_flows</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">hello_flow </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> flow </span><span class="token comment" style="color:#999988;font-style:italic"># assuming flow is defined in ./my_flows/flow.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># example using Gitlab</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># either branch_name or tag must be empty string &quot;&quot; or None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">storage </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Git</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repo_host</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">git_hostname</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repo</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">repo_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    flow_path</span><span class="token operator" style="color:#393A34">=</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">flow</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">__name__</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">replace</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation string" style="color:#e3116c">&#x27;.&#x27;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">,</span><span class="token string-interpolation interpolation string" style="color:#e3116c">&#x27;/&#x27;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">.py&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    flow_name</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    branch_name</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">branch_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tag</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">build_tag</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    git_token_secret_name</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">git_token_secret_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    git_token_username</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">git_token_username</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">storage</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">add_flow</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">storage </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> storage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">regsiter</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">build</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once registered, the flow storage details can be viewed in the Prefect Server or Prefect Cloud UI.  In this example, Prefect will use the <code>HEAD</code> version of the <code>main</code> branch on each flow run.</p><p><a target="_blank" href="/assets/files/flow-storage-details-e2be96914a590e405cacb47ffc0eceaa.png"><img loading="lazy" alt="hello flow storage details" src="/assets/images/flow-storage-details-e2be96914a590e405cacb47ffc0eceaa.png" width="678" height="339" class="img_ev3q"></a></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="next-steps---run-config">Next Steps - Run Config<a class="hash-link" href="#next-steps---run-config" title="Direct link to heading">​</a></h2><p>With Prefect Git Storage the runtime configuration and environment management is decoupled from the
data pipeline development workflow.  Unlike with Docker Storage, with Git Storage, the runtime
execution environment and data pipeline development workflows are defined and managed separately.
As an added benefit, the developer feedback loop cycle time is also reduced.</p><p>With the data engineering workflow addressed, the next step in scaling out the Prefect solution
turns to configuration and lifecycle management of the runtime environment for data pipelines.
Prefect Run Configs and Job templates provide the tools retaining the flexibility on container
image based runtime environments with improved manageability.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/prefect">prefect</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/gitlab">gitlab</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/docker">docker</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/etl">etl</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/images/spark-sql-etl-framework.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/multi-stage-etl-framework-using-spark-sql">Multi Stage ETL Framework using Spark SQL</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2019-01-09T00:00:00.000Z" itemprop="datePublished">January 9, 2019</time> · <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="Spark SQL ETL Framework" src="/assets/images/spark-sql-etl-framework-7491c174dee5cda2a37f00480d593b80.png" width="451" height="223" class="img_ev3q"></p><p>Most traditional data warehouse or datamart ETL routines consist of multi stage SQL transformations, often a series of CTAS (<code>CREATE TABLE AS SELECT</code>) statements usually creating transient or temporary tables – such as volatile tables in Teradata or Common Table Expressions (CTE’s).</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</div><div class="admonitionContent_S0QG"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The initial challenge when moving from a SQL/MPP based ETL framework platformed on Oracle, Teradata, SQL Server, etc to a Spark based ETL framework is what to do with this…</p><p><img loading="lazy" alt="Multi Stage SQL Based ETL" src="/assets/images/multi-stage-sql-1b6298de71ac35e0ecde3af82a831be6.png" width="736" height="805" class="img_ev3q"></p><p>One approach is to use the lightweight, configuration driven, multi stage Spark SQL based ETL framework described in this post.</p><p>This framework is driven from a YAML configuration document. YAML was preferred over JSON as a document format as it allows for multi-line statements (SQL statements), as well as comments - which are very useful as SQL can sometimes be undecipherable even for the person that wrote it.</p><p>The YAML config document has three main sections: <strong><code>sources</code></strong>, <strong><code>transforms</code></strong> and <strong><code>targets</code></strong>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sources">Sources<a class="hash-link" href="#sources" title="Direct link to heading">​</a></h3><p>The <strong><code>sources</code></strong> section is used to configure the input data source(s) including optional column and row filters. In this case the data sources are tables available in the Spark catalog (for instance the AWS Glue Catalog or a Hive Metastore), this could easily be extended to read from other datasources using the Spark DataFrameReader API.</p><iframe width="100%" frameborder="0" id="gist-eaf03229466718ee125e0a6d23370f1b"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="transforms">Transforms<a class="hash-link" href="#transforms" title="Direct link to heading">​</a></h3><p>The <strong><code>transforms</code></strong> section contains the multiple SQL statements to be run in sequence where each statement creates a temporary view using objects created by preceding statements.</p><iframe width="100%" frameborder="0" id="gist-89ad7ac6b036e5f22b2d3dec43b1fe44"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="targets">Targets<a class="hash-link" href="#targets" title="Direct link to heading">​</a></h3><p>Finally the <strong><code>targets</code></strong> section writes out the final object or objects to a specified destination (S3, HDFS, etc).</p><iframe width="100%" frameborder="0" id="gist-5af780dd6b6e5ddd79a4cac8a59e6a69"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="process-sql-statements">Process SQL Statements<a class="hash-link" href="#process-sql-statements" title="Direct link to heading">​</a></h3><p>The <strong><code>process_sql_statements.py</code></strong> script that is used to execute the framework is very simple (30 lines of code not including comments, etc). It loads the sources into Spark Dataframes and then creates temporary views to reference these datasets in the <strong><code>transforms</code></strong> section, then sequentially executes the SQL statements in the list of transforms. Lastly the script writes out the final view or views to the desired destination – in this case parquet files stored in S3 were used as the target.</p><p>You could implement an object naming convention such as prefixing object names with <code>sv_</code>, <code>iv_</code>, <code>fv_</code> (for source view, intermediate view and final view respectively) if this helps you differentiate between the different objects.</p><p>To use this framework you would simply use <strong><code>spark-submit</code></strong> as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit process_sql_statements.py config.yml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/spark-sql-etl-framework" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/spark-sql-etl-framework</strong></a></em></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/etl">etl</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/sql">sql</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">StackQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.windrate.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">WindRate<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.fa9202be.js"></script>
<script src="/assets/js/main.a1cf5441.js"></script>
</body>
</html>