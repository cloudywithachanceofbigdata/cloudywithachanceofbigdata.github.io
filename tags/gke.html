<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Cloudy with a chance of Big Data Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Cloudy with a chance of Big Data Blog Feed Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4N6KSJ2G0P"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-4N6KSJ2G0P",{})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Cloudy with a chance of Big Data" href="/opensearch.xml"><title data-react-helmet="true">One post tagged with &quot;gke&quot; | Cloudy with a chance of Big Data</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;gke&quot; | Cloudy with a chance of Big Data"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://cloudywithachanceofbigdata.com/tags/gke"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://cloudywithachanceofbigdata.com/tags/gke"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/tags/gke" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/tags/gke" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d8b73325.css">
<link rel="preload" href="/assets/js/runtime~main.be9d500d.js" as="script">
<link rel="preload" href="/assets/js/main.2a4c0142.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_2qcr"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title">Cloudy with a chance of Big Data</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link" href="/tags">Topics</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_71bT toggle_3Zt9 toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">ðŸŒœ</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">ðŸŒž</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/aws-deployments-with-cloudformation-and-gitlab-ci">Simplified AWS Deployments with CloudFormation and GitLab CI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/from-wordpress-to-jamstack">From Wordpress to Jamstack</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/using-jsonnet-to-configure-multiple-environments">Using Jsonnet to Configure Multiple Environments</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/use-bigquery-to-trigger-cloud-run">Use BigQuery to trigger Cloud Run</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/azure-static-web-app-review">Azure Static Web App Review</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/introducing-the-metadata-hub-mdh">Introducing the Metadata Hub (MDH)</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/masking-private-keys-in-ci-cd-pipelines-in-gitlab">Masking Private Keys in CI/CD Pipelines in GitLab</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simple-tasker-configuration-driven-orchestration">Simple Tasker: Configuration driven orchestration</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/okta-admin-command-line-interface">Okta Admin Command Line Interface</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/enumerating-all-roles-for-a-user-in-snowflake">Enumerating all roles for a user in Snowflake</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;gke&quot;</h1><a href="/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/spark-in-the-google-cloud-platform-part-2">Spark in the Google Cloud Platform Part 2</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2020-02-29T00:00:00.000Z" itemprop="datePublished">February 29, 2020</time> Â· <!-- -->5 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/spark-gcp-featured-image.png"><div class="markdown" itemprop="articleBody"><p>In the previous post in this series <a href="https://cloudywithachanceofbigdata.com/spark-in-the-google-cloud-platform-part-1/" target="_blank" rel="noopener noreferrer"><strong>Spark in the Google Cloud Platform Part 1</strong></a>, we started to explore the various ways in which we could deploy Apache Spark applications in GCP. The first option we looked at was deploying Spark using Cloud DataProc, a managed Hadoop cluster with various ecosystem components included.</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</h5></div><div class="admonition-content"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>In this post, we will look at another option for deploying Spark in GCP â€“ <em>a Spark Standalone cluster running on GKE</em>.</p><p>Spark Standalone refers to the in-built cluster manager provided with each Spark release. Standalone can be a bit of a misnomer as it sounds like a single instance â€“ which it is not, standalone simply refers to the fact that it is not dependent upon any other projects or components â€“ such as Apache YARN, Mesos, etc.</p><p>A Spark Standalone cluster consists of a Master node or instance and one of more Worker nodes. The Master node serves as both a master and a cluster manager in the Spark runtime architecture.</p><p>The Master process is responsible for marshalling resource requests on behalf of applications and monitoring cluster resources.</p><p>The Worker nodes host one or many Executor instances which are responsible for carrying out tasks.</p><p>Deploying a Spark Standalone cluster on GKE is reasonably straightforward. In the example provided in this post we will set up a private network (VPC), create a GKE cluster, and deploy a Spark Master pod and two Spark Worker pods (in a real scenario you would typically have many Worker pods).</p><p>Once the network and GKE cluster have been deployed, the first step is to create Docker images for both the Master and Workers.</p><p>The <code>Dockerfile</code> below can be used to create an image capable or running either the Worker or Master daemons:</p><iframe width="100%" frameborder="0" id="gist-a2828409021205b3f6587c824c59928d"></iframe><p>Note the shell scripts included in the <code>Dockerfile</code>: <code>spark-master</code> and <code>spark-worker</code>. These will be used later on by K8S deployments to start the relative Master and Worker daemon processes in each of the pods.</p><p>Next, we will use Cloud Build to build an image using the <code>Dockerfile</code> are store this in GCR (Google Container Registry), from the Cloud Build directory in our project we will run:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud builds submit --tag gcr.io/spark-demo-266309/spark-standalone</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Next, we will create Kubernetes deployments for our Master and Worker pods.</p><p>Firstly, we need to get cluster credentials for our GKE cluster named â€˜spark-clusterâ€™:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud container clusters get-credentials spark-cluster --zone australia-southeast1-a --project spark-demo-266309</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now from within the <code>k8s-deployments\deploy</code> folder of our project we will use the <code>kubectl</code> command to deploy the Master pod, service and the Worker pods</p><p>Starting with the Master deployment, this will deploy our Spark Standalone image into a container running the Master daemon process:</p><iframe width="100%" frameborder="0" id="gist-31bca11627167e0cd963103e4c7f11d2"></iframe><p>To deploy the Master, run the following:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-master-deployment.yaml</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>The Master will expose a web UI on port 8080 and an RPC service on port 7077, we will need to deploy a K8S service for this, the YAML required to do this is shown here:</p><iframe width="100%" frameborder="0" id="gist-a72d3c38d7a3f94e88c7affd28a3034b"></iframe><p>To deploy the Master service, run the following:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-master-service.yaml</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now that we have a Master pod and service up and running, we need to deploy our Workers which are preconfigured to communicate with the Master service.</p><p>The YAML required to deploy the two Worker pods is shown here:</p><iframe width="100%" frameborder="0" id="gist-97ceb93ed35959c41d80fb8c025a7ba1"></iframe><p>To deploy the Worker pods, run the following:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-worker-deployment.yaml</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>You can now inspect the Spark processes running on your GKE cluster.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deployments</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Shows...</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-master   1/1     1            1           7m45s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker   2/2     2            2           9s</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Shows...</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                            READY   STATUS    RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-master-f69d7d9bc-7jgmj    1/1     Running   0          8m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker-55965f669c-rm59p   1/1     Running   0          24s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker-55965f669c-wsb2f   1/1     Running   0          24s</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Next, as we need to expose the Web UI for the Master process we will create a <em>LoadBalancer</em> resource. The YAML used to do this is provided here:</p><iframe width="100%" frameborder="0" id="gist-56ee86f50f329f99679ff243bb00fb07"></iframe><p>To deploy the LB, you would run the following:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-ui-lb.yaml</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p><strong>NOTE</strong> This is just an example, for simplicity we are creating an external <em>LoadBalancer</em> with a public IP, this configuration is likely not be appropriate in most real scenarios, alternatives would include an internal <em>LoadBalancer</em>, retraction of Authorized Networks, a jump host, SSH tunnelling or IAP.</p><p>Now youâ€™re up and running!</p><p>You can access the Master web UI from the Google Console link shown here:</p><p><a target="_blank" href="/assets/files/master-ui-link-c9d78a7032459c01291494b1c26e34ff.png"><img alt="Accessing the Spark Master UI from the Google Cloud Console" src="/assets/images/master-ui-link-c9d78a7032459c01291494b1c26e34ff.png"></a></p><p>The Spark Master UI should look like this:</p><p><a target="_blank" href="/assets/files/spark-master-ui-fa6eecc91847995dea15601166516004.png"><img alt="Spark Master UI" src="/assets/images/spark-master-ui-fa6eecc91847995dea15601166516004.png"></a></p><p>Next we will exec into a Worker pod, get a shell:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec -it spark-worker-55965f669c-rm59p -- sh</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now from within the shell environment of a Worker â€“ which includes all of the Spark client libraries, we will submit a simple Spark application:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --class org.apache.spark.examples.SparkPi \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> --master spark://10.11.250.98:7077 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/opt/spark/examples/jars/spark-examples*.jar 10000</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>You can see the results in the shell, as shown here:</p><p><a target="_blank" href="/assets/files/spark-application-example-0f11e071394077ac8c678ed7d3e93791.png"><img alt="Spark Pi Estimator Example" src="/assets/images/spark-application-example-0f11e071394077ac8c678ed7d3e93791.png"></a></p><p>Additionally, as all of the container logs go to Stackdriver, you can view the application logs there as well:</p><p><a target="_blank" href="/assets/files/container-logs-in-stackdriver-350797a4dd5cceab0b4aa12445adeed4.png"><img alt="Container Logs in StackDriver" src="/assets/images/container-logs-in-stackdriver-350797a4dd5cceab0b4aa12445adeed4.png"></a></p><p>This is a simple way to get a Spark cluster running, it is not without its downsides and shortcomings however, which include the limited security mechanisms available (SASL, network security, shared secrets).</p><p>In the final post in this series we will look at Spark on Kubernetes, using Kubernetes as the Spark cluster manager and interacting with Spark using the Kubernetes API and control plane, see you then.</p><blockquote><p>Full source code for this article is available at: <a href="https://github.com/gamma-data/spark-on-gcp" target="_blank" rel="noopener noreferrer">https://github.com/gamma-data/spark-on-gcp</a></p></blockquote><p>The infrastructure coding for this example uses Powershell and Terraform, and is deployed as follows:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly powershell"><pre tabindex="0" class="prism-code language-powershell codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">PS &gt; .\run.ps1 private-network apply &lt;gcp-project&gt; &lt;region&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PS &gt; .\run.ps1 gke apply &lt;gcp-project&gt; &lt;region&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/apache-spark">apache-spark</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/cloud-dataproc">cloud-dataproc</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/dataproc">dataproc</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/gcp">gcp</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/gke">gke</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/googlecloudplatform">googlecloudplatform</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/kubernetes">kubernetes</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/spark">spark</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Spark in the Google Cloud Platform Part 2" href="/spark-in-the-google-cloud-platform-part-2"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items"><li class="footer__item"><a href="https://infraql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>InfraQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/assets/js/runtime~main.be9d500d.js"></script>
<script src="/assets/js/main.2a4c0142.js"></script>
</body>
</html>