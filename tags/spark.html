<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">7 posts tagged with &quot;spark&quot; | Full Stack Chronicles</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" name="twitter:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" property="og:url" content="https://fullstackchronicles.io/tags/spark"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="twitter:site" content="@fschronicles1"><meta data-rh="true" name="twitter:creator" content="@fschronicles1"><meta data-rh="true" name="og:type" content="website"><meta data-rh="true" name="og:locale" content="en_US"><meta data-rh="true" name="og:site_name" content="Full Stack Chronicles"><meta data-rh="true" name="msapplication-TileColor" content="#2d89ef"><meta data-rh="true" name="theme-color" content="#ffffff"><meta data-rh="true" property="og:title" content="7 posts tagged with &quot;spark&quot; | Full Stack Chronicles"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/favicon.ico"><link data-rh="true" rel="canonical" href="https://fullstackchronicles.io/tags/spark"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/spark" hreflang="en"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/spark" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MZCGVO503N-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Full Stack Chronicles Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Full Stack Chronicles Blog Feed Atom Feed">
<link rel="alternate" type="application/json" href="/feed.json" title="Full Stack Chronicles Blog Feed JSON Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FVDC1E8G6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0FVDC1E8G6",{})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Full Stack Chronicles" href="/opensearch.xml">


<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0f4c81"><link rel="stylesheet" href="/assets/css/styles.5ea58133.css">
<link rel="preload" href="/assets/js/runtime~main.80d85236.js" as="script">
<link rel="preload" href="/assets/js/main.563a43d5.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ navbar--primary"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Full Stack Chronicles</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/tags">Topics</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/snowflake">Snowflake</a></li><li><a class="dropdown__link" href="/tags/okta">Okta</a></li><li><a class="dropdown__link" href="/tags/openapi">OpenAPI</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags/spark">Spark</a></li><li><a class="dropdown__link" href="/tags/kafka">Kafka</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/gitver-an-alternative-versioning-scheme-to-semver-or-calver">Introducing GitVer - an alternative versioning scheme</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/use-deno-deploy-to-serve-non-traditional-artifacts">Use Deno Deploy to Serve Non-Traditional Artifacts</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/apache-beam-in-five-minutes">Apache Beam in Five Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/aws-iam-vs-google-iam">AWS IAM vs Google IAM</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/create-and-use-custom-magic-commands-in-jupyter">Create and use Custom Magic Commands in Jupyter</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/deno-in-five-minutes">Deno in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dbt-in-five-minutes">DBT in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/loading-parquet-files-into-snowflake">Loading Parquet Files into Snowflake</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/analyze-developer-activity-with-stackql-jupyter-bigquery">Analyze Developer Activity with StackQL, Jupyter and BigQuery</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/converting-google-discovery-docs-to-openapi3-specs">Converting Google Discovery Docs to OpenAPI3 Specs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/recurse-javascript-object-to-get-values-for-a-given-key-the-easy-way">Recurse JavaScript Object to Get Values for a Given Key the Easy Way</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dataops-with-container-images-and-multi-stage-builds">DataOps with Container Images and Multi-Stage Builds</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/using-the-snowflake-sql-api-with-typescript">Using the Snowflake SQL API with TypeScript</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/split-a-large-swagger-openapi-specification-into-smaller-documents">Split a large Open API or Swagger Specification into smaller documents</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/stream-processing-with-spark-structured-streaming-kafka-and-snowflake-using-python">Stream Processing with Spark Structured Streaming, Kafka and Snowflake using Python</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>7 posts tagged with &quot;spark&quot;</h1><a href="/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/blog/parquet-to-snowflake.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/loading-parquet-files-into-snowflake">Loading Parquet Files into Snowflake</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-07-30T00:00:00.000Z" itemprop="datePublished">July 30, 2022</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Loading Parquet format files into BigQuery is straightforward, you just need to specify the file location (local, Google Cloud Storage, Drive, Amazon S3 or Azure Blob storage) and thats pretty much it, BigQuery works the rest out from there.  </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bq load \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--location=australia-southeast2 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--project_id=parquet-demo \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--source_format=PARQUET \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">parquet_test.dim_calendar \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">.\Calendar.gzip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In Snowflake, however, it is not as simple, I&#x27;ll share my approach to automating this here.  </p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>Parquet is a self-describing, column-oriented storage format commonly used in distributed systems for input and output.  Data in Parquet files is serialised for optimised consumption from Parquet client libraries and packages such as <code>pandas</code>, <code>pyarrow</code>, <code>fastparquet</code>, <code>dask</code>, and <code>pyspark</code>.</p></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="background">Background<a class="hash-link" href="#background" title="Direct link to heading">​</a></h2><p>Data in a Parquet file is stored in a single column for a self-contained dataset.  If you were to ingest this into Snowflake without knowing the schema you could do something like this...   </p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">OR</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">REPLACE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">TABLE</span><span class="token plain"> PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">Data</span><span class="token plain"> variant</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY </span><span class="token keyword" style="color:#00009f">INTO</span><span class="token plain"> PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">Data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">*</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token variable" style="color:#36acaa">@PARQUET_TEST.PUBLIC.DIM_CALENDAR_STAGE</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  file_format </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">TYPE</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parquet</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You would end up with something like...   </p><table><thead><tr><th><code>Row</code></th><th><code>Data</code></th></tr></thead><tbody><tr><td><code>1</code></td><td><code>{&quot;CalMonthOfYearNo&quot;: 6, &quot;CalYear&quot;: 2020, ... }</code></td></tr><tr><td><code>2</code></td><td><code>{&quot;CalMonthOfYearNo&quot;: 6, &quot;CalYear&quot;: 2020, ... }</code></td></tr><tr><td><code>...</code></td><td><code>...</code></td></tr></tbody></table><p>You could then have a second stage of processing to convert this into a normal relational structure.  </p><p>Or you could do this in one step, with a little prep work ahead of time.  In my scenario I was given several parquet files from a client for a one-off load into Snowflake, several files for a fact table and multiple single files representing different dimension tables.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="streamlined-ingestion-for-parquet-files-into-snowflake">Streamlined Ingestion for Parquet Files into Snowflake<a class="hash-link" href="#streamlined-ingestion-for-parquet-files-into-snowflake" title="Direct link to heading">​</a></h2><p>To collapse the formatting and uploading of Parquet files into a materialized table into one step, we need to do a couple of things:  </p><ol><li>Create the target table with the correct schema (column names and data types); and</li><li>perform a projection in our <code>COPY</code> command from the single column containing all of the data (represented by <code>$1</code> in Snowflake) into columns defined in step 1</li></ol><p>Since this is technically a transformation and only named stages are supported for <code>COPY</code> transformations, we need to create a stage for the copy.  In my case there is a pre-existing Storage Integration in place that can be used by the stage.  </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="generate-table-ddl">Generate Table DDL<a class="hash-link" href="#generate-table-ddl" title="Direct link to heading">​</a></h3><p>To automate the generation of the DDL to create the table and stage and the <code>COPY</code> command, I used Python and Spark (which has first class support for Parquet files).  Parquet datatypes are largely the same as Snowflake, but if we needed to, we could create a map and modify the target types during the DDL generation.  </p><p>First copy specimen Parquet formatted files to a local directory, the script we are creating can then iterate through the parquet files and generate all of the commands we will need saved to a <code>.sql</code> file.  </p><p>With some setup information provided (not shown for brevity), we will first go through each file in the directory, capture metadata along with the schema (column name and data type) as shown here:  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> </span><span class="token builtin">file</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> files</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    table </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">file</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">stem</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spark </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> launch_spark_session</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parquetFile </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> spark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">read</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">parquet</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;%s/%s&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BASE_DIR</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">file</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_types </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parquetFile</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dtypes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stop_spark_session</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">spark</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> table</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;file&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">file</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;data_types&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> data_types</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    allTables</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tableMap</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The <code>allTables</code> list looks something like this...  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Calendar&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;file&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> PosixPath</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;data/dim/Calendar.gzip&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;data_types&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;Time_ID&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;bigint&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;CalYear&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;bigint&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;CalMonthOfYearNo&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;bigint&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;FinYear&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;bigint&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;FinWeekOfYearNo&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;bigint&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next we generate the <code>CREATE TABLE</code> statement using the <code>allTables</code> list:  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># create output file for all sql</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> </span><span class="token builtin">open</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;all_tables.sql&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;w&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> f</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> table </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> allTables</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;processing %s...&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;/*** Create %s Table***/&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">CREATE OR REPLACE TABLE %s.%s.%s (</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">database</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> schema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> column </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;data_types&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;  %s %s,\n&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">column</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> column</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sql</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;\n);&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;\n\n&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="generate-named-stage-ddl">Generate Named Stage DDL<a class="hash-link" href="#generate-named-stage-ddl" title="Direct link to heading">​</a></h3><p>Then we generate the stage in S3 from which the files will be loaded:  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;/*** Create %s Stage***/&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">CREATE OR REPLACE STAGE %s.%s.%s_STAGE </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  url=&#x27;%s/%s&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  storage_integration = %s</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  encryption=(type=&#x27;AWS_SSE_KMS&#x27; kms_key_id = &#x27;%s&#x27;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">database</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> schema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> s3_prefix</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;file&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> storage_int</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kms_key_id</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;\n\n&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="generate-copy-commands">Generate <code>COPY</code> commands<a class="hash-link" href="#generate-copy-commands" title="Direct link to heading">​</a></h3><p>Then we generate the <code>COPY</code> commands...  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;/*** Copying Data into %s ***/&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">COPY INTO %s.%s.%s </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">(\n&quot;&quot;&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">database</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> schema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> column </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;data_types&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;  %s,\n&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> column</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sql</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;\n)&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot; FROM (\nSELECT\n&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> column </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;data_types&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;  $1:%s::%s,\n&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">column</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> column</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sql</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;\nFROM\n&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;@%s.%s.%s_STAGE)\n&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">database</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> schema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;  file_format = (TYPE = parquet);&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;\n\n&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Since this is a one off load, we will go ahead and drop the stage we created as it is no longer needed (this step is optional)..</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;/*** Dropping stage for %s ***/&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">DROP STAGE %s.%s.%s_STAGE; </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">database</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> schema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> table</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;\n\n&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The resultant file created looks like this..</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">/*** Create CALENDAR Table***/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">OR</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">REPLACE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">TABLE</span><span class="token plain"> PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Time_ID </span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  CalYear </span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  CalMonthOfYearNo </span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  FinYear </span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  FinWeekOfYearNo </span><span class="token keyword" style="color:#00009f">bigint</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">/*** Create DIM_CALENDAR Stage***/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">OR</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">REPLACE</span><span class="token plain"> STAGE PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR_STAGE </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  url</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;s3://my-bucket/data/dim/Calendar.gzip&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  storage_integration </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> my_storage_int</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  encryption</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">type</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;AWS_SSE_KMS&#x27;</span><span class="token plain"> kms_key_id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;4f715ec9-ee8e-44ab-b35d-8daf36c05f19&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">/*** Copying Data into DIM_CALENDAR ***/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY </span><span class="token keyword" style="color:#00009f">INTO</span><span class="token plain"> PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Time_ID</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  CalYear</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  CalMonthOfYearNo</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  FinYear</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  FinWeekOfYearNo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  $</span><span class="token number" style="color:#36acaa">1</span><span class="token plain">:Time_ID::</span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  $</span><span class="token number" style="color:#36acaa">1</span><span class="token plain">:CalYear::</span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  $</span><span class="token number" style="color:#36acaa">1</span><span class="token plain">:CalMonthOfYearNo::</span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  $</span><span class="token number" style="color:#36acaa">1</span><span class="token plain">:FinYear::</span><span class="token keyword" style="color:#00009f">bigint</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  $</span><span class="token number" style="color:#36acaa">1</span><span class="token plain">:FinWeekOfYearNo::</span><span class="token keyword" style="color:#00009f">bigint</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token variable" style="color:#36acaa">@PARQUET_TEST.PUBLIC.DIM_CALENDAR_STAGE</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  file_format </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">TYPE</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parquet</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">/*** Dropping stage for DIM_CALENDAR ***/</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">DROP</span><span class="token plain"> STAGE PARQUET_TEST</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">PUBLIC</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DIM_CALENDAR_STAGE</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="load-your-data">Load your data<a class="hash-link" href="#load-your-data" title="Direct link to heading">​</a></h3><p>You can then run this along with all of the other dimension and fact table DDL and COPY commands generated to perform the one-off load from parquet files. You can find the complete code below, enjoy!  </p><details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Complete Code</summary><div><div class="collapsibleContent_i85q"><pre tabindex="0" class="codeBlockStandalone_MEMb thin-scrollbar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><code class="codeBlockLines_e6Vv">from pathlib import Path<br>from pyspark.sql import SparkSession</code></pre><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def launch_spark_session():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return SparkSession \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .builder \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .appName(&quot;Parquet DDL Generation&quot;) \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def stop_spark_session(spark):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spark.stop()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">allTables = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">database = &quot;PARQUET_TEST&quot; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">schema = &quot;PUBLIC&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s3_prefix = &#x27;s3://my-bucket&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">storage_int = &#x27;my_storage_int&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kms_key_id = &#x27;4f715ec9-ee8e-44ab-b35d-8daf36c05f19&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BASE_DIR = Path(__file__).resolve().parent</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">directory = &#x27;data/dim&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">files = Path(directory).glob(&#x27;*.gzip&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for file in files:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap = {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    table = file.stem</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spark = launch_spark_session()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parquetFile = spark.read.parquet(&quot;%s/%s&quot; %(BASE_DIR, file))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_types = parquetFile.dtypes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stop_spark_session(spark)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap[&#x27;name&#x27;] = table</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap[&#x27;file&#x27;] = file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tableMap[&#x27;data_types&#x27;] = data_types</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    allTables.append(tableMap)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># create output file for all sql</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with open(&#x27;all_tables.sql&#x27;, &#x27;w&#x27;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for table in allTables:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&quot;processing %s...&quot; % table[&#x27;name&#x27;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;/*** Create %s Table***/&quot; % table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CREATE OR REPLACE TABLE %s.%s.%s (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot; % (database, schema, table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for column in table[&#x27;data_types&#x27;]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql += &quot;  %s %s,\n&quot; % (column[0], column[1])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = sql[:-2] + &quot;\n);&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(sql)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;\n\n&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;/*** Create %s Stage***/&quot; % table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CREATE OR REPLACE STAGE %s.%s.%s_STAGE </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  url=&#x27;%s/%s&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  storage_integration = %s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  encryption=(type=&#x27;AWS_SSE_KMS&#x27; kms_key_id = &#x27;%s&#x27;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot; % (database, schema, table[&#x27;name&#x27;].upper(), s3_prefix, table[&#x27;file&#x27;], storage_int, kms_key_id)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(sql)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;\n\n&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;/*** Copying Data into %s ***/&quot; % table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">COPY INTO %s.%s.%s </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(\n&quot;&quot;&quot; % (database, schema, table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for column in table[&#x27;data_types&#x27;]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql += &quot;  %s,\n&quot; % column[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = sql[:-2] + &quot;\n)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql += &quot; FROM (\nSELECT\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for column in table[&#x27;data_types&#x27;]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sql += &quot;  $1:%s::%s,\n&quot; % (column[0], column[1])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = sql[:-2] + &quot;\nFROM\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql += &quot;@%s.%s.%s_STAGE)\n&quot; % (database, schema, table[&#x27;name&#x27;].upper()) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql += &quot;  file_format = (TYPE = parquet);&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(sql)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;\n\n&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;/*** Dropping stage for %s ***/&quot; % table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sql = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DROP STAGE %s.%s.%s_STAGE; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot; % (database, schema, table[&#x27;name&#x27;].upper())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(sql)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f.write(&quot;\n\n&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></details></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/snowflake">snowflake</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/parquet">parquet</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/python">python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/pyspark">pyspark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/bigquery">bigquery</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/blog/kafka-spark-snowflake.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/stream-processing-with-spark-structured-streaming-kafka-and-snowflake-using-python">Stream Processing with Spark Structured Streaming, Kafka and Snowflake using Python</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2022-04-28T00:00:00.000Z" itemprop="datePublished">April 28, 2022</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Structured Streaming in Spark provides a powerful framework for stream processing an analysis, such as streaming transformations, stateful streaming or sliding window operations.  </p><p>Kafka is a common streaming source and sink for Spark Streaming and Structured Streaming operations.  However, there may be situations where a data warehouse (such as Snowflake) is a more appropriate target for streaming operations, especially where there is a reporting or long-term storage requirement on the data derived from the streaming source.  </p><p>This article will demonstrate just how easy this is to implement using Python.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="design">Design<a class="hash-link" href="#design" title="Direct link to heading">​</a></h2><p>The following diagram illustrates the ingestion design for this example:  </p><p><a target="_blank" href="/assets/files/spark-streaming-kafka-snowflake-5b6babb75a8da1443183fabc68c704a1.png"><img loading="lazy" alt="Spark Structured Streaming using Kafka and Snowflake" src="/assets/images/spark-streaming-kafka-snowflake-5b6babb75a8da1443183fabc68c704a1.png" width="948" height="390" class="img_ev3q"></a></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="snowflake-setup">Snowflake Setup<a class="hash-link" href="#snowflake-setup" title="Direct link to heading">​</a></h2><p>Some prerequisites for Snowflake:  </p><ol><li>You will need to create a user (or use an existing user), in either case the user will need to be identified by a private key.  You will need to generate a key pair as follows:  </li></ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">openssl genrsa </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> openssl pkcs8 -topk8 -inform PEM -out rsa_key.p8 -nocrypt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openssl rsa -in rsa_key.p8 -pubout -out rsa_key.pub</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>copy the contents of the <code>rsa_key.pub</code> file, remove the <code>-----BEGIN PUBLIC KEY-----</code> and <code>-----END PUBLIC KEY-----</code> strings, then remove the line breaks to form one string, use this string as the <code>RSA_PUBLIC_KEY</code> in a <code>CREATE USER</code> or <code>ALTER USER</code> statement in Snowflake, like:  </p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">ALTER</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">USER</span><span class="token plain"> youruser </span><span class="token keyword" style="color:#00009f">SET</span><span class="token plain"> RSA_PUBLIC_KEY</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;MIIBI...&#x27;</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="2"><li>Now setup the target database, schema and table you will use to write out your stream data (the schema for the table must match the schema for the Data Stream you will use the <code>DataStreamWriter</code> to emit records to Snowflake  </li></ol><p>The user you will be using (that you setup the key pair authentication for) will need to be assigned a default role to which the appropriate write permissions are granted to the target objects in Snowflake.  You will also need to designate a virtual warehouse (which your user must have <code>USAGE</code> permissions to.  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-code">The Code<a class="hash-link" href="#the-code" title="Direct link to heading">​</a></h2><p>Now that we have the objects and user setup in Snowflake, we can construct our Spark application.  </p><p>First, you will need to start your Spark session (either using <code>pyspark</code> or <code>spark-submit</code>) including the packages that Spark will need to connect to Kafka and to Snowflake.  </p><p>The Snowflake packages include a JDBC driver and the Snowflake Connector for Spark, see <a href="https://docs.snowflake.com/en/user-guide/spark-connector.html" target="_blank" rel="noopener noreferrer">Snowflake Connector for Spark</a>.  </p><p>An example is shown here (package versions may vary depending upon the version of Spark you are using):  </p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pyspark </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--packages </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">net.snowflake:snowflake-jdbc:3.13.14,</span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">net.snowflake:spark-snowflake_2.12:2.10.0-spark_3.1,</span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now that we have a spark session with the necessary packages, lets go...  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># import any required functions, set the checkpoint directory, and log level (optional)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pyspark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">functions </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> split</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sparkContext</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">setLogLevel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;ERROR&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conf</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">set</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;spark.sql.streaming.checkpointLocation&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;file:///tmp&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>setup connection options for Snowflake by creating an <code>sfOptions</code> dictionary  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sfOptions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;sfURL&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> sfUrl</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;sfUser&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;avensolutions&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;pem_private_key&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> private_key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;sfDatabase&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;SPARK_SNOWFLAKE_DEMO&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;sfSchema&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;PUBLIC&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;sfWarehouse&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;COMPUTE_WH&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token string" style="color:#e3116c">&quot;streaming_stage&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;mystage&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>set a variable for the Snowflake Spark connector  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SNOWFLAKE_SOURCE_NAME </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;net.snowflake.spark.snowflake&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>read messages from Kafka:    </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">lines </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> spark \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">readStream \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">format</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;kafka&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">option</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;kafka.bootstrap.servers&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;kafkabroker:9092&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">option</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;subscribe&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;weblogs&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>perform necessary transformations (the fields and data types in the resultant data structure must match the target table you created in Snowflake:  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">log_recs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> lines</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">select</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">lines</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">value</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cast</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;string&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot; &quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">alias</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;data&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> log_recs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">selectExpr</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[0] as string) as date&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[1] as string) as time&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[2] as string) as c_ip&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[3] as string) as cs_username&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[4] as string) as s_sitename&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[5] as string) as s_computername&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[6] as string) as s_ip&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[7] as int) as s_port&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[8] as string) as cs_method&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[9] as string) as cs_uri_stem&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[10] as string) as cs_uri_query&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[11] as int) as sc_status&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[12] as int) as time_taken&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[13] as string) as cs_version&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[14] as string) as cs_host&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[15] as string) as User_Agent&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;CAST(data[16] as string) as Referer&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>write to Snowflake!  </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">query </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> log_data\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">writeStream\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">format</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">SNOWFLAKE_SOURCE_NAME</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">options</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">**</span><span class="token plain">sfOptions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">option</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;dbtable&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;WEB_LOGS&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">trigger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">processingTime</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;30 seconds&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">query</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">awaitTermination</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>Note that I have included the <code>processingTime</code> trigger of <code>30 seconds</code> (this is akin to the <code>batchInterval</code> in the DStream API), you should tune this to get a balance between batch sizes to ingest into Snowflake (which will benefit from larger batches) and latency.</p></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-results">The Results<a class="hash-link" href="#the-results" title="Direct link to heading">​</a></h2><p><a target="_blank" href="/assets/files/snowflake-screenshot-97a035bab5f113d5139441dde516099d.png"><img loading="lazy" alt="Spark Structured Streaming into Snowflake" src="/assets/images/snowflake-screenshot-97a035bab5f113d5139441dde516099d.png" width="1920" height="1040" class="img_ev3q"></a></p><p>Enjoy!</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/snowflake">snowflake</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/kafka">kafka</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/sql">sql</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/streaming">streaming</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/images/spark-gcp-featured-image.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/spark-in-the-google-cloud-platform-part-2">Spark in the Google Cloud Platform Part 2</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2020-02-29T00:00:00.000Z" itemprop="datePublished">February 29, 2020</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="Apache Spark in GCP" src="/assets/images/spark-gcp-featured-image-86e0bfd36db759253fff66591b594d8b.png" width="213" height="155" class="img_ev3q"></p><p>In the previous post in this series <a href="https://cloudywithachanceofbigdata.com/spark-in-the-google-cloud-platform-part-1/" target="_blank" rel="noopener noreferrer"><strong>Spark in the Google Cloud Platform Part 1</strong></a>, we started to explore the various ways in which we could deploy Apache Spark applications in GCP. The first option we looked at was deploying Spark using Cloud DataProc, a managed Hadoop cluster with various ecosystem components included.</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</div><div class="admonitionContent_S0QG"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>In this post, we will look at another option for deploying Spark in GCP – <em>a Spark Standalone cluster running on GKE</em>.</p><p>Spark Standalone refers to the in-built cluster manager provided with each Spark release. Standalone can be a bit of a misnomer as it sounds like a single instance – which it is not, standalone simply refers to the fact that it is not dependent upon any other projects or components – such as Apache YARN, Mesos, etc.</p><p>A Spark Standalone cluster consists of a Master node or instance and one of more Worker nodes. The Master node serves as both a master and a cluster manager in the Spark runtime architecture.</p><p>The Master process is responsible for marshalling resource requests on behalf of applications and monitoring cluster resources.</p><p>The Worker nodes host one or many Executor instances which are responsible for carrying out tasks.</p><p>Deploying a Spark Standalone cluster on GKE is reasonably straightforward. In the example provided in this post we will set up a private network (VPC), create a GKE cluster, and deploy a Spark Master pod and two Spark Worker pods (in a real scenario you would typically have many Worker pods).</p><p>Once the network and GKE cluster have been deployed, the first step is to create Docker images for both the Master and Workers.</p><p>The <code>Dockerfile</code> below can be used to create an image capable or running either the Worker or Master daemons:</p><iframe width="100%" frameborder="0" id="gist-a2828409021205b3f6587c824c59928d"></iframe><p>Note the shell scripts included in the <code>Dockerfile</code>: <code>spark-master</code> and <code>spark-worker</code>. These will be used later on by K8S deployments to start the relative Master and Worker daemon processes in each of the pods.</p><p>Next, we will use Cloud Build to build an image using the <code>Dockerfile</code> are store this in GCR (Google Container Registry), from the Cloud Build directory in our project we will run:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud builds submit --tag gcr.io/spark-demo-266309/spark-standalone</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next, we will create Kubernetes deployments for our Master and Worker pods.</p><p>Firstly, we need to get cluster credentials for our GKE cluster named ‘spark-cluster’:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud container clusters get-credentials spark-cluster --zone australia-southeast1-a --project spark-demo-266309</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now from within the <code>k8s-deployments\deploy</code> folder of our project we will use the <code>kubectl</code> command to deploy the Master pod, service and the Worker pods</p><p>Starting with the Master deployment, this will deploy our Spark Standalone image into a container running the Master daemon process:</p><iframe width="100%" frameborder="0" id="gist-31bca11627167e0cd963103e4c7f11d2"></iframe><p>To deploy the Master, run the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-master-deployment.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The Master will expose a web UI on port 8080 and an RPC service on port 7077, we will need to deploy a K8S service for this, the YAML required to do this is shown here:</p><iframe width="100%" frameborder="0" id="gist-a72d3c38d7a3f94e88c7affd28a3034b"></iframe><p>To deploy the Master service, run the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-master-service.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now that we have a Master pod and service up and running, we need to deploy our Workers which are preconfigured to communicate with the Master service.</p><p>The YAML required to deploy the two Worker pods is shown here:</p><iframe width="100%" frameborder="0" id="gist-97ceb93ed35959c41d80fb8c025a7ba1"></iframe><p>To deploy the Worker pods, run the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-worker-deployment.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You can now inspect the Spark processes running on your GKE cluster.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deployments</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Shows...</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-master   1/1     1            1           7m45s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker   2/2     2            2           9s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Shows...</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                            READY   STATUS    RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-master-f69d7d9bc-7jgmj    1/1     Running   0          8m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker-55965f669c-rm59p   1/1     Running   0          24s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> spark-worker-55965f669c-wsb2f   1/1     Running   0          24s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next, as we need to expose the Web UI for the Master process we will create a <em>LoadBalancer</em> resource. The YAML used to do this is provided here:</p><iframe width="100%" frameborder="0" id="gist-56ee86f50f329f99679ff243bb00fb07"></iframe><p>To deploy the LB, you would run the following:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create -f spark-ui-lb.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>NOTE</strong> This is just an example, for simplicity we are creating an external <em>LoadBalancer</em> with a public IP, this configuration is likely not be appropriate in most real scenarios, alternatives would include an internal <em>LoadBalancer</em>, retraction of Authorized Networks, a jump host, SSH tunnelling or IAP.</p><p>Now you’re up and running!</p><p>You can access the Master web UI from the Google Console link shown here:</p><p><a target="_blank" href="/assets/files/master-ui-link-c9d78a7032459c01291494b1c26e34ff.png"><img loading="lazy" alt="Accessing the Spark Master UI from the Google Cloud Console" src="/assets/images/master-ui-link-c9d78a7032459c01291494b1c26e34ff.png" width="1070" height="611" class="img_ev3q"></a></p><p>The Spark Master UI should look like this:</p><p><a target="_blank" href="/assets/files/spark-master-ui-fa6eecc91847995dea15601166516004.png"><img loading="lazy" alt="Spark Master UI" src="/assets/images/spark-master-ui-fa6eecc91847995dea15601166516004.png" width="1070" height="668" class="img_ev3q"></a></p><p>Next we will exec into a Worker pod, get a shell:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec -it spark-worker-55965f669c-rm59p -- sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now from within the shell environment of a Worker – which includes all of the Spark client libraries, we will submit a simple Spark application:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --class org.apache.spark.examples.SparkPi \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> --master spark://10.11.250.98:7077 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/opt/spark/examples/jars/spark-examples*.jar 10000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You can see the results in the shell, as shown here:</p><p><a target="_blank" href="/assets/files/spark-application-example-0f11e071394077ac8c678ed7d3e93791.png"><img loading="lazy" alt="Spark Pi Estimator Example" src="/assets/images/spark-application-example-0f11e071394077ac8c678ed7d3e93791.png" width="1022" height="932" class="img_ev3q"></a></p><p>Additionally, as all of the container logs go to Stackdriver, you can view the application logs there as well:</p><p><a target="_blank" href="/assets/files/container-logs-in-stackdriver-350797a4dd5cceab0b4aa12445adeed4.png"><img loading="lazy" alt="Container Logs in StackDriver" src="/assets/images/container-logs-in-stackdriver-350797a4dd5cceab0b4aa12445adeed4.png" width="1070" height="668" class="img_ev3q"></a></p><p>This is a simple way to get a Spark cluster running, it is not without its downsides and shortcomings however, which include the limited security mechanisms available (SASL, network security, shared secrets).</p><p>In the final post in this series we will look at Spark on Kubernetes, using Kubernetes as the Spark cluster manager and interacting with Spark using the Kubernetes API and control plane, see you then.</p><blockquote><p>Full source code for this article is available at: <a href="https://github.com/gamma-data/spark-on-gcp" target="_blank" rel="noopener noreferrer">https://github.com/gamma-data/spark-on-gcp</a></p></blockquote><p>The infrastructure coding for this example uses Powershell and Terraform, and is deployed as follows:</p><div class="language-powershell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-powershell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">PS &gt; .\run.ps1 private-network apply &lt;gcp-project&gt; &lt;region&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PS &gt; .\run.ps1 gke apply &lt;gcp-project&gt; &lt;region&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/apache-spark">apache-spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/cloud-dataproc">cloud-dataproc</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/dataproc">dataproc</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/gcp">gcp</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/gke">gke</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/googlecloudplatform">googlecloudplatform</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/kubernetes">kubernetes</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/images/spark-gcp-featured-image.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/spark-in-the-google-cloud-platform-part-1">Spark in the Google Cloud Platform Part 1</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2020-02-14T00:00:00.000Z" itemprop="datePublished">February 14, 2020</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="Apache Spark in GCP" src="/assets/images/spark-gcp-featured-image-86e0bfd36db759253fff66591b594d8b.png" width="213" height="155" class="img_ev3q"></p><p>I have been an avid Spark enthusiast since 2014 (the early days..). Spark has featured heavily in every project I have been involved with from data warehousing, ETL, feature extraction, advanced analytics to event processing and IoT applications. I like to think of it as a Swiss army knife for distributed processing.</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</div><div class="admonitionContent_S0QG"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>Curiously enough, the first project I had been involved with for some years that did not feature the Apache Spark project was a green field GCP project which got me thinking… where does Spark fit into the GCP landscape?</p><p>Unlike the other major providers who use Spark as the backbone of their managed distributed ETL services with examples such as AWS Glue or the Spark integration runtime option in Azure Data Factory, Google’s managed ETL solution is Cloud DataFlow. Cloud DataFlow which is a managed Apache Beam service does not use a Spark runtime (there is a Spark Runner however this is not an option when using CDF). So where does this leave Spark?</p><p>My summation is that although Spark is not a first-class citizen in GCP (as far as managed ETL), it is not a second-class citizen either. This article will discuss the various ways Spark clusters and applications can be deployed within the GCP ecosystem.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="quick-primer-on-spark">Quick Primer on Spark<a class="hash-link" href="#quick-primer-on-spark" title="Direct link to heading">​</a></h2><p>Every Spark application contains several components regardless of deployment mode, the components in the Spark runtime architecture are:</p><ul><li>the Driver</li><li>the Master</li><li>the Cluster Manager</li><li>the Executor(s), which run on worker nodes or Workers</li></ul><p>Each component has a specific role in executing a Spark program and all of the Spark components run in Java virtual machines (JVMs).</p><p><a target="_blank" href="/assets/files/spark-runtime-0b55b3d8793bab097b517603866abe16.png"><img loading="lazy" alt="Spark Runtime Architecture" src="/assets/images/spark-runtime-0b55b3d8793bab097b517603866abe16.png" width="752" height="420" class="img_ev3q"></a></p><p>Cluster Managers schedule and manage distributed resources (compute and memory) across the nodes of the cluster. Cluster Managers available for Spark include:</p><ul><li>Standalone</li><li>YARN (Hadoop)</li><li>Mesos</li><li>Kubernetes</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="spark-on-dataproc">Spark on DataProc<a class="hash-link" href="#spark-on-dataproc" title="Direct link to heading">​</a></h2><p>This is perhaps the simplest and most integrated approach to using Spark in the GCP ecosystem.</p><p>DataProc is GCP’s managed Hadoop Service (akin to AWS EMR or HDInsight on Azure). DataProc uses Hadoop/YARN as the Cluster Manager. DataProc clusters can be deployed on a private network (VPC using RFC1918 address space), supports encryption at Rest using Google Managed or Customer Managed Keys in KMS, supports autoscaling and the use of Preemptible Workers, and can be deployed in a HA config.</p><p>Furthermore, DataProc clusters can enforce strong authentication using Kerberos which can be integrated into other directory services such as Active Directory through the use of cross realm trusts.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="deployment">Deployment<a class="hash-link" href="#deployment" title="Direct link to heading">​</a></h3><p>DataProc clusters can be deployed using the <code>gcloud dataproc clusters create</code> command or using IaC solutions such as Terraform. For this article I have included an example in the source code using the <code>gcloud</code> command to deploy a DataProc cluster on a private network which was created using Terraform.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="integration">Integration<a class="hash-link" href="#integration" title="Direct link to heading">​</a></h3><p>The beauty of DataProc is its native integration into IAM and the GCP service plane. Having been a long-time user of AWS EMR, I have found that the usability and integration are in many ways superior in GCP DataProc. Let’s look at some examples...</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="iam-and-iap-tcp-forwarding">IAM and IAP (TCP Forwarding)<a class="hash-link" href="#iam-and-iap-tcp-forwarding" title="Direct link to heading">​</a></h4><p>DataProc is integrated into Cloud IAM using various coarse grained permissions use as <code>dataproc.clusters.use</code> and simplified IAM Roles such as <code>dataproc.editor</code> or <code>dataproc.admin</code>. Members with bindings to the these roles can perform tasks such as submitting jobs and creating workflow templates (which we will discuss shortly), as well as accessing instances such as the master node instance or instances in the cluster using IAP (TCP Forwarding) without requiring a public IP address or a bastion host.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dataproc-jobs-and-workflows">DataProc Jobs and Workflows<a class="hash-link" href="#dataproc-jobs-and-workflows" title="Direct link to heading">​</a></h4><p>Spark jobs can be submitted using the console or via <code>gcloud dataproc jobs submit</code> as shown here:</p><p><a target="_blank" href="/assets/files/dataproc-spark-job-953a699ceef00b9e3b0f05068a844a56.png"><img loading="lazy" alt="Submitting a Spark Job using gcloud dataproc jobs submit" src="/assets/images/dataproc-spark-job-953a699ceef00b9e3b0f05068a844a56.png" width="1097" height="499" class="img_ev3q"></a></p><p>Cluster logs are natively available in StackDriver and standard out from the Spark Driver is visible from the console as well as via <code>gcloud</code> commands.</p><p>Complex Workflows can be created by adding Jobs as Steps in Workflow Templates using the following command:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud dataproc workflow-templates add-job spark</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="optional-components-and-the-component-gateway">Optional Components and the Component Gateway<a class="hash-link" href="#optional-components-and-the-component-gateway" title="Direct link to heading">​</a></h4><p>DataProc provides you with a Hadoop cluster including YARN and HDFS, a Spark runtine – which includes Spark SQL and SparkR. DataProc also supports several optional components including Anaconda, Jupyter, Zeppelin, Druid, Presto, and more.</p><p>Web interfaces to some of these components as well as the management interfaces such as the Resource Manager UI or the Spark History Server UI can be accessed through the Component Gateway.</p><p>This is a Cloud IAM integrated gateway (much like IAP) which can allow access through an authenticated and authorized console session to web UIs in the cluster – without the need for SSH tunnels, additional firewall rules, bastion hosts, or public IPs. Very cool.</p><p>Links to the component UIs as well as built in UIs like the YARN Resource Manager UI are available directly from through the console.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="jupyter">Jupyter<a class="hash-link" href="#jupyter" title="Direct link to heading">​</a></h4><p>Jupyter is a popular notebook application in the data science and analytics communities used for reproducible research. DataProc’s Jupyter component provides a ready-made Spark application vector using PySpark. If you have also installed the Anaconda component you will have access to the full complement of scientific and mathematic Python packages such as Pandas and NumPy which can be used in Jupyter notebooks as well. Using the Component Gateway, Jupyer notebooks can be accessed directly from the Google console as shown here:</p><p><a target="_blank" href="/assets/files/dataproc-jupyter-notebook-14d165b5563c903961beb68bef757a82.png"><img loading="lazy" alt="Jupyter Notebooks using DataProc" src="/assets/images/dataproc-jupyter-notebook-14d165b5563c903961beb68bef757a82.png" width="1359" height="924" class="img_ev3q"></a></p><p>From this example you can see that I accessed source data from a GCS bucket and used HDFS as local scratch space.</p><p>Furthermore, notebooks are automagically saved in your integrated Cloud Storage DataProc staging bucket and can be shared amongst analysts or accessed at a later time. These notebooks also persist beyond the lifespan of the cluster.</p><p>Next up we will look at deploying a Spark Standalone cluster on a GKE cluster, see you then!</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/apache-spark">apache-spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/gcp">gcp</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/googlecloudplatform">googlecloudplatform</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/images/CDC-using-Spark.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/change-data-capture-at-scale-using-spark">Change Data Capture at Scale using Spark</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2019-06-28T00:00:00.000Z" itemprop="datePublished">June 28, 2019</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="CDC using Spark" src="/assets/images/CDC-using-Spark-38cb48e3545c719f89f4380b50711cf3.png" width="256" height="251" class="img_ev3q"></p><p>Change Data Capture (CDC) is one of the most challenging processing patterns to implement at scale. I personally have had several cracks at this using various different frameworks and approaches, the most recent of which was implemented using Spark – and I think I have finally found the best approach. Even though the code examples referenced use Spark, the pattern is language agnostic – the focus is on the approach not the specific implementation (as this could be applied to any framework or runtime).</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</div><div class="admonitionContent_S0QG"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The first challenge you are faced with, is to compare a very large dataset (representing the current state of an object) with another potentially very large dataset (representing new or incoming data). Ideally, you would like the process to be configuration driven and accommodate such things as composite primary keys, or operational columns which you would like to restrict from change detection. You may also want to implement a pattern to segregate sensitive attributes from non-sensitive attributes.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="overview">Overview<a class="hash-link" href="#overview" title="Direct link to heading">​</a></h2><p>This pattern (and all my other recent attempts) is fundamentally based upon calculating a deterministic hash of the key and non-key attribute(s), and then using this hash as the basis for comparison. The difference between this pattern and my other attempts is in the distillation and reconstitution of data during the process, as well as breaking the pattern into discrete stages (designed to minimize the impact to other applications). This pattern can be used to process delta or full datasets.</p><p>A high-level flowchart representing the basic pattern is shown here:</p><p><a target="_blank" href="/assets/files/CDC-59f029c756f942661da9a4744801d227.png"><img loading="lazy" alt="CDC Flowchart" src="/assets/images/CDC-59f029c756f942661da9a4744801d227.png" width="382" height="1118" class="img_ev3q"></a></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-example">The Example<a class="hash-link" href="#the-example" title="Direct link to heading">​</a></h2><p>The example provided uses the <a href="https://github.com/avensolutions/synthetic-cdc-data-generator" target="_blank" rel="noopener noreferrer">Synthetic CDC Data Generator application</a>, configuring an incoming set with 5 uuid columns acting as a composite key, and 10 random number columns acting as non key values. The initial days payload consists of 10,000 records, the subsequent days payload consists of another 10,000 records. From the initial dataset, a <code>DELETE</code> operation was performed at the source system for 20% of records, an <code>UPDATE</code> was performed on 40% of the records and the remaining 40% of records were unchanged. In this case the 20% of records that were deleted at the source, were replaced by new <code>INSERT</code> operations creating new keys.</p><p>After creating the synthesized day 1 and day 2 datasets, the files are processed as follows:</p><p>$ spark-submit cdc.py config.yaml data/day1 2019-06-18<br>
<!-- -->$ spark-submit cdc.py config.yaml data/day2 2019-06-19</p><p>Where <code>config.yaml</code> is the configuration for the dataset, data/day1 and data/day2 represent the different data files, and 2019-06-18 and 2019-06-19 represent a business effective date.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-results">The Results<a class="hash-link" href="#the-results" title="Direct link to heading">​</a></h2><p>You should see the following output from running the preceding commands for day 1 and day 2 respectively:</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="day-1">Day 1:<a class="hash-link" href="#day-1" title="Direct link to heading">​</a></h3><iframe width="100%" frameborder="0" id="gist-b75edc7825b46c12b328d78d47b4b902"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="day-2">Day 2:<a class="hash-link" href="#day-2" title="Direct link to heading">​</a></h3><iframe width="100%" frameborder="0" id="gist-ca92e132105fb5bb381bf9dfca562bf4"></iframe><p>A summary analysis of the resultant dataset should show:</p><iframe width="100%" frameborder="0" id="gist-ded1f98dc4fce13c9bb3d12a51a46b94"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pattern-details">Pattern Details<a class="hash-link" href="#pattern-details" title="Direct link to heading">​</a></h2><p>Details about the pattern and its implementation follow.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="current-and-historical-datasets">Current and Historical Datasets<a class="hash-link" href="#current-and-historical-datasets" title="Direct link to heading">​</a></h3><p>The output of each operation will yield a current dataset (that is the current stateful representation of a give object) and a historical dataset partition (capturing the net changes from the previous state in an appended partition).</p><p>This is useful, because often consumers will primarily query the latest state of an object. The change sets (or historical dataset partitions) can be used for more advanced analysis by sophisticated users.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="type-2-scds-sort-of">Type 2 SCDs (sort of)<a class="hash-link" href="#type-2-scds-sort-of" title="Direct link to heading">​</a></h3><p>Two operational columns are added to each current and historical object:</p><ul><li><code>OPERATION</code> : Represents the last known operation to the record, valid values include :<ul><li><code>I</code> (<code>INSERT</code>)</li><li><code>U</code> (<code>UPDATE</code>)</li><li><code>D</code> (<code>DELETE</code> – hard <code>DELETE</code>s, applies to full datasets only)</li><li><code>X</code> (Not supplied, applies to delta processing only)</li><li><code>N</code> (No change)</li></ul></li><li><code>EFF_START_DATE</code></li></ul><p>Since data structures on most big data or cloud storage platforms are immutable, we only store the effective start date for each record, this is changed as needed with each coarse-grained operation on the current object. The effective end date is inferred by the presence of a new effective start date (or change in the <code>EFF_START_DATE</code> value for a given record).</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-configuration">The Configuration<a class="hash-link" href="#the-configuration" title="Direct link to heading">​</a></h3><p>I am using a YAML document to store the configuration for the pattern. Important attributes to include in your configuration are a list of keys and non keys and their datatype (this implementation does type casting as well). Other important attributes include the table names and file paths for the current and historical data structures.</p><p>The configuration is read at the beginning of a routine as an input along with the path of an incoming data file (a CSV file in this case) and a business effective date (which will be used as the <code>EFF_START_DATE</code> for new or updated records).</p><p>Processing is performed using the specified key and non key attributes and the output datasets (current and historical) are written to columnar storage files (parquet in this case). This is designed to make subsequent access and processing more efficient.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-algorithm">The Algorithm<a class="hash-link" href="#the-algorithm" title="Direct link to heading">​</a></h3><p>I have broken the process into stages as follows:</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stage-1--type-cast-and-hash-incoming-data">Stage 1 – Type Cast and Hash Incoming Data<a class="hash-link" href="#stage-1--type-cast-and-hash-incoming-data" title="Direct link to heading">​</a></h4><p>The first step is to create deterministic hashes of the configured key and non key values for incoming data. The hashes are calculated based upon a list of elements representing the key and non key values using the MD5 algorithm. The hashes for each record are then stored with the respective record. Furthermore, the fields are casted their target datatype as specified in the configuration. Both of these operations can be performed in a single pass of each row using a <code>map()</code> operation.</p><p>Importantly we only calculate hashes once upon arrival of new data, as the hashes are persisted for the life of the data – and the data structures are immutable – the hashes should never change or be invalidated.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stage-2--determine-inserts">Stage 2 – Determine INSERTs<a class="hash-link" href="#stage-2--determine-inserts" title="Direct link to heading">​</a></h4><p>We now compare Incoming Hashes with previously calculated hash values for the (previous day’s) current object. If no current object exists for the dataset, then it can be assumed this is a first run. In this case every record is considered as an <code>INSERT</code> with an <code>EFF_START_DATE</code> of the business effective date supplied.</p><p>If there is a current object, then the key and non key hash values (only the hash values) are read from the current object. These are then compared to the respective hashes of the incoming data (which should still be in memory).</p><p>Given the full outer join:</p><p>incoming<!-- -->_<!-- -->data(keyhash, nonkeyhash)
FULL OUTER JOIN<br>
<!-- -->current<!-- -->_<!-- -->data(keyhash, nonkeyhash)
ON keyhash</p><p>Keys which exist in the left entity which do not exist in the right entity must be the results of an INSERT operation.</p><p>Tag these records with an operation of <code>I</code> with an <code>EFF_START_DATE</code> of the business effective date, then rejoin only these records with their full attribute payload from the incoming dataset. Finally, write out these records to the current and historical partition in <code>overwrite</code> mode.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stage-3---determine-deletes-or-missing-records">Stage 3 - Determine DELETEs or Missing Records<a class="hash-link" href="#stage-3---determine-deletes-or-missing-records" title="Direct link to heading">​</a></h4><p>Referring the previous full outer join operation, keys which exist in the right entity (current object) which do not appear in the left entity (incoming data) will be the result of a (hard) <code>DELETE</code> operation if you are processing full snapshots, otherwise if you are processing deltas these would be missing records (possibly because there were no changes at the source).</p><p>Tag these records as <code>D</code> or <code>X</code> respectively with an <code>EFF_START_DATE</code> of the business effective date, rejoin these records with their full attribute payload from the current dataset, then write out these records to the current and historical partition in <code>append</code> mode.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stage-4---determine-updates-or-unchanged-records">Stage 4 - Determine UPDATEs or Unchanged Records<a class="hash-link" href="#stage-4---determine-updates-or-unchanged-records" title="Direct link to heading">​</a></h4><p>Again, referring to the previous full outer join, keys which exist in both the incoming and current datasets must be either the result of an <code>UPDATE</code> or they could be unchanged. To determine which case they fall under, compare the non key hashes. If the non key hashes differ, it must have been a result of an <code>UPDATE</code> operation at the source, otherwise the record would be unchanged.</p><p>Tag these records as <code>U</code> or <code>N</code> respectively with an <code>EFF_START_DATE</code> of the business effective date (in the case of an update - otherwise maintain the current <code>EFF_START_DATE</code>), rejoin these records with their full attribute payload from the incoming dataset, then write out these records to the current and historical partition in <code>append</code> mode.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="key-callouts">Key Callouts<a class="hash-link" href="#key-callouts" title="Direct link to heading">​</a></h3><p>A summary of the key callouts from this pattern are:</p><ul><li>Use the RDD API for iterative record operations (such as type casting and hashing)</li><li>Persist hashes with the records</li><li>Use Dataframes for <code>JOIN</code> operations</li><li>Only perform <code>JOIN</code>s with the <code>keyhash</code> and <code>nonkeyhash</code> columns – this minimizes the amount of data shuffled across the network</li><li>Write output data in columnar (Parquet) format</li><li>Break the routine into stages, covering each operation, culminating with a <code>saveAsParquet()</code> action – this may seem expensive but for large datsets it is more efficient to break down DAGs for each operation</li><li>Use caching for objects which will be reused between actions</li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="metastore-integration">Metastore Integration<a class="hash-link" href="#metastore-integration" title="Direct link to heading">​</a></h4><p>Although I did not include this in my example, you could easily integrate this pattern with a metastore (such as a Hive metastore or AWS Glue Catalog), by using table objects and <code>ALTER TABLE</code> statements to add historical partitions.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="further-optimisations">Further optimisations<a class="hash-link" href="#further-optimisations" title="Direct link to heading">​</a></h4><p>If the incoming data is known to be relatively small (in the case of delta processing for instance), you could consider a broadcast join where the smaller incoming data is distributed to all of the different Executors hosting partitions from the current dataset.</p><p>Also you could add a key to the column config to configure a column to be nullable or not.</p><p>Happy CDCing!</p><blockquote><p>Full source code for this article can be found at: <a href="https://github.com/avensolutions/cdc-at-scale-using-spark" target="_blank" rel="noopener noreferrer">https://github.com/avensolutions/cdc-at-scale-using-spark</a></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/big-data">big-data</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/cdc">cdc</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/pyspark">pyspark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/python">python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/tags/spark/page/2"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">StackQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.windrate.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">WindRate<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.80d85236.js"></script>
<script src="/assets/js/main.563a43d5.js"></script>
</body>
</html>