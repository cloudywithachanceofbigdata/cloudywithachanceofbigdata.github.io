<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">7 posts tagged with &quot;spark&quot; | Full Stack Chronicles</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" name="twitter:image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><meta data-rh="true" property="og:url" content="https://fullstackchronicles.io/tags/spark/page/2"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="wot-verification" content="e7522390be4370727fac"><meta data-rh="true" property="og:title" content="7 posts tagged with &quot;spark&quot; | Full Stack Chronicles"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://fullstackchronicles.io/tags/spark/page/2"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/spark/page/2" hreflang="en"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/tags/spark/page/2" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MZCGVO503N-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Full Stack Chronicles Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Full Stack Chronicles Blog Feed Atom Feed">
<link rel="alternate" type="application/json" href="/feed.json" title="Full Stack Chronicles Blog Feed JSON Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FVDC1E8G6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0FVDC1E8G6",{})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Full Stack Chronicles" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.5ea58133.css">
<link rel="preload" href="/assets/js/runtime~main.5850473c.js" as="script">
<link rel="preload" href="/assets/js/main.b8fc3cd8.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ navbar--primary"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Full Stack Chronicles</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/tags">Topics</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/snowflake">Snowflake</a></li><li><a class="dropdown__link" href="/tags/okta">Okta</a></li><li><a class="dropdown__link" href="/tags/openapi">OpenAPI</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/tags/spark">Spark</a></li><li><a class="dropdown__link" href="/tags/kafka">Kafka</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/apache-beam-in-five-minutes">Apache Beam in Five Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/aws-iam-vs-google-iam">AWS IAM vs Google IAM</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/create-and-use-custom-magic-commands-in-jupyter">Create and use Custom Magic Commands in Jupyter</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/deno-in-five-minutes">Deno in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dbt-in-five-minutes">DBT in 5 Minutes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/loading-parquet-files-into-snowflake">Loading Parquet Files into Snowflake</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/analyze-developer-activity-with-stackql-jupyter-bigquery">Analyze Developer Activity with StackQL, Jupyter and BigQuery</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/converting-google-discovery-docs-to-openapi3-specs">Converting Google Discovery Docs to OpenAPI3 Specs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/recurse-javascript-object-to-get-values-for-a-given-key-the-easy-way">Recurse JavaScript Object to Get Values for a Given Key the Easy Way</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/dataops-with-container-images-and-multi-stage-builds">DataOps with Container Images and Multi-Stage Builds</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>7 posts tagged with &quot;spark&quot;</h1><a href="/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/img/fullstackchronicles-cover-image.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/synthetic-cdc-data-generator">Synthetic CDC Data Generator</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2019-06-28T00:00:00.000Z" itemprop="datePublished">June 28, 2019</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>This is a simple routine to generate random data with a configurable number or records, key fields and non key fields to be used to create synthetic data for source change data capture (CDC) processing. The output includes an initial directory containing CSV files representing an initial data load, and an incremental directory containing CSV files representing incremental data.</p><p>Spark Training Courses from the AlphaZetta Academy</p><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p><p>Arguments (by position) include:</p><ul><li><code>no_init_recs</code> : the number of initial records to generate</li><li><code>no_incr_recs</code> : the number of incremental records on the second run - should be <code>&gt;= no_init_recs</code></li><li><code>no_keys</code> : number of key columns in the dataset – keys are generated as UUIDs</li><li><code>no_nonkeys</code> : number of non-key columns in the dataset – nonkey values are generated as random numbers</li><li><code>pct_del</code> : percentage of initial records deleted on the second run - between 0.0 and 1.0</li><li><code>pct_upd</code> : percentage of initial records updated on the second run - between 0.0 and 1.0</li><li><code>pct_unchanged</code> : percentage of records unchanged on the second run - between 0.0 and 1.0</li><li><code>initial_output</code> : folder for initial output in CSV format</li><li><code>incremental_output</code> : folder for incremental output in CSV format</li></ul><p>NOTE : <code>pct_del</code> + <code>pct_upd</code> + <code>pct_unchanged</code> must equal 1.0</p><p>Example usage:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ spark-submit synthetic-cdc-data-generator.py 100000 100000 2 3 0.2 0.4 0.4 data/day1 data/day2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Example output from the <strong><em>day1</em></strong> run for the above configuration would look like this:</p><iframe width="100%" frameborder="0" id="gist-befb034da2b4f25a1dbbc0e9b4b8eef6"></iframe><p>Note that this routine can be run subsequent times producing different key and non key values each time, as the keys are UUIDs and the values are random numbers.</p><p>We will use this application to generate random input data to demonstrate CDC using Spark in a subsequent post, see you soon!</p><blockquote><p>Full source code can be found at: <a href="https://github.com/avensolutions/synthetic-cdc-data-generator" target="_blank" rel="noopener noreferrer">https://github.com/avensolutions/synthetic-cdc-data-generator</a></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/cdc">cdc</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/python">python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://fullstackchronicles.io/images/spark-sql-etl-framework.png"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/multi-stage-etl-framework-using-spark-sql">Multi Stage ETL Framework using Spark SQL</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2019-01-09T00:00:00.000Z" itemprop="datePublished">January 9, 2019</time> · <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="Spark SQL ETL Framework" src="/assets/images/spark-sql-etl-framework-7491c174dee5cda2a37f00480d593b80.png" width="451" height="223" class="img_ev3q"></p><p>Most traditional data warehouse or datamart ETL routines consist of multi stage SQL transformations, often a series of CTAS (<code>CREATE TABLE AS SELECT</code>) statements usually creating transient or temporary tables – such as volatile tables in Teradata or Common Table Expressions (CTE’s).</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</div><div class="admonitionContent_S0QG"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The initial challenge when moving from a SQL/MPP based ETL framework platformed on Oracle, Teradata, SQL Server, etc to a Spark based ETL framework is what to do with this…</p><p><img loading="lazy" alt="Multi Stage SQL Based ETL" src="/assets/images/multi-stage-sql-1b6298de71ac35e0ecde3af82a831be6.png" width="736" height="805" class="img_ev3q"></p><p>One approach is to use the lightweight, configuration driven, multi stage Spark SQL based ETL framework described in this post.</p><p>This framework is driven from a YAML configuration document. YAML was preferred over JSON as a document format as it allows for multi-line statements (SQL statements), as well as comments - which are very useful as SQL can sometimes be undecipherable even for the person that wrote it.</p><p>The YAML config document has three main sections: <strong><code>sources</code></strong>, <strong><code>transforms</code></strong> and <strong><code>targets</code></strong>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sources">Sources<a class="hash-link" href="#sources" title="Direct link to heading">​</a></h3><p>The <strong><code>sources</code></strong> section is used to configure the input data source(s) including optional column and row filters. In this case the data sources are tables available in the Spark catalog (for instance the AWS Glue Catalog or a Hive Metastore), this could easily be extended to read from other datasources using the Spark DataFrameReader API.</p><iframe width="100%" frameborder="0" id="gist-eaf03229466718ee125e0a6d23370f1b"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="transforms">Transforms<a class="hash-link" href="#transforms" title="Direct link to heading">​</a></h3><p>The <strong><code>transforms</code></strong> section contains the multiple SQL statements to be run in sequence where each statement creates a temporary view using objects created by preceding statements.</p><iframe width="100%" frameborder="0" id="gist-89ad7ac6b036e5f22b2d3dec43b1fe44"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="targets">Targets<a class="hash-link" href="#targets" title="Direct link to heading">​</a></h3><p>Finally the <strong><code>targets</code></strong> section writes out the final object or objects to a specified destination (S3, HDFS, etc).</p><iframe width="100%" frameborder="0" id="gist-5af780dd6b6e5ddd79a4cac8a59e6a69"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="process-sql-statements">Process SQL Statements<a class="hash-link" href="#process-sql-statements" title="Direct link to heading">​</a></h3><p>The <strong><code>process_sql_statements.py</code></strong> script that is used to execute the framework is very simple (30 lines of code not including comments, etc). It loads the sources into Spark Dataframes and then creates temporary views to reference these datasets in the <strong><code>transforms</code></strong> section, then sequentially executes the SQL statements in the list of transforms. Lastly the script writes out the final view or views to the desired destination – in this case parquet files stored in S3 were used as the target.</p><p>You could implement an object naming convention such as prefixing object names with <code>sv_</code>, <code>iv_</code>, <code>fv_</code> (for source view, intermediate view and final view respectively) if this helps you differentiate between the different objects.</p><p>To use this framework you would simply use <strong><code>spark-submit</code></strong> as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit process_sql_statements.py config.yml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/spark-sql-etl-framework" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/spark-sql-etl-framework</strong></a></em></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/etl">etl</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/spark">spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/sql">sql</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/tags/spark"><div class="pagination-nav__label">Newer Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">StackQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.windrate.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">WindRate<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.5850473c.js"></script>
<script src="/assets/js/main.b8fc3cd8.js"></script>
</body>
</html>