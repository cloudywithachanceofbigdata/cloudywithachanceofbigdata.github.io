<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Cloudy with a chance of Big Data Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Cloudy with a chance of Big Data Blog Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4N6KSJ2G0P"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-4N6KSJ2G0P",{})</script><title data-react-helmet="true">Multi Stage ETL Framework using Spark SQL | Cloudy with a chance of Big Data</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://cloudywithachanceofbigdata.com/multi-stage-etl-framework-using-spark-sql"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Multi Stage ETL Framework using Spark SQL | Cloudy with a chance of Big Data"><meta data-react-helmet="true" name="description" content="A simple configuration driven Spark SQL ETL framework"><meta data-react-helmet="true" property="og:description" content="A simple configuration driven Spark SQL ETL framework"><meta data-react-helmet="true" name="keywords" content="etl,spark,sql"><meta data-react-helmet="true" property="og:image" content="https://cloudywithachanceofbigdata.com/images/spark-sql-etl-framework.png"><meta data-react-helmet="true" name="twitter:image" content="https://cloudywithachanceofbigdata.com/images/spark-sql-etl-framework.png"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2019-01-09T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://www.linkedin.com/in/jeffreyaven/"><meta data-react-helmet="true" property="article:tag" content="etl,spark,sql"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://cloudywithachanceofbigdata.com/multi-stage-etl-framework-using-spark-sql"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/multi-stage-etl-framework-using-spark-sql" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/multi-stage-etl-framework-using-spark-sql" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.3f66b476.css">
<link rel="preload" href="/assets/js/runtime~main.42ba1e05.js" as="script">
<link rel="preload" href="/assets/js/main.34136df6.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_2qcr"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title">Cloudy with a chance of Big Data</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/tags">Topics</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/from-wordpress-to-jamstack">From Wordpress to Jamstack</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/using-jsonnet-to-configure-multiple-environments">Using Jsonnet to Configure Multiple Environments</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/use-bigquery-to-trigger-cloud-run">Use BigQuery to trigger Cloud Run</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/azure-static-web-app-review">Azure Static Web App Review</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/introducing-the-metadata-hub-mdh">Introducing the Metadata Hub (MDH)</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/masking-private-keys-in-ci-cd-pipelines-in-gitlab">Masking Private Keys in CI/CD Pipelines in GitLab</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simple-tasker-configuration-driven-orchestration">Simple Tasker: Configuration driven orchestration</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/okta-admin-command-line-interface">Okta Admin Command Line Interface</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/enumerating-all-roles-for-a-user-in-snowflake">Enumerating all roles for a user in Snowflake</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/eventarc-the-state-of-eventing-in-google-cloud">EventArc: The state of eventing in Google Cloud</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_GeHD" itemprop="headline">Multi Stage ETL Framework using Spark SQL</h1><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-09T00:00:00.000Z" itemprop="datePublished">January 9, 2019</time> Â· 3 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/spark-sql-etl-framework.png"><div class="markdown" itemprop="articleBody"><p>Most traditional data warehouse or datamart ETL routines consist of multi stage SQL transformations, often a series of CTAS (<code>CREATE TABLE AS SELECT</code>) statements usually creating transient or temporary tables â€“ such as volatile tables in Teradata or Common Table Expressions (CTEâ€™s).</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</h5></div><div class="admonition-content"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The initial challenge when moving from a SQL/MPP based ETL framework platformed on Oracle, Teradata, SQL Server, etc to a Spark based ETL framework is what to do with thisâ€¦</p><p><img alt="Multi Stage SQL Based ETL" src="/assets/images/multi-stage-sql-1b6298de71ac35e0ecde3af82a831be6.png"></p><p>One approach is to use the lightweight, configuration driven, multi stage Spark SQL based ETL framework described in this post.</p><p>This framework is driven from a YAML configuration document. YAML was preferred over JSON as a document format as it allows for multi-line statements (SQL statements), as well as comments - which are very useful as SQL can sometimes be undecipherable even for the person that wrote it.</p><p>The YAML config document has three main sections: <strong><code>sources</code></strong>, <strong><code>transforms</code></strong> and <strong><code>targets</code></strong>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithHideOnScrollNavbar_3R7-" id="sources"></a>Sources<a class="hash-link" href="#sources" title="Direct link to heading">#</a></h3><p>The <strong><code>sources</code></strong> section is used to configure the input data source(s) including optional column and row filters. In this case the data sources are tables available in the Spark catalog (for instance the AWS Glue Catalog or a Hive Metastore), this could easily be extended to read from other datasources using the Spark DataFrameReader API.</p><iframe width="100%" frameborder="0" id="gist-eaf03229466718ee125e0a6d23370f1b"></iframe><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithHideOnScrollNavbar_3R7-" id="transforms"></a>Transforms<a class="hash-link" href="#transforms" title="Direct link to heading">#</a></h3><p>The <strong><code>transforms</code></strong> section contains the multiple SQL statements to be run in sequence where each statement creates a temporary view using objects created by preceding statements.</p><iframe width="100%" frameborder="0" id="gist-89ad7ac6b036e5f22b2d3dec43b1fe44"></iframe><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithHideOnScrollNavbar_3R7-" id="targets"></a>Targets<a class="hash-link" href="#targets" title="Direct link to heading">#</a></h3><p>Finally the <strong><code>targets</code></strong> section writes out the final object or objects to a specified destination (S3, HDFS, etc).</p><iframe width="100%" frameborder="0" id="gist-5af780dd6b6e5ddd79a4cac8a59e6a69"></iframe><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithHideOnScrollNavbar_3R7-" id="process-sql-statements"></a>Process SQL Statements<a class="hash-link" href="#process-sql-statements" title="Direct link to heading">#</a></h3><p>The <strong><code>process_sql_statements.py</code></strong> script that is used to execute the framework is very simple (30 lines of code not including comments, etc). It loads the sources into Spark Dataframes and then creates temporary views to reference these datasets in the <strong><code>transforms</code></strong> section, then sequentially executes the SQL statements in the list of transforms. Lastly the script writes out the final view or views to the desired destination â€“ in this case parquet files stored in S3 were used as the target.</p><p>You could implement an object naming convention such as prefixing object names with <code>sv_</code>, <code>iv_</code>, <code>fv_</code> (for source view, intermediate view and final view respectively) if this helps you differentiate between the different objects.</p><p>To use this framework you would simply use <strong><code>spark-submit</code></strong> as follows:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit process_sql_statements.py config.yml</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/spark-sql-etl-framework" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/spark-sql-etl-framework</strong></a></em></p></blockquote></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_3kfx"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/etl">etl</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/spark">spark</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/sql">sql</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io/tree/main/src/blog/blog/2019-01-09-multi-stage-etl-framework-using-spark-sql/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/infrastructure-automation-using-aws-lambda"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« Infrastructure Automation using AWS Lambda</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/cost-of-future-change"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">The Cost of Future Change Â»</div></a></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items"><li class="footer__item"><a href="https://infraql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>InfraQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/assets/js/runtime~main.42ba1e05.js"></script>
<script src="/assets/js/main.34136df6.js"></script>
</body>
</html>