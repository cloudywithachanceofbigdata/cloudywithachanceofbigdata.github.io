"use strict";(self.webpackChunkfull_stack_chronicles=self.webpackChunkfull_stack_chronicles||[]).push([[59805],{30433:function(e,t,a){a.d(t,{Z:function(){return l}});var n=a(67294),i=a(34334),r="tabItem_Ymn6";function l(e){var t=e.children,a=e.hidden,l=e.className;return n.createElement("div",{role:"tabpanel",className:(0,i.Z)(r,l),hidden:a},t)}},65559:function(e,t,a){a.d(t,{Z:function(){return g}});var n=a(83117),i=a(67294),r=a(34334),l=a(5730),o=a(20636),s=a(76602),p=a(63735),u="tabList__CuJ",c="tabItem_LNqP";function d(e){var t,a,l=e.lazy,d=e.block,g=e.defaultValue,m=e.values,k=e.groupId,h=e.className,f=i.Children.map(e.children,(function(e){if((0,i.isValidElement)(e)&&"value"in e.props)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),b=null!=m?m:f.map((function(e){var t=e.props;return{value:t.value,label:t.label,attributes:t.attributes}})),y=(0,o.l)(b,(function(e,t){return e.value===t.value}));if(y.length>0)throw new Error('Docusaurus error: Duplicate values "'+y.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var v=null===g?g:null!=(t=null!=g?g:null==(a=f.find((function(e){return e.props.default})))?void 0:a.props.value)?t:f[0].props.value;if(null!==v&&!b.some((function(e){return e.value===v})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+v+'" but none of its children has the corresponding value. Available values are: '+b.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var w=(0,s.U)(),T=w.tabGroupChoices,N=w.setTabGroupChoices,C=(0,i.useState)(v),M=C[0],E=C[1],D=[],O=(0,p.o5)().blockElementScrollPositionUntilNextRender;if(null!=k){var _=T[k];null!=_&&_!==M&&b.some((function(e){return e.value===_}))&&E(_)}var R=function(e){var t=e.currentTarget,a=D.indexOf(t),n=b[a].value;n!==M&&(O(t),E(n),null!=k&&N(k,String(n)))},I=function(e){var t,a=null;switch(e.key){case"ArrowRight":var n,i=D.indexOf(e.currentTarget)+1;a=null!=(n=D[i])?n:D[0];break;case"ArrowLeft":var r,l=D.indexOf(e.currentTarget)-1;a=null!=(r=D[l])?r:D[D.length-1]}null==(t=a)||t.focus()};return i.createElement("div",{className:(0,r.Z)("tabs-container",u)},i.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":d},h)},b.map((function(e){var t=e.value,a=e.label,l=e.attributes;return i.createElement("li",(0,n.Z)({role:"tab",tabIndex:M===t?0:-1,"aria-selected":M===t,key:t,ref:function(e){return D.push(e)},onKeyDown:I,onFocus:R,onClick:R},l,{className:(0,r.Z)("tabs__item",c,null==l?void 0:l.className,{"tabs__item--active":M===t})}),null!=a?a:t)}))),l?(0,i.cloneElement)(f.filter((function(e){return e.props.value===M}))[0],{className:"margin-top--md"}):i.createElement("div",{className:"margin-top--md"},f.map((function(e,t){return(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==M})}))))}function g(e){var t=(0,l.Z)();return i.createElement(d,(0,n.Z)({key:String(t)},e))}},24273:function(e,t,a){a.r(t),a.d(t,{assets:function(){return d},contentTitle:function(){return u},default:function(){return k},frontMatter:function(){return p},metadata:function(){return c},toc:function(){return g}});var n=a(83117),i=a(80102),r=(a(67294),a(3905)),l=a(65559),o=a(30433),s=["components"],p={slug:"dataops-with-container-images-and-multi-stage-builds",title:"DataOps with Container Images and Multi-Stage Builds",authors:["chrisottinger"],draft:!1,image:"/img/blog/dataops-featured-image.png",tags:["python","docker","ci-cd","data engineering","poetry"],keywords:["python","docker","ci-cd","data engineering","poetry"]},u=void 0,c={permalink:"/dataops-with-container-images-and-multi-stage-builds",editUrl:"https://github.com/stackql/fullstackchronicles.io/tree/main/src/blog/blog/2022-05-28-dataops-with-container-images-and-multi-stage-builds/index.md",source:"@site/blog/2022-05-28-dataops-with-container-images-and-multi-stage-builds/index.md",title:"DataOps with Container Images and Multi-Stage Builds",description:"",date:"2022-05-28T00:00:00.000Z",formattedDate:"May 28, 2022",tags:[{label:"python",permalink:"/tags/python"},{label:"docker",permalink:"/tags/docker"},{label:"ci-cd",permalink:"/tags/ci-cd"},{label:"data engineering",permalink:"/tags/data-engineering"},{label:"poetry",permalink:"/tags/poetry"}],readingTime:7.15,hasTruncateMarker:!1,authors:[{name:"Chris Ottinger",title:"Senior Technologist",url:"https://github.com/datwiz",imageURL:"http://0.gravatar.com/avatar/f9af9c3fae755ac170c5798c53c5267d?s=80",key:"chrisottinger"}],frontMatter:{slug:"dataops-with-container-images-and-multi-stage-builds",title:"DataOps with Container Images and Multi-Stage Builds",authors:["chrisottinger"],draft:!1,image:"/img/blog/dataops-featured-image.png",tags:["python","docker","ci-cd","data engineering","poetry"],keywords:["python","docker","ci-cd","data engineering","poetry"]},prevItem:{title:"Recurse JavaScript Object to Get Values for a Given Key the Easy Way",permalink:"/recurse-javascript-object-to-get-values-for-a-given-key-the-easy-way"},nextItem:{title:"Using the Snowflake SQL API with TypeScript",permalink:"/using-the-snowflake-sql-api-with-typescript"}},d={authorsImageUrls:[void 0]},g=[{value:"The DataOps Container Lifecycle Workflow",id:"the-dataops-container-lifecycle-workflow",level:2},{value:"Multi-stage Dockerfile",id:"multi-stage-dockerfile",level:2},{value:"Build Stage: base-pre-pkg",id:"build-stage-base-pre-pkg",level:3},{value:"Build Stage: python-pkg-refresh",id:"build-stage-python-pkg-refresh",level:3},{value:"Build Stage: python-pkg-pinned",id:"build-stage-python-pkg-pinned",level:3},{value:"Build Stage: base-post-pkg",id:"build-stage-base-post-pkg",level:3},{value:"Build Stage: smoke-test",id:"build-stage-smoke-test",level:3},{value:"Build Stage: target-image",id:"build-stage-target-image",level:3},{value:"Multi-stage Makefile",id:"multi-stage-makefile",level:2},{value:"Make Target: style-check",id:"make-target-style-check",level:2},{value:"Make Target: python-pkg-refresh",id:"make-target-python-pkg-refresh",level:2},{value:"Make Target: build",id:"make-target-build",level:3},{value:"Make Target: smoke-test",id:"make-target-smoke-test",level:3},{value:"Conclusion",id:"conclusion",level:2}],m={toc:g};function k(e){var t=e.components,p=(0,i.Z)(e,s);return(0,r.kt)("wrapper",(0,n.Z)({},m,p,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Container images provide an ideal software packaging solution for DataOps and python based data pipeline workloads.  Containers enable Data Scientists and Data Engineers to incorporate the latest packages and libraries without the issues associated with introducing breaking changes into shared environments.  A Data Engineer or Data Scienctist can quickly release new functionality with the best tools available.  "),(0,r.kt)("p",null,"Container images provide safer developer environments but as the number of container images used for production workloads grow, a maintenance challenge can emerge.  Whether using ",(0,r.kt)("a",{parentName:"p",href:"https://pypi.org/project/pip"},"pip")," or ",(0,r.kt)("a",{parentName:"p",href:"https://python-poetry.org/"},"poetry")," to manage python packages and dependencies, updating a container definition requires edits to the explicit package versions as well as to the pinned or locked versions of the package dependencies. This process can be error prone without automation and a repeatable CICD workflow.  "),(0,r.kt)("p",null,"A workflow pattern based on ",(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/develop/develop-images/build_enhancements/"},"docker buildkit")," / ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/moby/buildkit"},"moby buildkit")," multi-stage builds provides an approach that maintains all the build specifications in a single ",(0,r.kt)("inlineCode",{parentName:"p"},"Dockerfile"),", while build tools like ",(0,r.kt)("inlineCode",{parentName:"p"},"make")," provide a simple and consistent interface into the container build stages.  The data pipeline challenges addresses with a multi-stage build pattern include:  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"automating lifecycle management of the Python packages used by data pipelines"),(0,r.kt)("li",{parentName:"ul"},"integrating smoke testing of container images to weed out compatibility issues early"),(0,r.kt)("li",{parentName:"ul"},"simplifying the developer experience with tools like ",(0,r.kt)("inlineCode",{parentName:"li"},"make")," that can be used both locally and in CI/CD pipelines")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Dockerfile")," contains the definitions of the different target build stages and order of execution from one stage to the next.  The ",(0,r.kt)("inlineCode",{parentName:"p"},"Makefile")," wraps the Dockerfile build targets into a standard set of workflow activities, following a similar to ",(0,r.kt)("inlineCode",{parentName:"p"},"$ config && make && make install")," "),(0,r.kt)("h2",{id:"the-dataops-container-lifecycle-workflow"},"The DataOps Container Lifecycle Workflow"),(0,r.kt)("p",null,"A typical dataops/gitops style workflow for maintaining container images includes actions in the local environment to define the required packages and produce the pinned dependency ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry.lock")," file or ",(0,r.kt)("inlineCode",{parentName:"p"},"requirements.txt")," packages list containing the full set of pinned dependent packages.  "),(0,r.kt)("p",null,"Given and existing project in a remote git repository with a CI/CD pipeline defined, the following workflow would be used to update package versions and dependencies:  "),(0,r.kt)(l.Z,{defaultValue:"flow",values:[{label:"Workflow",value:"flow"},{label:"PlantUML",value:"plantuml"}],mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"flow",mdxType:"TabItem"},(0,r.kt)("p",null,(0,r.kt)("a",{target:"_blank",href:a(1460).Z},(0,r.kt)("img",{alt:"Multi-stage build workflow",src:a(74333).Z,width:"540",height:"749"}))," ")),(0,r.kt)(o.Z,{value:"plantuml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plantuml"},"@startuml Multi-stage build workflow\n|Local Maintainer|\nstart\n:Clone git repository and\ncreate a feature branch;\n:Update declared\ndependencies;\n:Run build with\nrefresh option;\n:Update new pinned\npackages file in the\ngit repository;\n:Commit changes and push\nto remote repository;\n|Remote Git Service|\n:Validate feature branch\nchanges;\n:Merge changes into\nmain branch;\n:build target image and\npush to package registry;\n|Package Registry|\n:publish new image;\nstop\n@enduml\n")))),(0,r.kt)("p",null,"The image maintainer selects the packages to update or refresh using a local development environment, working from a feature branch.  This includes performing an image smoke-test to validate the changes within the container image.  "),(0,r.kt)("p",null,"Once refreshed image has been validated, the lock file or full pinned package list is commited back to the repository and pushed to the remote repository.  The CI/CD pipeline performs a trial build and conducts smoke testing.  On merge into the main branch, the target image is built, re-validated, and pushed to the container image registry.  "),(0,r.kt)("p",null,"The multi-stage build pattern can support both defining both the declared packages for an environment as well as the dependent packages, but ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry")," splits the two into distinct files, a ",(0,r.kt)("inlineCode",{parentName:"p"},"pyproject.toml")," file containing the declated packages and a ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry.lock")," file that contains the full set of declared and dependent packages, including pinned versions.  ",(0,r.kt)("inlineCode",{parentName:"p"},"pip")," supports loading packages from different files, but requires a convention for which requirements file contains the declared packages and while contains the full set of pinned package versions produced by ",(0,r.kt)("inlineCode",{parentName:"p"},"pip freeze"),".  The example code repo contains examples using both ",(0,r.kt)("inlineCode",{parentName:"p"},"pip")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry"),".  "),(0,r.kt)("p",null,"The following example uses ",(0,r.kt)("a",{parentName:"p",href:"https://python-poetry.org/"},"poetry")," in a ",(0,r.kt)("inlineCode",{parentName:"p"},"python:3.8")," base image to illustrate managing the dependencies and version pinning of python packages.  "),(0,r.kt)("h2",{id:"multi-stage-dockerfile"},"Multi-stage Dockerfile"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Dockerfile")," defines the build stages used for both local refresh and by the CICD pipelines to build the target image.  "),(0,r.kt)(l.Z,{defaultValue:"stages",values:[{label:"Stages",value:"stages"},{label:"PlantUML",value:"plantuml"}],mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"stages",mdxType:"TabItem"},(0,r.kt)("p",null,(0,r.kt)("a",{target:"_blank",href:a(41876).Z},(0,r.kt)("img",{alt:"Dockerfile Stages",src:a(54427).Z,width:"380",height:"425"}))," ")),(0,r.kt)(o.Z,{value:"plantuml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plantuml"},'@startuml Dockerfile stages\n!define C4_PLANTUML https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master\n!include C4_PLANTUML/C4_Component.puml\n\nHIDE_STEREOTYPE()\nUpdateElementStyle(Container, $bgColor=green)\n\nTitle: Docker build stages\nContainer(pre, base-pre-pkg,)\nContainer(refresh, python-pkg-refresh,)\nContainer(pinned, python-pkg-pinned,)\nContainer(post, base-post-pkg,)\nContainer(smoke, smoke-test,)\nContainer(target, target-image,)\n\nRel(pre, refresh, "refresh")\nRel(pre, pinned, "pinned")\nRel(refresh, post, " ")\nRel(pinned, post, " ")\nRel(post, smoke, "QA")\nRel(post, target, "artefact")\n@enduml\n')))),(0,r.kt)("p",null,"The Dockerfile makes use of the docker build arguments feature to pass in whether the build should refresh package versions or build the image from pinned packages.  "),(0,r.kt)("h3",{id:"build-stage-base-pre-pkg"},"Build Stage: base-pre-pkg"),(0,r.kt)("p",null,"Any image setup and pre-python package installation steps.  For ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry"),", this includes setting the config option to skip the creation of a virtual environment as the container already provides the required isolation.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"ARG PYTHON_PKG_VERSIONS=pinned\nFROM python:3.8 as base-pre-pkg\n\nRUN install -d /src && \\\n    pip install --no-cache-dir poetry==1.1.13 && \\\n    poetry config virtualenvs.create false\nWORKDIR /src\n")),(0,r.kt)("h3",{id:"build-stage-python-pkg-refresh"},"Build Stage: python-pkg-refresh"),(0,r.kt)("p",null,"The steps to generate a ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry.lock")," file containing the pinned package versions.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM base-pre-pkg as python-pkg-refresh\nCOPY pyproject.toml poetry.lock /src/\nRUN poetry update && \\\n    poetry install \n")),(0,r.kt)("h3",{id:"build-stage-python-pkg-pinned"},"Build Stage: python-pkg-pinned"),(0,r.kt)("p",null,"The steps to install packages using the pinned package versions."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM base-pre-pkg as python-pkg-pinned\nCOPY pyproject.toml poetry.lock /src/\nRUN poetry install \n")),(0,r.kt)("h3",{id:"build-stage-base-post-pkg"},"Build Stage: base-post-pkg"),(0,r.kt)("p",null,"A consolidation build target that can refer to either the python-pkg-refresh or the python-pkg-pinned stages, depending on the docker build argument and includes any post-package installation steps.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM python-pkg-${PYTHON_PKG_VERSIONS} as base-post-pkg\n")),(0,r.kt)("h3",{id:"build-stage-smoke-test"},"Build Stage: smoke-test"),(0,r.kt)("p",null,"Simple smoke tests and validation commands to validate the built image.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM base-post-pkg as smoke-test\nWORKDIR /src\nCOPY tests/ ./tests\nRUN poetry --version && \\\n    python ./tests/module_smoke_test.py\n")),(0,r.kt)("h3",{id:"build-stage-target-image"},"Build Stage: target-image"),(0,r.kt)("p",null,"The final build target container image.  Listing the ",(0,r.kt)("inlineCode",{parentName:"p"},"target-image")," as the last stage in the ",(0,r.kt)("inlineCode",{parentName:"p"},"Dockerfile")," has the effect of also making this the default build target.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM base-post-pkg as target-image\n")),(0,r.kt)("h2",{id:"multi-stage-makefile"},"Multi-stage Makefile"),(0,r.kt)("p",null,"The Makefile provides a workflow oriented wrapper over the Dockerfile build stage targets.  The Makefile targets can be executed both in a local development environment as well as via a CICD pipeline.  The ",(0,r.kt)("inlineCode",{parentName:"p"},"Makefile")," includes several variables that can either be run using default values, or overridden by the CI/CD pipeline.  "),(0,r.kt)(l.Z,{defaultValue:"targets",values:[{label:"Targets",value:"targets"},{label:"PlantUML",value:"plantuml"}],mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"targets",mdxType:"TabItem"},(0,r.kt)("p",null,(0,r.kt)("a",{target:"_blank",href:a(86695).Z},(0,r.kt)("img",{alt:"Makefile targets",src:a(57182).Z,width:"389",height:"338"}))," ")),(0,r.kt)(o.Z,{value:"plantuml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-plantuml"},'@startuml Makefile targets\n!define C4_PLANTUML https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master\n!include C4_PLANTUML/C4_Component.puml\n\nHIDE_STEREOTYPE()\n\nTitle: Makefile targets\nContainer(style, style-check,)\nContainer(refresh, python-pkg-refresh, "docker target=smoke-test")\nContainer(smoke, smoke-test, "docker target=smoke-test")\nContainer(build, build, "docker target=target-image")\n\nRel(style, refresh, " ")\nRel(style, build, " ")\nRel(build, smoke, " ")\n\n@enduml\n')))),(0,r.kt)("h2",{id:"make-target-style-check"},"Make Target: style-check"),(0,r.kt)("p",null,"Linting and style checking of source code.  Can include both application code as well as the Dockerfile itself using tools such as ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/hadolint/hadolint"},"hadolint"),".  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Makefile"},"style-check:\n    hadolint ./Dockerfile\n")),(0,r.kt)("h2",{id:"make-target-python-pkg-refresh"},"Make Target: python-pkg-refresh"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"python-pkg-refresh")," target builds a version of the target image with refreshed package versions. A temporary container instance is created from the target image and the ",(0,r.kt)("inlineCode",{parentName:"p"},"poetry.lock")," file is copied into the local file system. The ",(0,r.kt)("inlineCode",{parentName:"p"},"smoke-test")," docker build target is used to ensure image validation is also performed.\nThe temporary container as well as the package refresh image are removed after the build.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Makefile"},'python-pkg-refresh:\n    @echo ">> Update python packages in container image"\n    docker build ${DOCKER_BUILD_ARGS} \\\n           --target smoke-test \\\n           --build-arg PYTHON_PKG_VERSIONS=refresh \\\n           --tag ${TARGET_IMAGE_NAME}:$@ .\n    @echo ">> Copy the new poetry.lock file with updated package versions"\n    docker create --name ${TARGET_IMAGE_NAME}-$@ ${TARGET_IMAGE_NAME}:$@\n    docker cp ${TARGET_IMAGE_NAME}-$@:/src/poetry.lock .\n    @echo ">> Clean working container and refresh image"\n    docker rm ${TARGET_IMAGE_NAME}-$@\n    docker rmi ${TARGET_IMAGE_NAME}:$@\n')),(0,r.kt)("h3",{id:"make-target-build"},"Make Target: build"),(0,r.kt)("p",null,"The standard build target using pinned python package versions.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Makefile"},"build:\n    docker build ${DOCKER_BUILD_ARGS} \\\n           --target target-image \\\n           --tag ${TARGET_IMAGE_NAME}:${BUILD_TAG} .\n\n")),(0,r.kt)("h3",{id:"make-target-smoke-test"},"Make Target: smoke-test"),(0,r.kt)("p",null,"Builds an image and peforms smoke testing.  The smoke-testing image is removed after the build.  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Makefile"},"smoke-test:\n    docker build ${DOCKER_BUILD_ARGS} \\\n           --target smoke-test \\\n           --tag ${TARGET_IMAGE_NAME}:$@ .\n    docker rmi ${TARGET_IMAGE_NAME}:$@\n")),(0,r.kt)("h2",{id:"conclusion"},"Conclusion"),(0,r.kt)("p",null,"The toolchain combination of multi-stage container image builds with ",(0,r.kt)("inlineCode",{parentName:"p"},"make")," provides a codified method for the lifecycle management of the containers used in data science and data engineering workloads.  "),(0,r.kt)("p",null,"The maintainer:  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'git checkout -b my-refresh-feature\nmake python-pkg-refresh\nmake smoke-test\ngit add pyproject.toml poetry.lock\ngit commit -m "python package versions updated"\ngit push\n')),(0,r.kt)("p",null,"The CICD pipeline:  "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"make build\nmake smoke-test\ndocker push <target-image>:<build-tag>\n")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"You can find the complete source code for this article at ",(0,r.kt)("a",{parentName:"p",href:"https://gitlab.com/datwiz/multistage-pipeline-image-builds"},"https://gitlab.com/datwiz/multistage-pipeline-image-builds"))))}k.isMDXComponent=!0},3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return g}});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),d=p(a),g=i,m=d["".concat(s,".").concat(g)]||d[g]||c[g]||r;return a?n.createElement(m,l(l({ref:t},u),{},{components:a})):n.createElement(m,l({ref:t},u))}));function g(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,l=new Array(r);l[0]=d;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,l[1]=o;for(var p=2;p<r;p++)l[p]=a[p];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},41876:function(e,t,a){t.Z=a.p+"assets/files/Dockerfile-stages-097c44de43a3057961052ec16b2848cf.png"},86695:function(e,t,a){t.Z=a.p+"assets/files/Makefile-targets-777beb960ef5b7b68e396310bd409f3c.png"},1460:function(e,t,a){t.Z=a.p+"assets/files/multi-stage-build-workflow-87a8fcc972f27832eb913441f9382786.png"},54427:function(e,t,a){t.Z=a.p+"assets/images/Dockerfile-stages-097c44de43a3057961052ec16b2848cf.png"},57182:function(e,t,a){t.Z=a.p+"assets/images/Makefile-targets-777beb960ef5b7b68e396310bd409f3c.png"},74333:function(e,t,a){t.Z=a.p+"assets/images/multi-stage-build-workflow-87a8fcc972f27832eb913441f9382786.png"}}]);