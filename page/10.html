<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Cloudy with a chance of Big Data Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Cloudy with a chance of Big Data Blog Feed Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4N6KSJ2G0P"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-4N6KSJ2G0P",{})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Cloudy with a chance of Big Data" href="/opensearch.xml"><title data-react-helmet="true">Cloudy with a chance of Big Data | Cloudy with a chance of Big Data</title><meta data-react-helmet="true" property="og:title" content="Cloudy with a chance of Big Data | Cloudy with a chance of Big Data"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="description" content="Cloud and data design patterns and random musings"><meta data-react-helmet="true" property="og:description" content="Cloud and data design patterns and random musings"><meta data-react-helmet="true" property="og:url" content="https://cloudywithachanceofbigdata.com/page/10"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://cloudywithachanceofbigdata.com/page/10"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/page/10" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/page/10" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d8b73325.css">
<link rel="preload" href="/assets/js/runtime~main.e8bf8f37.js" as="script">
<link rel="preload" href="/assets/js/main.6b4a7196.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_2qcr"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title">Cloudy with a chance of Big Data</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/tags">Topics</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_71bT toggle_3Zt9 toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">üåú</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">üåû</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/automating-snowflake-role-based-storage-integration-for-aws">Automating Snowflake Role Based Storage Integration for AWS</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simplifying-large-cloudformation-templates-using-jsonnet">Simplifying Large CloudFormation Templates using Jsonnet</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/aws-deployments-with-cloudformation-and-gitlab-ci">Simplified AWS Deployments with CloudFormation and GitLab CI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/from-wordpress-to-jamstack">From Wordpress to Jamstack</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/using-jsonnet-to-configure-multiple-environments">Using Jsonnet to Configure Multiple Environments</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/use-bigquery-to-trigger-cloud-run">Use BigQuery to trigger Cloud Run</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/azure-static-web-app-review">Azure Static Web App Review</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/introducing-the-metadata-hub-mdh">Introducing the Metadata Hub (MDH)</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/masking-private-keys-in-ci-cd-pipelines-in-gitlab">Masking Private Keys in CI/CD Pipelines in GitLab</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simple-tasker-configuration-driven-orchestration">Simple Tasker: Configuration driven orchestration</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/infrastructure-automation-using-aws-lambda">Infrastructure Automation using AWS Lambda</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-15T00:00:00.000Z" itemprop="datePublished">January 15, 2019</time> ¬∑ <!-- -->2 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/automate-infrastructure-tasks-using-lambda-with-terraform.png"><div class="markdown" itemprop="articleBody"><p>There are many other blog posts and examples available for either scheduling infrastructure tasks such as the starting or stopping of EC2 instances; or deploying a Lambda function using Terraform. However, I have found many of the other examples to be unnecessarily complicated, so I have put together a very simple example doing both.</p><p>The function itself could be easily adapted to take other actions including interacting with other AWS services using the boto3 library (the Python AWS SDK). The data payload could be modified to pass different data to the function as well.</p><p>The script only requires input variables for <strong><em>schedule<!-- -->_<!-- -->expression</em></strong> (cron schedule based upon GMT for triggering the function ‚Äì could also be expressed as a rate, e.g. <strong><em>rate(5 minutes))</em></strong> and <strong><em>environment</em></strong> (value passed to the function on each invocation). In this example the Input data is the value for the ‚ÄúEnvironment‚Äù key for an EC2 instance tag ‚Äì a user defined tag to associate the instance to a particular environment (e.g. Dev, Test. Prod). The key could be changed as required, for instance if you wanted to stop instances based upon their given name or part thereof you could change the tag key to be ‚ÄúName‚Äù.</p><p>When triggered, the function will stop all running EC2 instances with the given Environment tag.</p><p>The Terraform script creates:</p><ul><li>an IAM Role and associated policy for the Lambda Function</li><li>the Lambda function</li><li>a Cloudwatch event rule and trigger</li></ul><p>The IAM role and policies required for the Lambda function are deployed as shown here:</p><iframe width="100%" frameborder="0" id="gist-6b8ed7c149a60e823361ee282615b826"></iframe><p>The function source code is packaged into a ZIP archive and deployed using Terraform as follows:</p><iframe width="100%" frameborder="0" id="gist-ca6a26a62302ff809eae028bbfb28b41"></iframe><p>Admittedly Terraform is an infrastructure automation tool and not a build/packaging tool (such as Jenkins, etc), but in this case the packaging only involves zipping up the function source code, so Terraform can be used as a ‚Äòone stop shop‚Äô to keep things simple.</p><p>The Cloudwatch schedule trigger is deployed as follows:</p><iframe width="100%" frameborder="0" id="gist-7920fda821eb4f03d8ba942da572180c"></iframe><p>Use the following commands to run this example (I have created a default credentials profile, but you could supply your API credentials directly, use STS, etc):</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">cd simple-lambda-ec2-scheduler</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">terraform init</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">terraform apply</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p><img alt="Terraform output" src="/assets/images/terraform-screenshot-2f677526d3d3dc10870393e11e6e85b8.png"></p><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/simple-lambda-ec2-scheduler" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/simple-lambda-ec2-scheduler</strong></a></em></p></blockquote><p>Stay tuned for more simple Terraform deployment recipes in coming posts‚Ä¶</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/aws">aws</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/automation">automation</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/boto-3">boto3</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/cloudwatch">cloudwatch</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/ec-2">ec2</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/lambda">lambda</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/python">python</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/scheduled-tasks">scheduled-tasks</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/terraform">terraform</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/multi-stage-etl-framework-using-spark-sql">Multi Stage ETL Framework using Spark SQL</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-09T00:00:00.000Z" itemprop="datePublished">January 9, 2019</time> ¬∑ <!-- -->3 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/spark-sql-etl-framework.png"><div class="markdown" itemprop="articleBody"><p>Most traditional data warehouse or datamart ETL routines consist of multi stage SQL transformations, often a series of CTAS (<code>CREATE TABLE AS SELECT</code>) statements usually creating transient or temporary tables ‚Äì such as volatile tables in Teradata or Common Table Expressions (CTE‚Äôs).</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</h5></div><div class="admonition-content"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The initial challenge when moving from a SQL/MPP based ETL framework platformed on Oracle, Teradata, SQL Server, etc to a Spark based ETL framework is what to do with this‚Ä¶</p><p><img alt="Multi Stage SQL Based ETL" src="/assets/images/multi-stage-sql-1b6298de71ac35e0ecde3af82a831be6.png"></p><p>One approach is to use the lightweight, configuration driven, multi stage Spark SQL based ETL framework described in this post.</p><p>This framework is driven from a YAML configuration document. YAML was preferred over JSON as a document format as it allows for multi-line statements (SQL statements), as well as comments - which are very useful as SQL can sometimes be undecipherable even for the person that wrote it.</p><p>The YAML config document has three main sections: <strong><code>sources</code></strong>, <strong><code>transforms</code></strong> and <strong><code>targets</code></strong>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="sources">Sources<a aria-hidden="true" class="hash-link" href="#sources" title="Direct link to heading">‚Äã</a></h3><p>The <strong><code>sources</code></strong> section is used to configure the input data source(s) including optional column and row filters. In this case the data sources are tables available in the Spark catalog (for instance the AWS Glue Catalog or a Hive Metastore), this could easily be extended to read from other datasources using the Spark DataFrameReader API.</p><iframe width="100%" frameborder="0" id="gist-eaf03229466718ee125e0a6d23370f1b"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="transforms">Transforms<a aria-hidden="true" class="hash-link" href="#transforms" title="Direct link to heading">‚Äã</a></h3><p>The <strong><code>transforms</code></strong> section contains the multiple SQL statements to be run in sequence where each statement creates a temporary view using objects created by preceding statements.</p><iframe width="100%" frameborder="0" id="gist-89ad7ac6b036e5f22b2d3dec43b1fe44"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="targets">Targets<a aria-hidden="true" class="hash-link" href="#targets" title="Direct link to heading">‚Äã</a></h3><p>Finally the <strong><code>targets</code></strong> section writes out the final object or objects to a specified destination (S3, HDFS, etc).</p><iframe width="100%" frameborder="0" id="gist-5af780dd6b6e5ddd79a4cac8a59e6a69"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="process-sql-statements">Process SQL Statements<a aria-hidden="true" class="hash-link" href="#process-sql-statements" title="Direct link to heading">‚Äã</a></h3><p>The <strong><code>process_sql_statements.py</code></strong> script that is used to execute the framework is very simple (30 lines of code not including comments, etc). It loads the sources into Spark Dataframes and then creates temporary views to reference these datasets in the <strong><code>transforms</code></strong> section, then sequentially executes the SQL statements in the list of transforms. Lastly the script writes out the final view or views to the desired destination ‚Äì in this case parquet files stored in S3 were used as the target.</p><p>You could implement an object naming convention such as prefixing object names with <code>sv_</code>, <code>iv_</code>, <code>fv_</code> (for source view, intermediate view and final view respectively) if this helps you differentiate between the different objects.</p><p>To use this framework you would simply use <strong><code>spark-submit</code></strong> as follows:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit process_sql_statements.py config.yml</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/spark-sql-etl-framework" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/spark-sql-etl-framework</strong></a></em></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/etl">etl</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/spark">spark</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/sql">sql</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/cost-of-future-change">The Cost of Future Change</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-01T00:00:00.000Z" itemprop="datePublished">January 1, 2019</time> ¬∑ <!-- -->4 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/changes-ahead.jpg"><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="what-we-should-really-be-focused-on-but-no-one-is">what we should really be focused on (but no one is‚Ä¶)<a aria-hidden="true" class="hash-link" href="#what-we-should-really-be-focused-on-but-no-one-is" title="Direct link to heading">‚Äã</a></h3><p><img alt="Cost of Future Change" src="/assets/images/changes-ahead-3d37059d33dcbf66b5d0157808722f40.jpg"></p><p>In my thirty year career in Technology I can‚Äôt think of a more profound period of change. It is not as if change never existed previously, it did. Innovation and Moore&#x27;s law have been constant features in technology. However, for decades we had experienced a long period of relativity stability. That is, the rate of change was somewhat fixed. This was largely due to the fact that change, for the most part, was dictated almost entirely by a handful of large companies (such as Oracle, Microsoft, IBM, SAP, etc.). We, the technology community, were exclusively at the mercy of the product management teams at these companies dreaming up the next new feature, and we were subject to the tech giant‚Äôs product release cycle as to when we could use this feature. The rate of change was therefore artificially suppressed to a degree.</p><p>Then along came the open source software revolution. I can recall being fortunate enough to be in a meeting with Steve Ballmer along with a small group of Microsoft partners in Sydney, Australia around 2002. I can remember him as a larger than life figure with a booming voice and an intense presence. I can vividly remember him going on a long diatribe about Open Source Software, primarily focused around Linux. To put some historical context around it, Linux was a fringe technology at best at that point in time ‚Äì nobody was taking it seriously in the enterprise. The Apache Software Foundation wasn‚Äôt a blip on the radar at the time, Software-as-a-Service was in its infancy, and Platform-as-a-Service and cloud were non-factors ‚Äì so what was he worried about?</p><p>From the fear instilled in his rant, you would have thought this was going to be the end of humanity as we knew it. Well it was the beginning of the end, the end of the halcyon days of the software industry as we knew it. The early beginnings of the end of the monopoly on change held by a select few software vendors. The beginning of the democratisation of change.</p><p>Fast forward fifteen years, and now everyone is a (potential) software publisher. Real world problems are solved in real companies and in many cases software products are created, published and made (freely) available to other companies. We have seen countless examples of this pattern, Hadoop at Yahoo!, Kafka at LinkedIn, Airflow at Airbnb, to name a few. Then there are companies created with scant capital or investment, driven by a small group of smart people focused on solving a problem or streamlining a process that they have encountered in the real world. Many of these companies growing to be globally recognised names, such as Atlassian or Hashicorp.</p><p>The rate of change is no longer suppressed to the privileged few ‚Äì in fact we have an explosion of change. No longer do we have a handful of technology options to achieve a desired outcome or solve a particular problem, we have a constellation of options.</p><p>Now the bad news, the force multiplier in change created by open source communities cuts both ways. When the community is behind a project it gets hyper-charged, conversely when the community drops off, functionality and stability drop off just as quickly.</p><p>This means there are components, projects, modules, services we are using today that won‚Äôt be around in the same format in 2-3 years‚Äô time. There are products that don‚Äôt exist today that will be integral (and potentially critical) to our operations in 1-2 years‚Äô time.</p><p>This brings me to my final point ‚Äì the cost of future change. We as leaders and custodians of technology in this period should not only factor in current day run costs or the cost of change we know about (the cost of current change), but the hidden cost of future change. We need to think that whatever we are doing now is not what we will be doing in a years‚Äô time ‚Äì we will need to accommodate future change.</p><p>We need to be thinking about the cost of future change and what we can do to minimise this. This means not just swapping out one system for another, but thinking about how you will change this system or component again in the near future. We need to take the opportunity that is in front of us to replace monoliths with modular systems, move from tightly coupled to loosely coupled components, from proprietary systems to open systems, from rigid architectures to extensible architectures.</p><p>When you‚Äôre planning a change today, consider the cost of future change‚Ä¶</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/change">change</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/open-source-software">open-source-software</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/technology">technology</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/page/9"><div class="pagination-nav__label">¬´<!-- --> <!-- -->Newer Entries</div></a></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items"><li class="footer__item"><a href="https://infraql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>InfraQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/assets/js/runtime~main.e8bf8f37.js"></script>
<script src="/assets/js/main.6b4a7196.js"></script>
</body>
</html>