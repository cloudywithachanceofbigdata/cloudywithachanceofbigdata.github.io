<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.18">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Full Stack Chronicles Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Full Stack Chronicles Blog Feed Atom Feed">
<link rel="alternate" type="application/json" href="/feed.json" title="Full Stack Chronicles Blog Feed JSON Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0FVDC1E8G6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0FVDC1E8G6",{})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Full Stack Chronicles" href="/opensearch.xml"><title data-rh="true">Full Stack Chronicles | Full Stack Chronicles</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://fullstackchronicles.io/page/10"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="wot-verification" content="e7522390be4370727fac"><meta data-rh="true" property="og:title" content="Full Stack Chronicles | Full Stack Chronicles"><meta data-rh="true" name="description" content="Full stack design patterns and random musings"><meta data-rh="true" property="og:description" content="Full stack design patterns and random musings"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://fullstackchronicles.io/page/10"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/page/10" hreflang="en"><link data-rh="true" rel="alternate" href="https://fullstackchronicles.io/page/10" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MZCGVO503N-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.77ea11e8.css">
<link rel="preload" href="/assets/js/runtime~main.c44711ab.js" as="script">
<link rel="preload" href="/assets/js/main.ef28b439.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><div class="announcementBar_IbjG" style="background-color:#A9BCD0;color:#1A4E82" role="banner"><div class="announcementBarPlaceholder_NC_W"></div><div class="announcementBarContent_KsVm"><b>If you find our content useful, give it a ⭐️ on <a target="_blank" rel="noopener noreferrer" href="https://github.com/stackql/fullstackchronicles.io">GitHub</a>, if you want to contribute and become an author, submit a PR</b></div><button type="button" class="clean-btn close announcementBarClose_FG1z" aria-label="Close"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top navbarHideable_ObN2 navbar--primary"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/full-stack-logo-transparent.svg" alt="Full Stack Chronicles" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Full Stack Chronicles</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/tags">Topics</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/snowflake">Snowflake</a></li><li><a class="dropdown__link" href="/tags/okta">Okta</a></li><li><a class="dropdown__link" href="/tags/spark">Spark</a></li><li><a class="dropdown__link" href="/tags/kafka">Kafka</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_qEbK"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/using-the-snowflake-sql-api-with-typescript">Using the Snowflake SQL API with TypeScript</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/split-a-large-swagger-openapi-specification-into-smaller-documents">Split a large Open API or Swagger Specification into smaller documents</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/stream-processing-with-spark-structured-streaming-kafka-and-snowflake-using-python">Stream Processing with Spark Structured Streaming, Kafka and Snowflake using Python</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/simple-cli-pkce-auth-using-okta">Simple CLI Application to Login to Okta using PKCE</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/cloudy-with-a-chance-of-big-data-has-moved">Cloudy with a Chance of Big Data has Moved</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/scaling-up-prefect-with-gitstorage">Scaling up Prefect with GitStorage</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/implementing-a-serverless-sftp-gateway-using-the-aws-transfer-family">Implementing a Serverless SFTP Gateway using the AWS Transfer Family</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/simple-sso-with-an-external-idp-using-active-directory-and-okta">Simple SSO with an external IdP using Active Directory and Okta</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/converting-to-local-time-in-aws-lambda-using-nodejs">Converting to local time in AWS Lambda using Node.js</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/automating-snowflake-role-based-storage-integration-for-aws">Automating Snowflake Role Based Storage Integration for AWS</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/change-data-capture-at-scale-using-spark">Change Data Capture at Scale using Spark</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2019-06-28T00:00:00.000Z" itemprop="datePublished">June 28, 2019</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://fullstackchronicles.io/images/CDC-using-Spark.png"><div class="markdown" itemprop="articleBody"><p>Change Data Capture (CDC) is one of the most challenging processing patterns to implement at scale. I personally have had several cracks at this using various different frameworks and approaches, the most recent of which was implemented using Spark – and I think I have finally found the best approach. Even though the code examples referenced use Spark, the pattern is language agnostic – the focus is on the approach not the specific implementation (as this could be applied to any framework or runtime).</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Spark Training Courses</h5></div><div class="admonition-content"><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p></div></div><p>The first challenge you are faced with, is to compare a very large dataset (representing the current state of an object) with another potentially very large dataset (representing new or incoming data). Ideally, you would like the process to be configuration driven and accommodate such things as composite primary keys, or operational columns which you would like to restrict from change detection. You may also want to implement a pattern to segregate sensitive attributes from non-sensitive attributes.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="overview">Overview<a class="hash-link" href="#overview" title="Direct link to heading">​</a></h2><p>This pattern (and all my other recent attempts) is fundamentally based upon calculating a deterministic hash of the key and non-key attribute(s), and then using this hash as the basis for comparison. The difference between this pattern and my other attempts is in the distillation and reconstitution of data during the process, as well as breaking the pattern into discrete stages (designed to minimize the impact to other applications). This pattern can be used to process delta or full datasets.</p><p>A high-level flowchart representing the basic pattern is shown here:</p><p><a target="_blank" href="/assets/files/CDC-59f029c756f942661da9a4744801d227.png"><img loading="lazy" alt="CDC Flowchart" src="/assets/images/CDC-59f029c756f942661da9a4744801d227.png" width="382" height="1118" class="img_E7b_"></a></p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-example">The Example<a class="hash-link" href="#the-example" title="Direct link to heading">​</a></h2><p>The example provided uses the <a href="https://github.com/avensolutions/synthetic-cdc-data-generator" target="_blank" rel="noopener noreferrer">Synthetic CDC Data Generator application</a>, configuring an incoming set with 5 uuid columns acting as a composite key, and 10 random number columns acting as non key values. The initial days payload consists of 10,000 records, the subsequent days payload consists of another 10,000 records. From the initial dataset, a <code>DELETE</code> operation was performed at the source system for 20% of records, an <code>UPDATE</code> was performed on 40% of the records and the remaining 40% of records were unchanged. In this case the 20% of records that were deleted at the source, were replaced by new <code>INSERT</code> operations creating new keys.</p><p>After creating the synthesized day 1 and day 2 datasets, the files are processed as follows:</p><p>$ spark-submit cdc.py config.yaml data/day1 2019-06-18<br>
<!-- -->$ spark-submit cdc.py config.yaml data/day2 2019-06-19</p><p>Where <code>config.yaml</code> is the configuration for the dataset, data/day1 and data/day2 represent the different data files, and 2019-06-18 and 2019-06-19 represent a business effective date.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-results">The Results<a class="hash-link" href="#the-results" title="Direct link to heading">​</a></h2><p>You should see the following output from running the preceding commands for day 1 and day 2 respectively:</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="day-1">Day 1:<a class="hash-link" href="#day-1" title="Direct link to heading">​</a></h3><iframe width="100%" frameborder="0" id="gist-b75edc7825b46c12b328d78d47b4b902"></iframe><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="day-2">Day 2:<a class="hash-link" href="#day-2" title="Direct link to heading">​</a></h3><iframe width="100%" frameborder="0" id="gist-ca92e132105fb5bb381bf9dfca562bf4"></iframe><p>A summary analysis of the resultant dataset should show:</p><iframe width="100%" frameborder="0" id="gist-ded1f98dc4fce13c9bb3d12a51a46b94"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="pattern-details">Pattern Details<a class="hash-link" href="#pattern-details" title="Direct link to heading">​</a></h2><p>Details about the pattern and its implementation follow.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="current-and-historical-datasets">Current and Historical Datasets<a class="hash-link" href="#current-and-historical-datasets" title="Direct link to heading">​</a></h3><p>The output of each operation will yield a current dataset (that is the current stateful representation of a give object) and a historical dataset partition (capturing the net changes from the previous state in an appended partition).</p><p>This is useful, because often consumers will primarily query the latest state of an object. The change sets (or historical dataset partitions) can be used for more advanced analysis by sophisticated users.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="type-2-scds-sort-of">Type 2 SCDs (sort of)<a class="hash-link" href="#type-2-scds-sort-of" title="Direct link to heading">​</a></h3><p>Two operational columns are added to each current and historical object:</p><ul><li><code>OPERATION</code> : Represents the last known operation to the record, valid values include :<ul><li><code>I</code> (<code>INSERT</code>)</li><li><code>U</code> (<code>UPDATE</code>)</li><li><code>D</code> (<code>DELETE</code> – hard <code>DELETE</code>s, applies to full datasets only)</li><li><code>X</code> (Not supplied, applies to delta processing only)</li><li><code>N</code> (No change)</li></ul></li><li><code>EFF_START_DATE</code></li></ul><p>Since data structures on most big data or cloud storage platforms are immutable, we only store the effective start date for each record, this is changed as needed with each coarse-grained operation on the current object. The effective end date is inferred by the presence of a new effective start date (or change in the <code>EFF_START_DATE</code> value for a given record).</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-configuration">The Configuration<a class="hash-link" href="#the-configuration" title="Direct link to heading">​</a></h3><p>I am using a YAML document to store the configuration for the pattern. Important attributes to include in your configuration are a list of keys and non keys and their datatype (this implementation does type casting as well). Other important attributes include the table names and file paths for the current and historical data structures.</p><p>The configuration is read at the beginning of a routine as an input along with the path of an incoming data file (a CSV file in this case) and a business effective date (which will be used as the <code>EFF_START_DATE</code> for new or updated records).</p><p>Processing is performed using the specified key and non key attributes and the output datasets (current and historical) are written to columnar storage files (parquet in this case). This is designed to make subsequent access and processing more efficient.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-algorithm">The Algorithm<a class="hash-link" href="#the-algorithm" title="Direct link to heading">​</a></h3><p>I have broken the process into stages as follows:</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="stage-1--type-cast-and-hash-incoming-data">Stage 1 – Type Cast and Hash Incoming Data<a class="hash-link" href="#stage-1--type-cast-and-hash-incoming-data" title="Direct link to heading">​</a></h4><p>The first step is to create deterministic hashes of the configured key and non key values for incoming data. The hashes are calculated based upon a list of elements representing the key and non key values using the MD5 algorithm. The hashes for each record are then stored with the respective record. Furthermore, the fields are casted their target datatype as specified in the configuration. Both of these operations can be performed in a single pass of each row using a <code>map()</code> operation.</p><p>Importantly we only calculate hashes once upon arrival of new data, as the hashes are persisted for the life of the data – and the data structures are immutable – the hashes should never change or be invalidated.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="stage-2--determine-inserts">Stage 2 – Determine INSERTs<a class="hash-link" href="#stage-2--determine-inserts" title="Direct link to heading">​</a></h4><p>We now compare Incoming Hashes with previously calculated hash values for the (previous day’s) current object. If no current object exists for the dataset, then it can be assumed this is a first run. In this case every record is considered as an <code>INSERT</code> with an <code>EFF_START_DATE</code> of the business effective date supplied.</p><p>If there is a current object, then the key and non key hash values (only the hash values) are read from the current object. These are then compared to the respective hashes of the incoming data (which should still be in memory).</p><p>Given the full outer join:</p><p>incoming<!-- -->_<!-- -->data(keyhash, nonkeyhash)
FULL OUTER JOIN<br>
<!-- -->current<!-- -->_<!-- -->data(keyhash, nonkeyhash)
ON keyhash</p><p>Keys which exist in the left entity which do not exist in the right entity must be the results of an INSERT operation.</p><p>Tag these records with an operation of <code>I</code> with an <code>EFF_START_DATE</code> of the business effective date, then rejoin only these records with their full attribute payload from the incoming dataset. Finally, write out these records to the current and historical partition in <code>overwrite</code> mode.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="stage-3---determine-deletes-or-missing-records">Stage 3 - Determine DELETEs or Missing Records<a class="hash-link" href="#stage-3---determine-deletes-or-missing-records" title="Direct link to heading">​</a></h4><p>Referring the previous full outer join operation, keys which exist in the right entity (current object) which do not appear in the left entity (incoming data) will be the result of a (hard) <code>DELETE</code> operation if you are processing full snapshots, otherwise if you are processing deltas these would be missing records (possibly because there were no changes at the source).</p><p>Tag these records as <code>D</code> or <code>X</code> respectively with an <code>EFF_START_DATE</code> of the business effective date, rejoin these records with their full attribute payload from the current dataset, then write out these records to the current and historical partition in <code>append</code> mode.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="stage-4---determine-updates-or-unchanged-records">Stage 4 - Determine UPDATEs or Unchanged Records<a class="hash-link" href="#stage-4---determine-updates-or-unchanged-records" title="Direct link to heading">​</a></h4><p>Again, referring to the previous full outer join, keys which exist in both the incoming and current datasets must be either the result of an <code>UPDATE</code> or they could be unchanged. To determine which case they fall under, compare the non key hashes. If the non key hashes differ, it must have been a result of an <code>UPDATE</code> operation at the source, otherwise the record would be unchanged.</p><p>Tag these records as <code>U</code> or <code>N</code> respectively with an <code>EFF_START_DATE</code> of the business effective date (in the case of an update - otherwise maintain the current <code>EFF_START_DATE</code>), rejoin these records with their full attribute payload from the incoming dataset, then write out these records to the current and historical partition in <code>append</code> mode.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="key-callouts">Key Callouts<a class="hash-link" href="#key-callouts" title="Direct link to heading">​</a></h3><p>A summary of the key callouts from this pattern are:</p><ul><li>Use the RDD API for iterative record operations (such as type casting and hashing)</li><li>Persist hashes with the records</li><li>Use Dataframes for <code>JOIN</code> operations</li><li>Only perform <code>JOIN</code>s with the <code>keyhash</code> and <code>nonkeyhash</code> columns – this minimizes the amount of data shuffled across the network</li><li>Write output data in columnar (Parquet) format</li><li>Break the routine into stages, covering each operation, culminating with a <code>saveAsParquet()</code> action – this may seem expensive but for large datsets it is more efficient to break down DAGs for each operation</li><li>Use caching for objects which will be reused between actions</li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="metastore-integration">Metastore Integration<a class="hash-link" href="#metastore-integration" title="Direct link to heading">​</a></h4><p>Although I did not include this in my example, you could easily integrate this pattern with a metastore (such as a Hive metastore or AWS Glue Catalog), by using table objects and <code>ALTER TABLE</code> statements to add historical partitions.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="further-optimisations">Further optimisations<a class="hash-link" href="#further-optimisations" title="Direct link to heading">​</a></h4><p>If the incoming data is known to be relatively small (in the case of delta processing for instance), you could consider a broadcast join where the smaller incoming data is distributed to all of the different Executors hosting partitions from the current dataset.</p><p>Also you could add a key to the column config to configure a column to be nullable or not.</p><p>Happy CDCing!</p><blockquote><p>Full source code for this article can be found at: <a href="https://github.com/avensolutions/cdc-at-scale-using-spark" target="_blank" rel="noopener noreferrer">https://github.com/avensolutions/cdc-at-scale-using-spark</a></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/big-data">big-data</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/cdc">cdc</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/pyspark">pyspark</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/python">python</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/spark">spark</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/synthetic-cdc-data-generator">Synthetic CDC Data Generator</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2019-06-28T00:00:00.000Z" itemprop="datePublished">June 28, 2019</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>This is a simple routine to generate random data with a configurable number or records, key fields and non key fields to be used to create synthetic data for source change data capture (CDC) processing. The output includes an initial directory containing CSV files representing an initial data load, and an incremental directory containing CSV files representing incremental data.</p><p>Spark Training Courses from the AlphaZetta Academy</p><p><a href="https://academy.alphazetta.ai/data-transformation-and-analysis-using-apache-spark/" target="_blank" rel="noopener noreferrer">Data Transformation and Analysis Using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/stream-and-event-processing-using-apache-spark/" target="_blank" rel="noopener noreferrer">Stream and Event Processing using Apache Spark</a><br>
<a href="https://academy.alphazetta.ai/advanced-analytics-using-apache-spark/" target="_blank" rel="noopener noreferrer">Advanced Analytics Using Apache Spark</a></p><p>Arguments (by position) include:</p><ul><li><code>no_init_recs</code> : the number of initial records to generate</li><li><code>no_incr_recs</code> : the number of incremental records on the second run - should be <code>&gt;= no_init_recs</code></li><li><code>no_keys</code> : number of key columns in the dataset – keys are generated as UUIDs</li><li><code>no_nonkeys</code> : number of non-key columns in the dataset – nonkey values are generated as random numbers</li><li><code>pct_del</code> : percentage of initial records deleted on the second run - between 0.0 and 1.0</li><li><code>pct_upd</code> : percentage of initial records updated on the second run - between 0.0 and 1.0</li><li><code>pct_unchanged</code> : percentage of records unchanged on the second run - between 0.0 and 1.0</li><li><code>initial_output</code> : folder for initial output in CSV format</li><li><code>incremental_output</code> : folder for incremental output in CSV format</li></ul><p>NOTE : <code>pct_del</code> + <code>pct_upd</code> + <code>pct_unchanged</code> must equal 1.0</p><p>Example usage:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx" style="color:#393A34;background-color:#f6f8fa"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">$ spark-submit synthetic-cdc-data-generator.py 100000 100000 2 3 0.2 0.4 0.4 data/day1 data/day2</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" title="Copy" class="copyButton_eDfN clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div><p>Example output from the <strong><em>day1</em></strong> run for the above configuration would look like this:</p><iframe width="100%" frameborder="0" id="gist-befb034da2b4f25a1dbbc0e9b4b8eef6"></iframe><p>Note that this routine can be run subsequent times producing different key and non key values each time, as the keys are UUIDs and the values are random numbers.</p><p>We will use this application to generate random input data to demonstrate CDC using Spark in a subsequent post, see you soon!</p><blockquote><p>Full source code can be found at: <a href="https://github.com/avensolutions/synthetic-cdc-data-generator" target="_blank" rel="noopener noreferrer">https://github.com/avensolutions/synthetic-cdc-data-generator</a></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/cdc">cdc</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/python">python</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/spark">spark</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/scalable-secure-application-load-balancing-with-vpc-native-gke-and-istio">Scalable, Secure Application Load Balancing with VPC Native GKE and Istio</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2019-05-18T00:00:00.000Z" itemprop="datePublished">May 18, 2019</time> · <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://fullstackchronicles.io/images/istio-blog-feature-image.png"><div class="markdown" itemprop="articleBody"><p>At the time of this writing, GCP does not have a generally available non-public facing Layer 7 load balancer. While this is sure to change in the future, this article outlines a design pattern which has been proven to provide scalable and extensible application load balancing services for multiple applications running in Kubernetes pods on GKE.</p><p>When you create a service of type LoadBalancer in GKE, Kubernetes hooks into the provider (GCP in this case) on your behalf to create a Google Load Balancer, while this may be specified as INTERNAL, there are two issues:</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="issue-1">Issue #1:<a class="hash-link" href="#issue-1" title="Direct link to heading">​</a></h3><p>The GCP load balancer created for you is a Layer 4 TCP load balancer.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="issue-2">Issue #2:<a class="hash-link" href="#issue-2" title="Direct link to heading">​</a></h3><p>The normal behaviour is for Google to enumerate all of the node pools in your GKE cluster and “automagically” create mapping GCE instance groups for each node pool for each zone the instances are deployed in. This means the entire surface area of your cluster is exposed to the external network – which may not be optimal for internal applications on a multi tenanted cluster.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-solution">The Solution:<a class="hash-link" href="#the-solution" title="Direct link to heading">​</a></h3><p>Using <a href="https://istio.io/" target="_blank" rel="noopener noreferrer">Istio</a> deployed on GKE along with the <a href="https://istio.io/docs/concepts/traffic-management/#ingress-and-egress" target="_blank" rel="noopener noreferrer">Istio Ingress Gateway</a> along with an externally created load balancer, it is possible to get scalable HTTP load balancing along with all the normal ALB goodness (stickiness, path-based routing, host-based routing, health checks, TLS offload, etc.).</p><p>An abstract depiction of this architecture is shown here:</p><p><a target="_blank" href="/assets/files/istio-ingress-blog-7f3d087a733de5cfabac40cf44b99bba.png"><img loading="lazy" alt="Istio Ingress Design Pattern for VPC Native GKE Clusters" src="/assets/images/istio-ingress-blog-7f3d087a733de5cfabac40cf44b99bba.png" width="942" height="268" class="img_E7b_"></a></p><p>This can be deployed with a combination of <a href="https://www.terraform.io/" target="_blank" rel="noopener noreferrer">Terraform</a> and kubectl. The steps to deploy at a high level are:</p><ol><li>Create a GKE cluster with at least two node pools: ingress-nodepool and service-nodepool. Ideally create these node pools as multi-zonal for availability. You could create additional node pools for your Egress Gateway or an operations-nodepool to host Istio, etc as well.</li><li>Deploy Istio.</li><li>Deploy the Istio Ingress Gateway service on the ingress-nodepool using Service type NodePort.</li><li>Create an associated Certificate Gateway using server certificates and private keys for TLS offload.</li><li>Create a service in the service-nodepool.</li><li>Reserve an unallocated static IP address from the node network range.</li><li><a href="https://cloud.google.com/load-balancing/docs/internal/setting-up-internal" target="_blank" rel="noopener noreferrer">Create an internal TCP load balancer</a>:<ol><li>Specify the frontend as the IP address reserved in step 6.</li><li>Specify the backend as the managed instance groups created during the node pool creation for the ingress-nodepool (ingress-nodepool-ig-a, ingress-nodepool-ig-b, ingress-nodepool-ig-c).</li><li>Specify ports 80 and 443.</li></ol></li><li>Create a GCP Firewall Rule to allow traffic from authorized sources (network tags or CIDR ranges) to a target of the ingress-nodepool network tag.</li><li>Create a Cloud DNS A Record for your managed zone as <!-- -->*<!-- -->.namespace.zone pointing to the IP Address assigned to the load balancer frontend in step 7.1.</li><li><a href="https://cloud.google.com/load-balancing/docs/health-checks#firewall_rules" target="_blank" rel="noopener noreferrer">Enable Health Checks through the GCP firewall</a> to reach the ingress-nodepool network tag at a minimum – however there is no harm in allowing these to all node pools.</li></ol><p>The service should then be resolvable and routable from authorized internal networks (peered private VPCs or internal networks connected via VPN or Dedicated Interconnect) as:</p><blockquote><p>https://_service<strong>.</strong>namespace<strong>.</strong>zone<strong>/</strong>endpoint__</p></blockquote><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-advantages-of-this-design-pattern-are">The advantages of this design pattern are...<a class="hash-link" href="#the-advantages-of-this-design-pattern-are" title="Direct link to heading">​</a></h3><ol><li>The Ingress Gateway provides fully functional application load balancing services.</li><li>Istio provides service discovery and routing using names and namespaces.</li><li>The Ingress Gateway service and ingress gateway node pool can be scaled as required to meet demand.</li><li>The Ingress Gateway is multi zonal for greater availability</li></ol></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/cloud">cloud</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/gcp">gcp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/istio">istio</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/load-balancing">load-balancing</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/vpc-native">vpc-native</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/aws-professional-and-speciality-exam-tips">AWS Professional and Speciality Exam Tips</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2019-04-04T00:00:00.000Z" itemprop="datePublished">April 4, 2019</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://fullstackchronicles.io/images/aws-pro-and-specialty-certs.png"><div class="markdown" itemprop="articleBody"><p>One you get beyond the Associate level AWS certification exams into the Professional or Speciality track exams the degree of difficulty rises significantly. As a veteran of the Certified Solutions Architect Professional and Big Data Specialty exams, I thought I would share my experiences which I believe are applicable to all the certification streams and tracks in the AWS certification program.</p><p>First off let me say that I am a self-professed certification addict, having sat more than thirty technical certification exams over my thirty plus year career in technology including certification and re-certification exams. I would put the AWS professional and specialty exams right up there in terms of their level of difficulty.</p><p>The AWS Professional and Specialty exams are specifically designed to be challenging. Although they have removed the pre-requisites for these exams (much to my dismay…), you really need to be prepared for these exams otherwise you are throwing your hard-earned money away.  </p><p>There are very few - if any - “easy” questions. All of the questions are scenario based and require you to design a solution to meet multiple requirements. The question and/or the correct answer will invariably involve the use of multiple AWS services (not just one). You will be tested on your reading comprehension, time management and ability to cope under pressure as well as being tested on your knowledge of the AWS platform.  </p><p>The following sections provide some general tips which will help you approach the exam and give you the best chance of success on the day. This is not a brain dump or a substitute for the hard work and dedication required to ensure success on your exam day.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="time-management">Time Management<a class="hash-link" href="#time-management" title="Direct link to heading">​</a></h2><p>Needless to say, your ability to manage time is critical, on average you will have approximately 2-3 minutes to answer each question. Reading the questions and answers carefully may take up 1-2 minutes on its own. If the answer is not apparent to you, you are best to mark the question and come back to it at the end of the exam.  </p><p>In many cases there may be subsequent questions and answer sets which jog your memory or help you deduce the correct answers to the questions you initial passed on. For instance, you may see references in future questions which put context around services you may not be completely familiar with, this may enable you to answer flagged questions with more confidence.  </p><p>Of course, you must answer all questions before completing the exam, there are no points for incomplete or unattempted answers.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="recommended-approach-to-each-question">Recommended Approach to each Question<a class="hash-link" href="#recommended-approach-to-each-question" title="Direct link to heading">​</a></h2><p>Most of the questions on the Professional or Specialty certification exams fall into one of three categories:</p><ul><li>Short-ish question, multiple long detailed answer options</li><li>Long-ish scenario question, multiple relatively short answer options</li><li>Long-ish question with multiple relatively long, detailed answers</li></ul><p>The latter scenario is thankfully less common. However, in all cases it is important to read the last sentence in the question first, this will provide indicators to help you read through the question in its entirety and all of the possible answers with a clear understanding of what is <em>“really”</em> being asked. For instance, the operative phrase may be <em>“highly available”</em> or <em>“most cost effective”</em>.</p><p>Try to eliminate answers based on what you know, for instance answers with erroneous instance families can be eliminated immediately. This will give you a much better statistical chance of success, even if you have to venture an educated guess in the end.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="the-most-complicated-solution-is-probably-not-the-correct-one">The Most Complicated Solution is Probably Not the Correct One<a class="hash-link" href="#the-most-complicated-solution-is-probably-not-the-correct-one" title="Direct link to heading">​</a></h2><p>In many answer sets to questions on the Professional or Specialty exams you will see some ridiculously complicated solution approaches, these are most often incorrect answers. Although there may be enough loosely relevant terminology or services to appear reasonable.</p><p>Note the following statement direct from the AWS Certified Solutions Architect Professional Exam Blueprint:</p><blockquote><p>“Distractors, or incorrect answers, are response options that an examinee with incomplete knowledge or skill would likely choose. However, they are generally plausible responses that fit in the content area defined by the test objective.”</p></blockquote><p>AWS wants professionals who design and implement solutions which are simple, sustainable, highly available, scalable and cost effective. One of the key Amazon Leadership Principles is <em>“Invent and Simplify”</em>, simplify is often the operative word.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="dont-spend-time-on-dumps-or-practice-exams-other-than-those-from-aws">Don’t spend time on dumps or practice exams (other than those from AWS)<a class="hash-link" href="#dont-spend-time-on-dumps-or-practice-exams-other-than-those-from-aws" title="Direct link to heading">​</a></h2><p>The question pools for AWS exams are enormous, the chances of you getting the same questions and answer sets as someone else are slim. Furthermore, non-AWS sources may not be trustworthy. There is no substitute to AWS white papers, how to’s, and real-life application of your learnings.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="dont-focus-on-service-limits-or-calculations">Don’t focus on Service Limits or Calculations<a class="hash-link" href="#dont-focus-on-service-limits-or-calculations" title="Direct link to heading">​</a></h2><p>In my experiences with AWS exams, they are not overly concerned with service limits, default values, formulas (e.g. the formula to calculate required partitions for a DynamoDB table) or syntax - so don’t waste time remembering them. You should however understand the 7 layer OSI model and be able to read and interpret CIDR notation.</p><p>Mainly, however, they want you to understand how services work together in an AWS solution to achieve an outcome for a customer.</p><h2 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="some-final-words-of-advice">Some Final Words of Advice<a class="hash-link" href="#some-final-words-of-advice" title="Direct link to heading">​</a></h2><p><strong>Always do what you think AWS would want you to do!</strong> </p><p>It is worthwhile having a quick look at the <a href="https://blog.aboutamazon.com.au/amazon-in-australia/our-leadership-principles" target="_blank" rel="noopener noreferrer">AWS Leadership Principles</a> (I have already referenced one of these in this article) as these are applied religiously in every aspect of the AWS business.  In particular, you should pay specific attention to the principals around simplicity and frugality.</p><p><strong>Good luck!</strong></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/aws">aws</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/certification">certification</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/gcp-networking-for-aws-professionals">GCP Networking for AWS Professionals</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2019-02-21T00:00:00.000Z" itemprop="datePublished">February 21, 2019</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://fullstackchronicles.io/images/gcp-aws-networking.png"><div class="markdown" itemprop="articleBody"><p>GCP and AWS share many similarities, they both provide similar services and both leverage containerization, virtualization and software defined networking.</p><p>There are some significant differences when it comes to their respective implementations, networking is a key example of this.</p><p>Before we compare and contrast the two different approaches to networking, it is worthwhile noting the genesis of the two major cloud providers.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="google-was-born-to-be-global-amazon-became-global"><em>Google was born to be global, Amazon became global</em><a class="hash-link" href="#google-was-born-to-be-global-amazon-became-global" title="Direct link to heading">​</a></h4><p>By no means am I suggesting that Amazon didn&#x27;t have designs on going global from it&#x27;s beginnings, but AWS was driven (entirely at the beginning) by the needs of the Amazon eCommerce business. Amazon started in the US before expanding into other regions (such as Europe and Australia). In some cases the expansion took decades (Amazon only entered Australia as a retailer in 2018).</p><p>Google, by contrast, was providing application, search and marketing services worldwide from its very beginning. GCP which was used as the vector to deliver these services and applications was architected around this global model, even though their actual data centre expansion may not have been as rapid as AWS’s (for example GCP opened its Australia region 5 years after AWS).</p><p>Their respective networking implementations reflect how their respective companies evolved.</p><h4 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="aws-is-a-leader-in-iaas-gcp-is-a-leader-in-paas"><em>AWS is a leader in IaaS, GCP is a leader in PaaS</em><a class="hash-link" href="#aws-is-a-leader-in-iaas-gcp-is-a-leader-in-paas" title="Direct link to heading">​</a></h4><p>This is only an opinion and may be argued, however if you look at the chronology of the two platforms, consider this:</p><ul><li>The first services released by AWS (simultaneously for all intents and purposes) were S3, SQS and EC2</li><li>The first service released by Google was AppEngine (a pure PaaS offering)</li></ul><p>Google has launched and matured their IaaS offerings since as AWS has done similarly with their PaaS offerings, but they started from much different places.</p><p>With all of that said, here are the key differences when it comes to networking between the two major cloud providers:</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="gcp-vpcs-are-global-by-default-aws-vpcs-are-regional-only">GCP VPCs are Global by default, AWS VPCs are Regional only<a class="hash-link" href="#gcp-vpcs-are-global-by-default-aws-vpcs-are-regional-only" title="Direct link to heading">​</a></h3><p>This is the first fundamental difference between the two providers. Each GCP project is allocated one VPC network with Subnets in each of the 18 GCP Regions. Whereas each AWS Account is allocated one Default VPC in each AWS Region with a Subnet in each AWS Availability Zone for that Region, that is each account has 17 VPCs in each of the 17 Regions (excluding GovCloud regions).</p><p><a target="_blank" href="/assets/files/gcp-default-network-bb8c3f62583663e872cc53948671005f.png"><img loading="lazy" alt="Default Global VPC Network in GCP" src="/assets/images/gcp-default-network-bb8c3f62583663e872cc53948671005f.png" width="1920" height="1080" class="img_E7b_"></a></p><p>It is entirely possible to create VPCs in GCP which are Regional, but they are Global by default.</p><p>This global tenancy can be advantageous in many cases, but can be limiting in others, for instance there is a limit of 25 peering connections to any one VPC, the limit in AWS is 125.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="gcp-subnets-are-regional-aws-subnets-are-zonal">GCP Subnets are Regional, AWS Subnets are Zonal<a class="hash-link" href="#gcp-subnets-are-regional-aws-subnets-are-zonal" title="Direct link to heading">​</a></h3><p>Subnets in GCP automatically span all Zones in a Region, whereas AWS VPC Subnets are assigned to Availability Zones in a Region. This means you are abstracted from some of the networking and zonal complexity, but you have less control over specific network placement of instances and endpoints. You can infer from this design that Zones are replicated or synchronised within a Region, making them less of a direct consideration for High Availability (or at least as much or your concern as they otherwise would be).</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="all-gcp-firewall-rules-are-stateful">All GCP Firewall Rules are Stateful<a class="hash-link" href="#all-gcp-firewall-rules-are-stateful" title="Direct link to heading">​</a></h3><p>AWS Security Groups are stateful firewall rules – meaning they maintain connection state for inbound connections, AWS also has Network ACLs (NACLs) which are stateless firewall rules. GCP has no direct equivalent of NACLs, however GCP Firewall Rules are more configurable than their AWS counterparts. For instance, GCP Firewall Rules can include Deny actions which is not an option with AWS Security Group Rules.</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="load-balancers-in-gcp-are-layer-4-tcpudp-unless-they-are-public-facing">Load Balancers in GCP are layer 4 (TCP/UDP) unless they are public facing<a class="hash-link" href="#load-balancers-in-gcp-are-layer-4-tcpudp-unless-they-are-public-facing" title="Direct link to heading">​</a></h3><p>AWS Application Load Balancers can be deployed in private VPCs with no external IPs attached to them. GCP has Application Load Balancers (Layer 7 load balancers) but only for public facing applications, internal facing load balancers in GCP are Network Load Balancers. This presents some challenges with application level load balancing functionality such as stickiness. There are potential workarounds however such as NGINX in GKE behind</p><h3 class="anchor anchorWithHideOnScrollNavbar_R0VQ" id="firewall-rules-are-at-the-network-level-not-at-the-instance-or-service-level">Firewall rules are at the Network Level not at the Instance or Service Level<a class="hash-link" href="#firewall-rules-are-at-the-network-level-not-at-the-instance-or-service-level" title="Direct link to heading">​</a></h3><p>There are simple firewall settings available at the instance level, these are limited to allowing HTTP and HTTPS traffic to the instance only and don’t allow you to specify sources. Detailed Firewall Rules are set at the GCP VPC Network level and are not attached or associated with instances as they are in AWS.</p><p><em>Hopefully this is helpful for AWS engineers and architects being exposed to GCP for the first time!</em></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/aws">aws</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/cloud">cloud</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/gcp">gcp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/tags/networking">networking</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/page/9"><div class="pagination-nav__label">Newer Entries</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/page/11"><div class="pagination-nav__label">Older Entries</div></a></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items"><li class="footer__item"><a href="https://stackql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">StackQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.windrate.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">WindRate<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/stackql/fullstackchronicles.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.c44711ab.js"></script>
<script src="/assets/js/main.ef28b439.js"></script>
</body>
</html>