<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Cloudy with a chance of Big Data Blog Feed RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Cloudy with a chance of Big Data Blog Feed Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4N6KSJ2G0P"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-4N6KSJ2G0P",{})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Cloudy with a chance of Big Data" href="/opensearch.xml"><title data-react-helmet="true">Cloudy with a chance of Big Data | Cloudy with a chance of Big Data</title><meta data-react-helmet="true" property="og:title" content="Cloudy with a chance of Big Data | Cloudy with a chance of Big Data"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="description" content="Cloud and data design patterns and random musings"><meta data-react-helmet="true" property="og:description" content="Cloud and data design patterns and random musings"><meta data-react-helmet="true" property="og:url" content="https://cloudywithachanceofbigdata.com/page/9"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://cloudywithachanceofbigdata.com/page/9"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/page/9" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://cloudywithachanceofbigdata.com/page/9" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.d8b73325.css">
<link rel="preload" href="/assets/js/runtime~main.e8bf8f37.js" as="script">
<link rel="preload" href="/assets/js/main.6b4a7196.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_2qcr"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title">Cloudy with a chance of Big Data</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Home</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/tags">Topics</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tags">All Topics</a></li><li><a class="dropdown__link" href="/tags/gcp">Google Cloud Platform</a></li><li><a class="dropdown__link" href="/tags/aws">AWS</a></li><li><a class="dropdown__link" href="/tags/azure">Azure</a></li><li><a class="dropdown__link" href="/tags/ci-cd">CI/CD</a></li></ul></div><a class="navbar__item navbar__link" href="/archive">Archive</a><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_71bT toggle_3Zt9 toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">🌜</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">🌞</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent Posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/automating-snowflake-role-based-storage-integration-for-aws">Automating Snowflake Role Based Storage Integration for AWS</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simplifying-large-cloudformation-templates-using-jsonnet">Simplifying Large CloudFormation Templates using Jsonnet</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/aws-deployments-with-cloudformation-and-gitlab-ci">Simplified AWS Deployments with CloudFormation and GitLab CI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/from-wordpress-to-jamstack">From Wordpress to Jamstack</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/using-jsonnet-to-configure-multiple-environments">Using Jsonnet to Configure Multiple Environments</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/use-bigquery-to-trigger-cloud-run">Use BigQuery to trigger Cloud Run</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/azure-static-web-app-review">Azure Static Web App Review</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/introducing-the-metadata-hub-mdh">Introducing the Metadata Hub (MDH)</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/masking-private-keys-in-ci-cd-pipelines-in-gitlab">Masking Private Keys in CI/CD Pipelines in GitLab</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/simple-tasker-configuration-driven-orchestration">Simple Tasker: Configuration driven orchestration</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/gcp-networking-for-aws-professionals">GCP Networking for AWS Professionals</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-02-21T00:00:00.000Z" itemprop="datePublished">February 21, 2019</time> · <!-- -->4 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/gcp-aws-networking.png"><div class="markdown" itemprop="articleBody"><p>GCP and AWS share many similarities, they both provide similar services and both leverage containerization, virtualization and software defined networking.</p><p>There are some significant differences when it comes to their respective implementations, networking is a key example of this.</p><p>Before we compare and contrast the two different approaches to networking, it is worthwhile noting the genesis of the two major cloud providers.</p><h4 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="google-was-born-to-be-global-amazon-became-global"><em>Google was born to be global, Amazon became global</em><a aria-hidden="true" class="hash-link" href="#google-was-born-to-be-global-amazon-became-global" title="Direct link to heading">​</a></h4><p>By no means am I suggesting that Amazon didn&#x27;t have designs on going global from it&#x27;s beginnings, but AWS was driven (entirely at the beginning) by the needs of the Amazon eCommerce business. Amazon started in the US before expanding into other regions (such as Europe and Australia). In some cases the expansion took decades (Amazon only entered Australia as a retailer in 2018).</p><p>Google, by contrast, was providing application, search and marketing services worldwide from its very beginning. GCP which was used as the vector to deliver these services and applications was architected around this global model, even though their actual data centre expansion may not have been as rapid as AWS’s (for example GCP opened its Australia region 5 years after AWS).</p><p>Their respective networking implementations reflect how their respective companies evolved.</p><h4 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="aws-is-a-leader-in-iaas-gcp-is-a-leader-in-paas"><em>AWS is a leader in IaaS, GCP is a leader in PaaS</em><a aria-hidden="true" class="hash-link" href="#aws-is-a-leader-in-iaas-gcp-is-a-leader-in-paas" title="Direct link to heading">​</a></h4><p>This is only an opinion and may be argued, however if you look at the chronology of the two platforms, consider this:</p><ul><li>The first services released by AWS (simultaneously for all intents and purposes) were S3, SQS and EC2</li><li>The first service released by Google was AppEngine (a pure PaaS offering)</li></ul><p>Google has launched and matured their IaaS offerings since as AWS has done similarly with their PaaS offerings, but they started from much different places.</p><p>With all of that said, here are the key differences when it comes to networking between the two major cloud providers:</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="gcp-vpcs-are-global-by-default-aws-vpcs-are-regional-only">GCP VPCs are Global by default, AWS VPCs are Regional only<a aria-hidden="true" class="hash-link" href="#gcp-vpcs-are-global-by-default-aws-vpcs-are-regional-only" title="Direct link to heading">​</a></h3><p>This is the first fundamental difference between the two providers. Each GCP project is allocated one VPC network with Subnets in each of the 18 GCP Regions. Whereas each AWS Account is allocated one Default VPC in each AWS Region with a Subnet in each AWS Availability Zone for that Region, that is each account has 17 VPCs in each of the 17 Regions (excluding GovCloud regions).</p><p><a target="_blank" href="/assets/files/gcp-default-network-bb8c3f62583663e872cc53948671005f.png"><img alt="Default Global VPC Network in GCP" src="/assets/images/gcp-default-network-bb8c3f62583663e872cc53948671005f.png"></a></p><p>It is entirely possible to create VPCs in GCP which are Regional, but they are Global by default.</p><p>This global tenancy can be advantageous in many cases, but can be limiting in others, for instance there is a limit of 25 peering connections to any one VPC, the limit in AWS is 125.</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="gcp-subnets-are-regional-aws-subnets-are-zonal">GCP Subnets are Regional, AWS Subnets are Zonal<a aria-hidden="true" class="hash-link" href="#gcp-subnets-are-regional-aws-subnets-are-zonal" title="Direct link to heading">​</a></h3><p>Subnets in GCP automatically span all Zones in a Region, whereas AWS VPC Subnets are assigned to Availability Zones in a Region. This means you are abstracted from some of the networking and zonal complexity, but you have less control over specific network placement of instances and endpoints. You can infer from this design that Zones are replicated or synchronised within a Region, making them less of a direct consideration for High Availability (or at least as much or your concern as they otherwise would be).</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="all-gcp-firewall-rules-are-stateful">All GCP Firewall Rules are Stateful<a aria-hidden="true" class="hash-link" href="#all-gcp-firewall-rules-are-stateful" title="Direct link to heading">​</a></h3><p>AWS Security Groups are stateful firewall rules – meaning they maintain connection state for inbound connections, AWS also has Network ACLs (NACLs) which are stateless firewall rules. GCP has no direct equivalent of NACLs, however GCP Firewall Rules are more configurable than their AWS counterparts. For instance, GCP Firewall Rules can include Deny actions which is not an option with AWS Security Group Rules.</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="load-balancers-in-gcp-are-layer-4-tcpudp-unless-they-are-public-facing">Load Balancers in GCP are layer 4 (TCP/UDP) unless they are public facing<a aria-hidden="true" class="hash-link" href="#load-balancers-in-gcp-are-layer-4-tcpudp-unless-they-are-public-facing" title="Direct link to heading">​</a></h3><p>AWS Application Load Balancers can be deployed in private VPCs with no external IPs attached to them. GCP has Application Load Balancers (Layer 7 load balancers) but only for public facing applications, internal facing load balancers in GCP are Network Load Balancers. This presents some challenges with application level load balancing functionality such as stickiness. There are potential workarounds however such as NGINX in GKE behind</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="firewall-rules-are-at-the-network-level-not-at-the-instance-or-service-level">Firewall rules are at the Network Level not at the Instance or Service Level<a aria-hidden="true" class="hash-link" href="#firewall-rules-are-at-the-network-level-not-at-the-instance-or-service-level" title="Direct link to heading">​</a></h3><p>There are simple firewall settings available at the instance level, these are limited to allowing HTTP and HTTPS traffic to the instance only and don’t allow you to specify sources. Detailed Firewall Rules are set at the GCP VPC Network level and are not attached or associated with instances as they are in AWS.</p><p><em>Hopefully this is helpful for AWS engineers and architects being exposed to GCP for the first time!</em></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/aws">aws</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/cloud">cloud</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/gcp">gcp</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/google-cloud-platform">google-cloud-platform</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/networking">networking</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/the-streaming-data-warehouse-kappa-architecture-and-data-warehousing-re-imagined">The Streaming Data Warehouse</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-02-14T00:00:00.000Z" itemprop="datePublished">February 14, 2019</time> · <!-- -->4 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/sdw.png"><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="kappa-architecture-and-data-warehousing-re-imagined">Kappa Architecture and Data Warehousing re-imagined<a aria-hidden="true" class="hash-link" href="#kappa-architecture-and-data-warehousing-re-imagined" title="Direct link to heading">​</a></h3><p><img alt="Streaming Data Warehouse" src="/assets/images/sdw-be6a1908ddfd66e86e152b05da8c227b.png"></p><p>The aspiration to extend data analysis (predictive, descriptive or otherwise) to streaming event data has been common across every enterprise scale program I have been involved with. Often, however, this aspiration goes unrealised as it tends to slide down the priority scale as we still grapple with legacy batch oriented integration patterns and processes.</p><p>Event processing is not a new concept, real time event and transaction processing has been a standard feature for security, digital and operations functions for some time, however in the Data Warehousing, BI and Advanced Analytics worlds it is often spoken about but rarely implemented, except for tech companies of course. In many cases personalization is still a batch oriented process, e.g. train a model from a feature set built from historical data, generate recommendations in batch, serve these recommendations upon the next visit - wash, rinse, and repeat.</p><p>Lambda has existed for several years now as a data-processing architecture pattern designed to incorporate both batch and stream-processing capabilities. Moreover, messaging platforms have existed for decades, from point-to-point messaging systems, to message-oriented-middleware systems, to distributed pub-sub messaging systems such as Apache Kafka.</p><p>Additionally, open source streaming data processing frameworks and tools have proliferated in recent years with projects such as Storm, Samza, Flink and Spark Streaming becoming established solutions.</p><p>Kafka in particular, with its focus on durability, resiliency, availability and consistency, has graduated into fully fledged data platform <strong>not simply a transient messaging system</strong>. In many cases Kafka is serving as a back end for operational processes, such as applications implementing the CQRS (Command Query Responsibility Segregation) design pattern.  </p><p>In other words, it is not the technology that holds us back, it&#x27;s our lack of imagination.</p><p>Enter <a href="http://milinda.pathirage.org/kappa-architecture.com/" target="_blank" rel="noopener noreferrer">Kappa Architecture</a> where we no longer have to attempt to integrate streaming data with batch processes…<strong>everything is a stream</strong>. The ultimate embodiment of Kappa Architecture is the <strong><em>Streaming Data Warehouse</em></strong>.</p><p>In the Streaming Data Warehouse, tables are represented by topics. Topics represent either:</p><ul><li>unbounded event or change streams; or</li><li>stateful representations of data (such as master, reference or summary data sets).</li></ul><p>This approach makes possible the enrichment and/or summarisation of transaction or event data with master or reference data. Furthermore many of the patterns used in data warehousing and master data management are inherent in Kafka as you can represent the current state of an object as well as the complete change history of that object (in other words change data capture and associated slowly changing dimensions from one inbound stream).</p><p>Data is acquired from source systems either in real time or as a scheduled extract process, <strong>in either case the data is presented to Kafka as a stream</strong>.</p><p>The Kafka Avro Schema Registry provides a systematic contract with source systems which also serves as a data dictionary for consumers supporting schema evolution with backward and forward compatibility. Data is retained on the Kafka platform for a designated period of time (days or weeks) where it is available for applications and processes to consume - these processes can include data summarisation or sliding window operations for reporting or notification, or data integration or datamart building processes which sink data to other systems - these could include relational or non-relational data stores.</p><p>Real time applications can be built using the KStreams API and emerging tools such as KSQL can be used to provide a well-known interface for sampling streaming data or performing windowed processing operations on streams. Structured Streaming in Spark or Spark Streaming in its original RDD/DStream implementation can be used to prepare and enrich data for machine learning operations using Spark ML or Spark MLlib.  </p><p>In addition, data sinks can operate concurrently to sink datasets to S3 or Google Cloud Storage or both (multi cloud - like real time analytics - is something which is talked about more than it’s implemented…).</p><p>In the Streaming Data Warehouse architecture Kafka is much more than a messaging platform it is a distributed data platform, which could easily replace major components of a legacy (or even a modern) data architecture.  </p><p>It just takes a little imagination…</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/data-warehousing">data-warehousing</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/kafka">kafka</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/kappa-architecture">kappa-architecture</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/stream-processing">stream-processing</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/streaming-analytics">streaming-analytics</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/test-driven-infrastructure-and-test-automation-with-ansible-molecule-and-azure">Test Driven Infrastructure and Test Automation with Ansible, Molecule and Azure</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-31T00:00:00.000Z" itemprop="datePublished">January 31, 2019</time> · <!-- -->5 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://github.com/datwiz" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="http://0.gravatar.com/avatar/f9af9c3fae755ac170c5798c53c5267d?s=80" alt="Chris Ottinger"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/datwiz" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Chris Ottinger</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Technologist</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/molecule-ansible-azure.png"><div class="markdown" itemprop="articleBody"><p>A few years back, before the rise of the hyper-scalers, I had my first infracode &#x27;aha moment&#x27; with OpenStack. The second came with <a href="https://kitchen.ci/" target="_blank" rel="noopener noreferrer">Kitchen</a>.</p><p>I had already been using test driven development for application code and configuration automation for infrastructure but Kitchen brought the two together. Kitchen made it possible to write tests, spin up infrastructure, and then tear everything down again - the Red/Green/Refactor cycle for infrastructure. What made this even better was that it wasn&#x27;t a facsimile of a target environment, it was the same - same VM&#x27;s, same OS, same network.</p><p>Coming from a Chef background for configuration automation, Kitchen is a great fit to the Ruby ecosystem. Kitchen works with Ansible and Azure, but a Ruby environment and at least a smattering of Ruby coding skills are required.</p><p><a href="https://molecule.readthedocs.io/" target="_blank" rel="noopener noreferrer">Molecule</a> provides a similar red-green development cycle to Kitchen, but without the need to step outside of the familiar Python environment.</p><p>Out of the box, Molecule supports development of Ansible roles using either a Docker or Virtual Box infrastructure provider. Molecule also leverages the Ansible drivers for private and public cloud platforms.</p><p>Molecule can be configured to test an individual role or collections of roles in Ansible playbooks.</p><p>This tutorial demonstrates how to use Molecule with Azure to develop and test an individual Ansible role following the red/green/refactor infracode workflow, which can be generalised as:</p><ul><li><strong>Red</strong>-<!-- --> write a failing infrastructure test</li><li><strong>Green</strong> - write the Ansible tasks needed to pass the test</li><li>Refactor - repeat the process</li></ul><p>The steps required for this tutorial are as follows:</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="azure-setup">Azure setup<a aria-hidden="true" class="hash-link" href="#azure-setup" title="Direct link to heading">​</a></h2><p>Ensure there is an existing Azure Resource Group that will be used for infracode development and testing. Within the resource group, ensure there is a single virtual network (vnet) with a single subnet. Ansible will use these for the default network setup.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="setup-a-working-environment">Setup a working environment<a aria-hidden="true" class="hash-link" href="#setup-a-working-environment" title="Direct link to heading">​</a></h2><p>There are a number of options for setting up a Python environment for Ansible and Molecule, including Python virtualenv or a Docker container environment.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="create-a-docker-image-for-ansiblemoleculeazure">Create a Docker image for Ansible+Molecule+Azure<a aria-hidden="true" class="hash-link" href="#create-a-docker-image-for-ansiblemoleculeazure" title="Direct link to heading">​</a></h2><p>This tutorial uses a Docker container environment. A <code>Dockerfile</code> for the image can be found in <code>./molecule-azure-image/Dockerfile</code>. The image sets up a sane Python3 environment with Ansible, Ansible<!-- -->[<!-- -->azure<!-- -->]<!-- -->, and Molecule <code>pip</code> modules installed.</p><iframe width="100%" frameborder="0" id="gist-4bd0c2ccae06dcaedffc2d91e594145f"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="create-a-docker-workspace">Create a Docker workspace<a aria-hidden="true" class="hash-link" href="#create-a-docker-workspace" title="Direct link to heading">​</a></h2><p>Setup a working environment using the Docker image with Ansible, Molecule, and the <code>azure-cli</code> installed.</p><iframe width="100%" frameborder="0" id="gist-f80ef20a720914cfd4e02cf9783fec06"></iframe><p>This example assumes the following:</p><ul><li>a resource group already exists with access rights to create virtual machines; and</li><li>the resource group contains a single vnet with a single subnet</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="log-into-an-azure-subcription">Log into an Azure subcription<a aria-hidden="true" class="hash-link" href="#log-into-an-azure-subcription" title="Direct link to heading">​</a></h2><p>Ansible supports a number of different methods for authenticating with Azure. This example uses the <code>azure-cli</code> to login interactively.</p><iframe width="100%" frameborder="0" id="gist-fd8987e7f724de5393a411c24c74978b"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="create-an-empty-ansible-role-with-molecule">Create an empty Ansible role with Molecule<a aria-hidden="true" class="hash-link" href="#create-an-empty-ansible-role-with-molecule" title="Direct link to heading">​</a></h2><p>Molecule provides an <code>init</code> function with defaults for various providers. The molecule-azure-role-template creates an empty role with scaffolding for Azure.</p><iframe width="100%" frameborder="0" id="gist-f9b301d950a2254ab9af4806f2110544"></iframe><p>Check that the environment is working by running the following code:</p><iframe width="100%" frameborder="0" id="gist-d56c3cd1e25b51acc634e5adb8a0a256"></iframe><p>The output should look be similar to…</p><iframe width="100%" frameborder="0" id="gist-a3f8aed99a7c910588a5651d8cabf0e8"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="spin-up-an-azure-vm">Spin up an Azure VM<a aria-hidden="true" class="hash-link" href="#spin-up-an-azure-vm" title="Direct link to heading">​</a></h2><p>Spin up a fresh VM to be used for infra-code development.</p><iframe width="100%" frameborder="0" id="gist-14a621ee65f9c2db583ed5ef94274c71"></iframe><p>Molecule provides a handy option for logging into the new VM:</p><iframe width="100%" frameborder="0" id="gist-456aa8a8860bf785b382e18ede204d33"></iframe><p>There is now a fresh Ubuntu 18.04 virtual machine ready for infra-code development. For this example, a basic Nginx server will be installed and verified.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="write-a-failing-test">Write a failing test<a aria-hidden="true" class="hash-link" href="#write-a-failing-test" title="Direct link to heading">​</a></h2><p><a href="https://testinfra.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Testinfra</a> provides a <code>pytest</code> based framework for verifying server and infrastructure configuration. Molecule then manages the execution of those <code>testinfra</code> tests. The Molecule template provides a starting point for crafting tests of your own. For this tutorial, installation of the <code>nginx</code> service is verified. Modify the tests file using <code>vi molecule/default/tests/test_default.py</code></p><iframe width="100%" frameborder="0" id="gist-5b22b20a192aecbecb8cc229cb5f2a69"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="execute-the-failing-test">Execute the failing test<a aria-hidden="true" class="hash-link" href="#execute-the-failing-test" title="Direct link to heading">​</a></h2><p>The Ansible task needed to install and enable <code>nginx</code> has not yet been written, so the test should fail:</p><iframe width="100%" frameborder="0" id="gist-38eb4bb776a41db7aa68f5962a97af62"></iframe><p>If the initial sample tests in <code>test_default.py</code> are kept, then 3 tests should fail and 2 tests should pass.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="write-a-task-to-install-nginx">Write a task to install <code>nginx</code><a aria-hidden="true" class="hash-link" href="#write-a-task-to-install-nginx" title="Direct link to heading">​</a></h2><p>Add a task to install the <code>nginx</code> service using <code>vi tasks/main.yml</code>:</p><iframe width="100%" frameborder="0" id="gist-40d884f0c3a39fc4b3e921d451d60358"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="apply-the-role">Apply the role<a aria-hidden="true" class="hash-link" href="#apply-the-role" title="Direct link to heading">​</a></h2><p>Apply the role to the instance created using Molecule.</p><iframe width="100%" frameborder="0" id="gist-5787aee41e2e3e9373f656677567ae41"></iframe><p>The <code>nginx</code> package should now be installed, both enabled and started, and listening on port 80. Note that the <code>nginx</code> instance will not be accessible from the Internet due to the Azure network security rules. The <code>nginx</code> instance can be confirmed manually by logging into the instance and using <code>curl</code> to make a request to the <code>nginx</code> service.</p><iframe width="100%" frameborder="0" id="gist-fb02518e7129bf28e27822c42221f706"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="execute-the-passing-test">Execute the passing test<a aria-hidden="true" class="hash-link" href="#execute-the-passing-test" title="Direct link to heading">​</a></h2><p>After applying the Ansible task to the instance, the <code>testinfra</code> tests should now pass.</p><iframe width="100%" frameborder="0" id="gist-b6359519ca6068615f8f1473636f90ea"></iframe><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="cleanup">Cleanup<a aria-hidden="true" class="hash-link" href="#cleanup" title="Direct link to heading">​</a></h2><p>Now that the Ansible role works as defined in the test specification, the development environment can be cleaned up.</p><iframe width="100%" frameborder="0" id="gist-150971a02b3f4b2c65d551cb09a203d0"></iframe><p>Molecule removes the Azure resources created to develop and test the configuration role. Note that deletion may take a few minutes.</p><p>Finally, once you are done, exit the container environment. If the container was started with the <code>--rm</code> switch, the container will also be removed, leaving you with a clean workspace and newly minted Ansible role with automated test cases.</p><iframe width="100%" frameborder="0" id="gist-4fbb00b116b1a389b0343f6424b19a1b"></iframe></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/ansible">ansible</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/azure">azure</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/cloud">cloud</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/infrastructure-code">infrastructure-code</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/molecule">molecule</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/python">python</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/test-automation">test-automation</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/when-life-gives-you-undrinkable-wine-make-cognac">When Life Gives you Undrinkable Wine – Make Cognac…</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-30T00:00:00.000Z" itemprop="datePublished">January 30, 2019</time> · <!-- -->3 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/shutterstock_425848342.jpg"><div class="markdown" itemprop="articleBody"><p><img alt="Make Cognac" src="/assets/images/shutterstock_425848342-2d637d243e9723efcc27775d70ce4b6c.jpg"></p><p>Firstly, this is not another motivational talk or motherhood statement (there are plenty of those out there already), but a metaphor about resourcefulness.</p><p>We have all heard the adage “when life gives you lemons, make lemonade”. Allow me to present a slight twist (pardon the pun…) on this statement.</p><p>Cognac is a variety of brandy named after the town of Cognac, France. It is distilled from a white wine grown from grapes in the area. The wine used to make Cognac is characterised as &quot;virtually undrinkable&quot;. However in its distilled form, Cognac is considered to be the world&#x27;s most refined spirit. With bottles of high end Cognac fetching as much as $200,000.</p><p>The area surrounding the town of Cognac was a recognised wine-growing area dating back to the third century, however when it was evident that the grapes produced in the town of Cognac itself were unsuitable for wine making, local producers developed the practice of double distillation in copper pot stills and ageing in oak barrels for at least two years. The product yielded was the spirit we now know as Cognac.</p><p>Fast forward 15 centuries to Scotland in the 1800’s, where John Walker was a humble shopkeeper. Local whiskey producers would bring John different varieties of single malt whiskeys, many of them below an acceptable standard. Instead of on selling these varieties – he began blending them as made-to-order whiskies, blended to meet specific customer requirements. From this idea a product (and subsequently one of the most globally recognised brands) was created which would last over 200 years.</p><p><strong>Interesting, but what does this have to do with technology you might ask?</strong></p><p>Ingenuity and resourcefulness have existed for as long as man has, but in the realm of technology and in particular cloud computing and open source software it has never been more imperative. We are continually faced with challenges on each assignment or project, often technology not working as planned or as advertised, or finding dead ends when trying to solve problems. This is particularly evident now as software and technology are moving at such an accelerated rate.</p><p>To be successful in this era you need creativity and lateral thinking. You need an ability not just to solve problems to which there are no documented solutions, but to create new products from existing ones which are not necessarily suitable for your specific objective. In many cases, looking to add value in the process. That is not just making lemonade from lemons (which anyone could think of) but making Cognac from sub-standard grapes or premium blended whiskey from sub-standard single malt whiskies.</p><p>One of my favourite Amazon Leadership Principles is <strong><em>“Invent and Simplify”</em></strong>:</p><blockquote><p><em>Leaders expect and require innovation and invention from their teams and always find ways to simplify. They are externally aware, look for new ideas from everywhere, and are not limited by “not invented here&quot;. As we do new things, we accept that we may be misunderstood for long periods of time.</em></p><p><a href="https://www.amazon.jobs/en/principles" target="_blank" rel="noopener noreferrer"><em><strong>https:</strong></em><strong>//www.amazon.jobs/en/principles</strong></a>  </p></blockquote><p>The intent in this statement is not simply to “lift and shift” current on premise systems and processes to the cloud, but to look for ways to streamline, rationalise and simplify processes in doing so. This mandates a combination of practicality and creativity.</p><p>The take away is when you are presented with a challenge, be creative and inventive and not just solve the problem but look for ways to add value in the process.</p><p>Cheers!</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/cloud">cloud</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/creativity">creativity</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/lateral-thinking">lateral-thinking</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/open-source-software">open-source-software</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/technology">technology</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/s3-object-notifications-using-lambda-and-ses">S3 Object Notifications using Lambda and SES</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-01-18T00:00:00.000Z" itemprop="datePublished">January 18, 2019</time> · <!-- -->3 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_1yU8" src="https://s.gravatar.com/avatar/f96573d092470c74be233e1dded5376f?s=80" alt="Jeffrey Aven"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeffreyaven/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeffrey Aven</span></a></div><small class="avatar__subtitle" itemprop="description">Technologist and Cloud Consultant</small></div></div></div></div></header><meta itemprop="image" content="https://cloudywithachanceofbigdata.com/images/s3-object-notifications-using-Lambda-and-SES-with-Terraform.png"><div class="markdown" itemprop="articleBody"><p>Following on from the previous post in the Really Simple Terraform series <a href="https://cloudywithachanceofbigdata.com/really-simple-terraform-infrastructure-automation-using-aws-lambda/" target="_blank" rel="noopener noreferrer">simple-lambda-ec2-scheduler</a>, where we used Terraform to deploy a Lambda function including the packaging of the Python function into a ZIP archive and creation of all supporting objects (roles, policies, permissions, etc) – in this post we will take things a step further by using templating to update parameters in the Lambda function code before the packaging and creation of the Lambda function.</p><p>S3 event notifications can be published directly to an SNS topic which you could create an email subscription, this is quite straightforward. However the email notifications you get look something like this:</p><p><img alt="Email Notification sent via an SNS Topic Subscription" src="/assets/images/sns-object-notification-email-173693c0618474107c4e13e72ea5e805.png"></p><p>There is very little you can do about this.</p><p>However if you take a slightly different approach by triggering a Lambda function to send an email via SES you have much more control over content and formatting. Using this approach you could get an email notification that looks like this:</p><p><img alt="Email Notification sent using Lambda and SES" src="/assets/images/ses-object-notification-email-f2ec2abb7f361ac49d08d5b54ac369ad.png"></p><p>Much easier on the eye!</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="prerequisites">Prerequisites<a aria-hidden="true" class="hash-link" href="#prerequisites" title="Direct link to heading">​</a></h2><p>You will need verified AWS SES (Simple Email Service) email addresses for the sender and recipient’s addresses used for your object notification emails. This can be done via the console as shown here:</p><p><img alt="SES Email Address Verification" src="/assets/images/ses-verify-67af4f0a0493eddb21c1500407857016.png"></p><p><em>Note that SES is not available in every AWS region, pick one that is generally closest to your particular reason (but it really doesn&#x27;t matter for this purpose).</em></p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="deployment">Deployment<a aria-hidden="true" class="hash-link" href="#deployment" title="Direct link to heading">​</a></h2><p>The Terraform module creates an IAM Role and associated policy for the Lambda function as shown here:</p><iframe width="100%" frameborder="0" id="gist-023fab404c0df759d6d1d4bdb02ab4e8"></iframe><p>Variables in the module are substituted into the function code template, the rendered template file is then packaged as a ZIP archive to be uploaded as the Lambda function source as shown here:</p><iframe width="100%" frameborder="0" id="gist-7d72d8c67114a9df0af1528a3b754d9e"></iframe><p><em>As in the previous post, I will reiterate that although Terraform is technically not a build tool, it can be used for simple build operations such as this.</em></p><p>The Lambda function is deployed using the following code:</p><iframe width="100%" frameborder="0" id="gist-5e7f2a238e8e0270cd55def40a389903"></iframe><p>Finally the S3 object notification events are configured as shown here:</p><iframe width="100%" frameborder="0" id="gist-e7de65f20c79e0efb115024597864a75"></iframe><p>Use the following commands to run this example (I have created a default credentials profile, but you could supply your API credentials directly, use STS, etc):</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">cd simple-notifications-with-lambda-and-ses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">terraform init</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">terraform apply</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><blockquote><p><em>Full source code can be found at: <a href="https://github.com/avensolutions/simple-notifications-with-lambda-and-ses" target="_blank" rel="noopener noreferrer"><strong>https://github.com/avensolutions/simple-notifications-with-lambda-and-ses</strong></a></em></p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/aws">aws</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/boto-3">boto3</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/lambda">lambda</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/python">python</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/s-3">s3</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/ses">ses</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/tags/terraform">terraform</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/page/8"><div class="pagination-nav__label">«<!-- --> <!-- -->Newer Entries</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/page/10"><div class="pagination-nav__label">Older Entries<!-- --> <!-- -->»</div></a></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Blog</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/archive">Archive</a></li><li class="footer__item"><a class="footer__link-item" href="/tags">Tags</a></li></ul></div><div class="col footer__col"><div class="footer__title">Sponsors</div><ul class="footer__items"><li class="footer__item"><a href="https://infraql.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>InfraQL<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://gammadata.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Gamma Data<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/cloudywithachanceofbigdata/cloudywithachanceofbigdata.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/assets/js/runtime~main.e8bf8f37.js"></script>
<script src="/assets/js/main.6b4a7196.js"></script>
</body>
</html>